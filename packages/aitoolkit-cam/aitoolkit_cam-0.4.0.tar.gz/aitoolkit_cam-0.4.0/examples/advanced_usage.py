#!/usr/bin/env python3
"""
é«˜çº§ä½¿ç”¨ç¤ºä¾‹ - å±•ç¤ºAIToolkit Cameraçš„é«˜çº§åŠŸèƒ½
"""
from aitoolkit_cam import Camera, Processor
import cv2
import time
import threading
import numpy as np

def multi_camera_example():
    """å¤šæ‘„åƒå¤´åŒæ—¶ä½¿ç”¨ç¤ºä¾‹"""
    print("=== å¤šæ‘„åƒå¤´ç¤ºä¾‹ ===")
    
    # æ£€æµ‹å¯ç”¨æ‘„åƒå¤´
    available_cameras = Camera.find_available_cameras()
    print(f"æ£€æµ‹åˆ°å¯ç”¨æ‘„åƒå¤´: {available_cameras}")
    
    if len(available_cameras) < 2:
        print("âš ï¸ éœ€è¦è‡³å°‘2ä¸ªæ‘„åƒå¤´æ‰èƒ½è¿è¡Œæ­¤ç¤ºä¾‹")
        return
    
    # åˆ›å»ºå¤šä¸ªæ‘„åƒå¤´å®ä¾‹
    cam1 = Camera(source=available_cameras[0], web_enabled=True, port=9010)
    cam2 = Camera(source=available_cameras[1], web_enabled=True, port=9011)
    
    try:
        # å¯åŠ¨æ‘„åƒå¤´
        print("å¯åŠ¨æ‘„åƒå¤´1...")
        cam1.start()
        url1 = cam1.get_web_url()
        
        print("å¯åŠ¨æ‘„åƒå¤´2...")
        cam2.start()
        url2 = cam2.get_web_url()
        
        print(f"ğŸŒ æ‘„åƒå¤´1åœ°å€: {url1}")
        print(f"ğŸŒ æ‘„åƒå¤´2åœ°å€: {url2}")
        
        # åŒæ—¶è¯»å–ä¸¤ä¸ªæ‘„åƒå¤´çš„æ•°æ®
        for i in range(5):
            ret1, frame1 = cam1.read()
            ret2, frame2 = cam2.read()
            
            if ret1 and ret2:
                print(f"å¸§ {i+1}: æ‘„åƒå¤´1={frame1.shape}, æ‘„åƒå¤´2={frame2.shape}")
            
            time.sleep(1)
        
        print("âœ… å¤šæ‘„åƒå¤´ç¤ºä¾‹å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ å¤šæ‘„åƒå¤´é”™è¯¯: {e}")
    finally:
        cam1.stop()
        cam2.stop()

def custom_processing_example():
    """è‡ªå®šä¹‰å›¾åƒå¤„ç†ç¤ºä¾‹"""
    print("\n=== è‡ªå®šä¹‰å›¾åƒå¤„ç†ç¤ºä¾‹ ===")
    
    def custom_effect(frame):
        """è‡ªå®šä¹‰æ•ˆæœï¼šå½©è™¹è¾¹æ¡†"""
        if frame is None:
            return frame
        
        h, w = frame.shape[:2]
        
        # åˆ›å»ºå½©è™¹è¾¹æ¡†
        border_size = 20
        colors = [(255, 0, 0), (255, 127, 0), (255, 255, 0), 
                 (0, 255, 0), (0, 0, 255), (75, 0, 130), (148, 0, 211)]
        
        result = frame.copy()
        
        for i, color in enumerate(colors):
            thickness = border_size - i * 2
            if thickness > 0:
                cv2.rectangle(result, (i, i), (w-i-1, h-i-1), color, 2)
        
        return result
    
    cam = Camera(source='auto', web_enabled=True, port=9012)
    
    try:
        cam.start()
        url = cam.get_web_url()
        print(f"ğŸŒ è‡ªå®šä¹‰æ•ˆæœåœ°å€: {url}")
        
        # åº”ç”¨è‡ªå®šä¹‰æ•ˆæœ
        for i, frame in enumerate(cam):
            processed_frame = custom_effect(frame)
            cam.cv_show(processed_frame, "web")
            
            if i >= 50:  # å¤„ç†50å¸§åé€€å‡º
                break
        
        print("âœ… è‡ªå®šä¹‰å¤„ç†ç¤ºä¾‹å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ è‡ªå®šä¹‰å¤„ç†é”™è¯¯: {e}")
    finally:
        cam.stop()

def performance_monitoring_example():
    """æ€§èƒ½ç›‘æ§ç¤ºä¾‹"""
    print("\n=== æ€§èƒ½ç›‘æ§ç¤ºä¾‹ ===")
    
    cam = Camera(source='auto', width=640, height=480)
    
    try:
        cam.start()
        
        # æ€§èƒ½ç»Ÿè®¡
        frame_count = 0
        start_time = time.time()
        processing_times = []
        
        print("å¼€å§‹æ€§èƒ½ç›‘æ§...")
        
        for frame in cam:
            frame_start = time.time()
            
            # æ¨¡æ‹Ÿä¸€äº›å¤„ç†
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            edges = cv2.Canny(gray, 50, 150)
            
            frame_end = time.time()
            processing_time = frame_end - frame_start
            processing_times.append(processing_time)
            
            frame_count += 1
            
            # æ¯10å¸§è¾“å‡ºä¸€æ¬¡ç»Ÿè®¡
            if frame_count % 10 == 0:
                elapsed = time.time() - start_time
                fps = frame_count / elapsed
                avg_processing = np.mean(processing_times[-10:]) * 1000
                
                print(f"å¸§æ•°: {frame_count}, FPS: {fps:.1f}, "
                      f"å¹³å‡å¤„ç†æ—¶é—´: {avg_processing:.1f}ms")
            
            if frame_count >= 50:
                break
        
        # æœ€ç»ˆç»Ÿè®¡
        total_time = time.time() - start_time
        avg_fps = frame_count / total_time
        avg_processing = np.mean(processing_times) * 1000
        
        print(f"\nğŸ“Š æ€§èƒ½ç»Ÿè®¡:")
        print(f"   æ€»å¸§æ•°: {frame_count}")
        print(f"   æ€»æ—¶é—´: {total_time:.2f}ç§’")
        print(f"   å¹³å‡FPS: {avg_fps:.1f}")
        print(f"   å¹³å‡å¤„ç†æ—¶é—´: {avg_processing:.1f}ms")
        
    except Exception as e:
        print(f"âŒ æ€§èƒ½ç›‘æ§é”™è¯¯: {e}")
    finally:
        cam.stop()

def threaded_processing_example():
    """å¤šçº¿ç¨‹å¤„ç†ç¤ºä¾‹"""
    print("\n=== å¤šçº¿ç¨‹å¤„ç†ç¤ºä¾‹ ===")
    
    cam = Camera(source='auto')
    processed_frames = []
    processing_lock = threading.Lock()
    
    def processing_worker(frame_queue):
        """å¤„ç†çº¿ç¨‹å·¥ä½œå‡½æ•°"""
        processor = Processor('cartoon')
        
        while True:
            try:
                frame = frame_queue.get(timeout=1.0)
                if frame is None:  # ç»“æŸä¿¡å·
                    break
                
                # å¤„ç†å¸§
                processed = processor.process(frame)
                
                with processing_lock:
                    processed_frames.append(processed)
                
                frame_queue.task_done()
                
            except:
                break
    
    try:
        cam.start()
        
        # åˆ›å»ºå¸§é˜Ÿåˆ—å’Œå¤„ç†çº¿ç¨‹
        import queue
        frame_queue = queue.Queue(maxsize=10)
        
        # å¯åŠ¨å¤„ç†çº¿ç¨‹
        worker_thread = threading.Thread(target=processing_worker, args=(frame_queue,))
        worker_thread.daemon = True
        worker_thread.start()
        
        print("å¼€å§‹å¤šçº¿ç¨‹å¤„ç†...")
        
        # ä¸»çº¿ç¨‹è´Ÿè´£è¯»å–å¸§
        for i, frame in enumerate(cam):
            try:
                frame_queue.put(frame, timeout=0.1)
            except queue.Full:
                print("é˜Ÿåˆ—æ»¡ï¼Œè·³è¿‡å¸§")
            
            # æ£€æŸ¥å¤„ç†ç»“æœ
            with processing_lock:
                if processed_frames:
                    processed = processed_frames.pop(0)
                    print(f"å¤„ç†å®Œæˆå¸§ {i}: {processed.shape}")
            
            if i >= 20:
                break
        
        # å‘é€ç»“æŸä¿¡å·
        frame_queue.put(None)
        worker_thread.join(timeout=2.0)
        
        print("âœ… å¤šçº¿ç¨‹å¤„ç†ç¤ºä¾‹å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ å¤šçº¿ç¨‹å¤„ç†é”™è¯¯: {e}")
    finally:
        cam.stop()

def context_manager_example():
    """ä¸Šä¸‹æ–‡ç®¡ç†å™¨ä½¿ç”¨ç¤ºä¾‹"""
    print("\n=== ä¸Šä¸‹æ–‡ç®¡ç†å™¨ç¤ºä¾‹ ===")
    
    try:
        # ä½¿ç”¨withè¯­å¥è‡ªåŠ¨ç®¡ç†èµ„æº
        with Camera(source='auto', web_enabled=True, port=9013) as cam:
            url = cam.get_web_url()
            print(f"ğŸŒ ä¸Šä¸‹æ–‡ç®¡ç†å™¨åœ°å€: {url}")
            
            # è¯»å–ä¸€äº›å¸§
            for i in range(5):
                ret, frame = cam.read()
                if ret:
                    print(f"å¸§ {i+1}: {frame.shape}")
                time.sleep(0.5)
        
        print("âœ… ä¸Šä¸‹æ–‡ç®¡ç†å™¨ç¤ºä¾‹å®Œæˆï¼ˆèµ„æºè‡ªåŠ¨æ¸…ç†ï¼‰")
        
    except Exception as e:
        print(f"âŒ ä¸Šä¸‹æ–‡ç®¡ç†å™¨é”™è¯¯: {e}")

if __name__ == "__main__":
    multi_camera_example()
    custom_processing_example()
    performance_monitoring_example()
    threaded_processing_example()
    context_manager_example() 