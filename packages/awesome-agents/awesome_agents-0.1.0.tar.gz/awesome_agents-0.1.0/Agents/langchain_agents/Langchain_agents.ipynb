{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-17T05:37:57.477510Z",
     "start_time": "2025-02-17T05:37:57.475021Z"
    }
   },
   "source": [
    "from utils import init\n",
    "\n",
    "init()"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "dc0021ff0db22ae7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "38358efeff205419"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T05:38:34.765451Z",
     "start_time": "2025-02-17T05:38:33.839395Z"
    }
   },
   "cell_type": "code",
   "source": "from langchain_community.tools.tavily_search import TavilySearchResults",
   "id": "21d5f2c7766148ea",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T05:38:41.661461Z",
     "start_time": "2025-02-17T05:38:41.655367Z"
    }
   },
   "cell_type": "code",
   "source": "search = TavilySearchResults()",
   "id": "6e32efff7f130091",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T05:38:50.560476Z",
     "start_time": "2025-02-17T05:38:46.940390Z"
    }
   },
   "cell_type": "code",
   "source": "search.invoke(\"what is the weather in SF\")",
   "id": "d19bc4751450e732",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://www.weatherapi.com/',\n",
       "  'content': \"{'location': {'name': 'San Francisco', 'region': 'California', 'country': 'United States of America', 'lat': 37.775, 'lon': -122.4183, 'tz_id': 'America/Los_Angeles', 'localtime_epoch': 1739770554, 'localtime': '2025-02-16 21:35'}, 'current': {'last_updated_epoch': 1739770200, 'last_updated': '2025-02-16 21:30', 'temp_c': 12.2, 'temp_f': 54.0, 'is_day': 0, 'condition': {'text': 'Overcast', 'icon': '//cdn.weatherapi.com/weather/64x64/night/122.png', 'code': 1009}, 'wind_mph': 4.5, 'wind_kph': 7.2, 'wind_degree': 290, 'wind_dir': 'WNW', 'pressure_mb': 1020.0, 'pressure_in': 30.11, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 97, 'cloud': 100, 'feelslike_c': 11.7, 'feelslike_f': 53.1, 'windchill_c': 11.2, 'windchill_f': 52.2, 'heatindex_c': 11.3, 'heatindex_f': 52.4, 'dewpoint_c': 10.9, 'dewpoint_f': 51.6, 'vis_km': 16.0, 'vis_miles': 9.0, 'uv': 0.0, 'gust_mph': 6.9, 'gust_kph': 11.2}}\"},\n",
       " {'url': 'https://weathershogun.com/weather/usa/ca/san-francisco/480/february/2025-02-17',\n",
       "  'content': 'San Francisco, California Weather: Monday, February 17, 2025. Cloudy weather, overcast skies with no rain. Day 59Â°. Night 48Â°.'},\n",
       " {'url': 'https://www.weather2travel.com/california/san-francisco/february/',\n",
       "  'content': \"San Francisco weather in February 2025 | California Holidays San Francisco weather in February 2025 Expect 16Â°C daytime maximum temperatures in the shade with on average 7 hours of sunshine per day in San Francisco in February. There are usually 9 days with some rain in San Francisco in February and the average monthly rainfall is 91mm. Get your weekly fix of holiday inspiration from some of the world's best travel writers plus save on your next trip with the latest exclusive offers More holidays January sales Handpicked travel deals & holiday discounts We help you find the best travel deals for your holiday in the sun by sharing tips on when and where to go, before providing you with top discounts. Holidays\"},\n",
       " {'url': 'https://world-weather.info/forecast/usa/san_francisco/february-2025/',\n",
       "  'content': \"Weather in San Francisco in February 2025 (California) - Detailed Weather Forecast for a Month Weather World Weather in San Francisco Weather in San Francisco in February 2025 San Francisco Weather Forecast for February 2025, is based on previous years' statistical data. +59Â°+50Â° +59Â°+52Â° +59Â°+50Â° +61Â°+52Â° +59Â°+50Â° +61Â°+50Â° +61Â°+52Â° +63Â°+52Â° +61Â°+52Â° +61Â°+50Â° +61Â°+50Â° +61Â°+50Â° +59Â°+50Â° +59Â°+50Â° +61Â°+50Â° +61Â°+52Â° +59Â°+50Â° +59Â°+48Â° +57Â°+48Â° +59Â°+50Â° +59Â°+48Â° +59Â°+50Â° +57Â°+46Â° +61Â°+50Â° +61Â°+50Â° +59Â°+50Â° +59Â°+48Â° +59Â°+50Â° Extended weather forecast in San Francisco HourlyWeek10-Day14-Day30-DayYear Weather in large and nearby cities Weather in Washington, D.C.+41Â° Sacramento+55Â° Pleasanton+55Â° Redwood City+55Â° San Leandro+55Â° San Mateo+54Â° San Rafael+52Â° San Ramon+52Â° South San Francisco+54Â° Vallejo+50Â° Palo Alto+55Â° Pacifica+55Â° Berkeley+54Â° Castro Valley+55Â° Concord+52Â° Daly City+54Â° Noverd+52Â° Sign Hill+54Â° world's temperature today day day Temperature units\"},\n",
       " {'url': 'https://www.weather25.com/north-america/usa/california/san-francisco?page=month&month=February',\n",
       "  'content': 'San Francisco weather in February 2025 | Weather25.com San Francisco weather in February 2025 The average weather in San Francisco in February | San Francisco in February | Temperatures in San Francisco in February Weather in San Francisco in February - FAQ What is the average temperature in San Francisco in February? The average temperature in San Francisco in February is 7/16Â° C. On average, there are 4 rainy days in San Francisco during February. The weather in San Francisco in February is good. On average, there are 0 snowy days in San Francisco in February. More about the weather in San Francisco San Francisco 14 day weather Long range weather for San Francisco San Francisco weather in March San Francisco Webcam Weather tomorrow Hotels in San Francisco'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T05:40:10.192634Z",
     "start_time": "2025-02-17T05:40:08.963928Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/overview\")\n",
    "docs = loader.load()\n",
    "documents = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200\n",
    ").split_documents(docs)\n",
    "vector = FAISS.from_documents(documents, OpenAIEmbeddings())\n",
    "retriever = vector.as_retriever()"
   ],
   "id": "36a14102247bb122",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T05:40:20.681497Z",
     "start_time": "2025-02-17T05:40:20.115546Z"
    }
   },
   "cell_type": "code",
   "source": "retriever.invoke(\"how to upload a dataset\")[0]",
   "id": "4be03447f7f47733",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(id='f6891146-b502-452c-9836-b0ae2b123b7e', metadata={'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | ðŸ¦œï¸ðŸ› ï¸ LangSmith', 'description': 'LangSmith is a platform for building production-grade LLM applications.', 'language': 'en'}, page_content='Get started by adding tracing to your application.\\nCreate dashboards to view key metrics like RPS, error rates and costs.\\n\\nEvals\\u200b\\nThe quality and development speed of AI applications depends on high-quality evaluation datasets and metrics to test and optimize your applications on. The LangSmith SDK and UI make building and running high-quality evaluations easy.\\n\\nGet started by creating your first evaluation.\\nQuickly assess the performance of your application using our off-the-shelf evaluators (Python only) as a starting point.\\nAnalyze results of evaluations in the LangSmith UI and compare results over time.\\nEasily collect human feedback on your data to improve your application.\\n\\nPrompt Engineering\\u200b\\nWhile traditional software applications are built by writing code, AI applications involve writing prompts to instruct the LLM on what to do. LangSmith provides a set of tools designed to enable and facilitate prompt engineering to help you find the perfect prompt for your application.')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T05:40:34.570491Z",
     "start_time": "2025-02-17T05:40:34.566075Z"
    }
   },
   "cell_type": "code",
   "source": "from langchain.tools.retriever import create_retriever_tool",
   "id": "9d5afbe6d7f46910",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T05:41:33.952875Z",
     "start_time": "2025-02-17T05:41:33.945213Z"
    }
   },
   "cell_type": "code",
   "source": [
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"langsmith_search\",\n",
    "    \"Search for information about LangSmith. For any questions about LangSmith, you must use this tool!\",\n",
    ")"
   ],
   "id": "24f0374a1df7b7d1",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T05:41:40.938587Z",
     "start_time": "2025-02-17T05:41:40.936411Z"
    }
   },
   "cell_type": "code",
   "source": "tools = [search, retriever_tool]",
   "id": "cc01b0330e518d18",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T05:41:48.429427Z",
     "start_time": "2025-02-17T05:41:48.386652Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)"
   ],
   "id": "d31224a5d98b8cb6",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T05:41:59.534471Z",
     "start_time": "2025-02-17T05:41:58.972357Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain import hub\n",
    "\n",
    "# Get the prompt to use - you can modify this!\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages"
   ],
   "id": "2b062574691b60a7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T05:42:08.212257Z",
     "start_time": "2025-02-17T05:42:07.965861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.agents import create_tool_calling_agent\n",
    "\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)"
   ],
   "id": "a4b5c770e3ad407e",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T05:42:14.747474Z",
     "start_time": "2025-02-17T05:42:14.745023Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ],
   "id": "874dd3c6f7c060d9",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T05:42:21.813147Z",
     "start_time": "2025-02-17T05:42:21.084496Z"
    }
   },
   "cell_type": "code",
   "source": "agent_executor.invoke({\"input\": \"hi!\"})",
   "id": "66e853724930638c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3mHello! How can I assist you today?\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'hi!', 'output': 'Hello! How can I assist you today?'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T05:42:31.289330Z",
     "start_time": "2025-02-17T05:42:29.197885Z"
    }
   },
   "cell_type": "code",
   "source": "agent_executor.invoke({\"input\": \"how can langsmith help with testing?\"})",
   "id": "4d61cd831320a241",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3m\n",
      "Invoking: `langsmith_search` with `{'query': 'how can LangSmith help with testing'}`\n",
      "\n",
      "\n",
      "\u001B[0m\u001B[33;1m\u001B[1;3mLangSmith + LangChain OSSLangSmith integrates seamlessly with LangChain's open source frameworks langchain and langgraph, with no extra instrumentation needed.If you're already using either of these, see the how-to guide for setting up LangSmith with LangChain or setting up LangSmith with LangGraph.\n",
      "Observabilityâ€‹\n",
      "Observability is important for any software application, but especially so for LLM applications. LLMs are non-deterministic by nature, meaning they can produce unexpected results. This makes them trickier than normal to debug.\n",
      "This is where LangSmith can help! LangSmith has LLM-native observability, allowing you to get meaningful insights from your application. LangSmithâ€™s observability features have you covered throughout all stages of application development - from prototyping, to beta testing, to production.\n",
      "\n",
      "Get started with LangSmith | ðŸ¦œï¸ðŸ› ï¸ LangSmith\n",
      "\n",
      "Skip to main contentJoin us at  Interrupt: The Agent AI Conference by LangChain on May 13 & 14 in San Francisco!API ReferenceRESTPythonJS/TSSearchRegionUSEUGo to AppGet StartedObservabilityEvaluationPrompt EngineeringDeployment (LangGraph Platform)AdministrationSelf-hostingPricingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsEvaluationDataset transformationsRegions FAQsdk_referenceGet StartedOn this pageGet started with LangSmith\n",
      "LangSmith is a platform for building production-grade LLM applications.\n",
      "It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence.\n",
      "ObservabilityAnalyze traces in LangSmith and configure metrics, dashboards, alerts based on these.EvalsEvaluate your application over production traffic â€” score application performance and get human feedback on your data.Prompt EngineeringIterate on prompts, with automatic version control and collaboration features.\n",
      "\n",
      "Get started by adding tracing to your application.\n",
      "Create dashboards to view key metrics like RPS, error rates and costs.\n",
      "\n",
      "Evalsâ€‹\n",
      "The quality and development speed of AI applications depends on high-quality evaluation datasets and metrics to test and optimize your applications on. The LangSmith SDK and UI make building and running high-quality evaluations easy.\n",
      "\n",
      "Get started by creating your first evaluation.\n",
      "Quickly assess the performance of your application using our off-the-shelf evaluators (Python only) as a starting point.\n",
      "Analyze results of evaluations in the LangSmith UI and compare results over time.\n",
      "Easily collect human feedback on your data to improve your application.\n",
      "\n",
      "Prompt Engineeringâ€‹\n",
      "While traditional software applications are built by writing code, AI applications involve writing prompts to instruct the LLM on what to do. LangSmith provides a set of tools designed to enable and facilitate prompt engineering to help you find the perfect prompt for your application.\u001B[0m\u001B[32;1m\u001B[1;3mLangSmith can help with testing in the following ways:\n",
      "\n",
      "1. **Observability**: LangSmith provides LLM-native observability, allowing you to get meaningful insights from your application. This observability feature covers all stages of application development, from prototyping to beta testing to production.\n",
      "\n",
      "2. **Evaluations**: LangSmith offers tools for evaluating your application over production traffic, scoring application performance, and receiving human feedback on your data. The LangSmith SDK and UI make building and running high-quality evaluations easy.\n",
      "\n",
      "3. **Prompt Engineering**: AI applications involve writing prompts to instruct the LLM on what to do. LangSmith provides tools for prompt engineering, enabling you to find the perfect prompt for your application.\n",
      "\n",
      "By utilizing LangSmith's observability, evaluation, and prompt engineering features, you can test and optimize your applications effectively.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'how can langsmith help with testing?',\n",
       " 'output': \"LangSmith can help with testing in the following ways:\\n\\n1. **Observability**: LangSmith provides LLM-native observability, allowing you to get meaningful insights from your application. This observability feature covers all stages of application development, from prototyping to beta testing to production.\\n\\n2. **Evaluations**: LangSmith offers tools for evaluating your application over production traffic, scoring application performance, and receiving human feedback on your data. The LangSmith SDK and UI make building and running high-quality evaluations easy.\\n\\n3. **Prompt Engineering**: AI applications involve writing prompts to instruct the LLM on what to do. LangSmith provides tools for prompt engineering, enabling you to find the perfect prompt for your application.\\n\\nBy utilizing LangSmith's observability, evaluation, and prompt engineering features, you can test and optimize your applications effectively.\"}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T05:42:50.960843Z",
     "start_time": "2025-02-17T05:42:45.977451Z"
    }
   },
   "cell_type": "code",
   "source": "agent_executor.invoke({\"input\": \"whats the weather in sf?\"})",
   "id": "d9aac3a2a02f499e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'weather in San Francisco'}`\n",
      "\n",
      "\n",
      "\u001B[0m\u001B[36;1m\u001B[1;3m[{'url': 'https://www.weatherapi.com/', 'content': \"{'location': {'name': 'San Francisco', 'region': 'California', 'country': 'United States of America', 'lat': 37.775, 'lon': -122.4183, 'tz_id': 'America/Los_Angeles', 'localtime_epoch': 1739770795, 'localtime': '2025-02-16 21:39'}, 'current': {'last_updated_epoch': 1739770200, 'last_updated': '2025-02-16 21:30', 'temp_c': 12.2, 'temp_f': 54.0, 'is_day': 0, 'condition': {'text': 'Overcast', 'icon': '//cdn.weatherapi.com/weather/64x64/night/122.png', 'code': 1009}, 'wind_mph': 4.5, 'wind_kph': 7.2, 'wind_degree': 290, 'wind_dir': 'WNW', 'pressure_mb': 1020.0, 'pressure_in': 30.11, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 97, 'cloud': 100, 'feelslike_c': 11.7, 'feelslike_f': 53.1, 'windchill_c': 11.2, 'windchill_f': 52.2, 'heatindex_c': 11.3, 'heatindex_f': 52.4, 'dewpoint_c': 10.9, 'dewpoint_f': 51.6, 'vis_km': 16.0, 'vis_miles': 9.0, 'uv': 0.0, 'gust_mph': 6.9, 'gust_kph': 11.2}}\"}, {'url': 'https://www.weather2travel.com/california/san-francisco/february/', 'content': \"San Francisco weather in February 2025 | California Holidays San Francisco weather in February 2025 Expect 16Â°C daytime maximum temperatures in the shade with on average 7 hours of sunshine per day in San Francisco in February. There are usually 9 days with some rain in San Francisco in February and the average monthly rainfall is 91mm. Get your weekly fix of holiday inspiration from some of the world's best travel writers plus save on your next trip with the latest exclusive offers More holidays January sales Handpicked travel deals & holiday discounts We help you find the best travel deals for your holiday in the sun by sharing tips on when and where to go, before providing you with top discounts. Holidays\"}, {'url': 'https://world-weather.info/forecast/usa/san_francisco/february-2025/', 'content': \"Weather in San Francisco in February 2025 (California) - Detailed Weather Forecast for a Month Weather World Weather in San Francisco Weather in San Francisco in February 2025 San Francisco Weather Forecast for February 2025, is based on previous years' statistical data. +59Â°+50Â° +59Â°+52Â° +59Â°+50Â° +61Â°+52Â° +59Â°+50Â° +61Â°+50Â° +61Â°+52Â° +63Â°+52Â° +61Â°+52Â° +61Â°+50Â° +61Â°+50Â° +61Â°+50Â° +59Â°+50Â° +59Â°+50Â° +61Â°+50Â° +61Â°+52Â° +59Â°+50Â° +59Â°+48Â° +57Â°+48Â° +59Â°+50Â° +59Â°+48Â° +59Â°+50Â° +57Â°+46Â° +61Â°+50Â° +61Â°+50Â° +59Â°+50Â° +59Â°+48Â° +59Â°+50Â° Extended weather forecast in San Francisco HourlyWeek10-Day14-Day30-DayYear Weather in large and nearby cities Weather in Washington, D.C.+41Â° Sacramento+55Â° Pleasanton+55Â° Redwood City+55Â° San Leandro+55Â° San Mateo+54Â° San Rafael+52Â° San Ramon+52Â° South San Francisco+54Â° Vallejo+50Â° Palo Alto+55Â° Pacifica+55Â° Berkeley+54Â° Castro Valley+55Â° Concord+52Â° Daly City+54Â° Noverd+52Â° Sign Hill+54Â° world's temperature today day day Temperature units\"}, {'url': 'https://www.weather25.com/north-america/usa/california/san-francisco?page=month&month=February', 'content': 'San Francisco weather in February 2025 | Weather25.com San Francisco weather in February 2025 The average weather in San Francisco in February | San Francisco in February | Temperatures in San Francisco in February Weather in San Francisco in February - FAQ What is the average temperature in San Francisco in February? The average temperature in San Francisco in February is 7/16Â° C. On average, there are 4 rainy days in San Francisco during February. The weather in San Francisco in February is good. On average, there are 0 snowy days in San Francisco in February. More about the weather in San Francisco San Francisco 14 day weather Long range weather for San Francisco San Francisco weather in March San Francisco Webcam Weather tomorrow Hotels in San Francisco'}, {'url': 'https://www.easeweather.com/north-america/united-states/california/city-and-county-of-san-francisco/san-francisco/february', 'content': \"February 2025 Weather - San Francisco Weather in San Francisco for February 2025 Your guide to San Francisco weather in February - trends and predictions In general, the average temperature in San Francisco at the beginning of February is 14.4\\xa0Â°F. Valentine's Day weather in San Francisco â¤ï¸ - See the complete forecast for Wednesday, February 14. San Francisco in February average weather Temperatures trend during February in San Francisco Our weather forecast for San Francisco in February is based on the analysis of historical data rather than real-time forecast models. San Francisco in February - FAQ Explore the daily rainfall trends and prepare for San Franciscos February weather\\xa0ðŸ’§ Get accurate weather forecasts for San Francisco, located at latitude 37.775 and longitude -122.419.\"}]\u001B[0m\u001B[32;1m\u001B[1;3mThe current weather in San Francisco is as follows:\n",
      "- Temperature: 12.2Â°C (54.0Â°F)\n",
      "- Condition: Overcast\n",
      "- Wind: 4.5 mph from WNW\n",
      "- Humidity: 97%\n",
      "- Cloud Cover: 100%\n",
      "- Feels like: 11.7Â°C (53.1Â°F)\n",
      "\n",
      "For more detailed information, you can visit [Weather API](https://www.weatherapi.com/).\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'whats the weather in sf?',\n",
       " 'output': 'The current weather in San Francisco is as follows:\\n- Temperature: 12.2Â°C (54.0Â°F)\\n- Condition: Overcast\\n- Wind: 4.5 mph from WNW\\n- Humidity: 97%\\n- Cloud Cover: 100%\\n- Feels like: 11.7Â°C (53.1Â°F)\\n\\nFor more detailed information, you can visit [Weather API](https://www.weatherapi.com/).'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Adding Memory",
   "id": "9ef608fd64a3f743"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T05:43:24.155218Z",
     "start_time": "2025-02-17T05:43:23.639978Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Here we pass in an empty list of messages for chat_history because it is the first message in the chat\n",
    "agent_executor.invoke({\"input\": \"hi! my name is bob\", \"chat_history\": []})"
   ],
   "id": "f7875785e4a15e58",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3mHello Bob! How can I assist you today?\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'hi! my name is bob',\n",
       " 'chat_history': [],\n",
       " 'output': 'Hello Bob! How can I assist you today?'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T05:43:35.760608Z",
     "start_time": "2025-02-17T05:43:35.758428Z"
    }
   },
   "cell_type": "code",
   "source": "from langchain_core.messages import AIMessage, HumanMessage",
   "id": "89fa0fcca29cb836",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T05:43:43.427913Z",
     "start_time": "2025-02-17T05:43:43.011046Z"
    }
   },
   "cell_type": "code",
   "source": [
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"chat_history\": [\n",
    "            HumanMessage(content=\"hi! my name is bob\"),\n",
    "            AIMessage(content=\"Hello Bob! How can I assist you today?\"),\n",
    "        ],\n",
    "        \"input\": \"what's my name?\",\n",
    "    }\n",
    ")"
   ],
   "id": "69a8f4c7d717b433",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3mYour name is Bob. How can I help you, Bob?\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='hi! my name is bob', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Hello Bob! How can I assist you today?', additional_kwargs={}, response_metadata={})],\n",
       " 'input': \"what's my name?\",\n",
       " 'output': 'Your name is Bob. How can I help you, Bob?'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T05:43:55.134468Z",
     "start_time": "2025-02-17T05:43:55.128421Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ],
   "id": "536e3b3f3859d89b",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T05:44:04.326567Z",
     "start_time": "2025-02-17T05:44:04.324538Z"
    }
   },
   "cell_type": "code",
   "source": "message_history = ChatMessageHistory()",
   "id": "c7d3ad6063a28fdd",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T05:44:10.864694Z",
     "start_time": "2025-02-17T05:44:10.860398Z"
    }
   },
   "cell_type": "code",
   "source": [
    "agent_with_chat_history = RunnableWithMessageHistory(\n",
    "    agent_executor,\n",
    "    # This is needed because in most real world scenarios, a session id is needed\n",
    "    # It isn't really used here because we are using a simple in memory ChatMessageHistory\n",
    "    lambda session_id: message_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")"
   ],
   "id": "9d26655d5cd60f53",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T05:44:29.469790Z",
     "start_time": "2025-02-17T05:44:29.034741Z"
    }
   },
   "cell_type": "code",
   "source": [
    "agent_with_chat_history.invoke(\n",
    "    {\"input\": \"hi! I'm bob\"},\n",
    "    # This is needed because in most real world scenarios, a session id is needed\n",
    "    # It isn't really used here because we are using a simple in memory ChatMessageHistory\n",
    "    config={\"configurable\": {\"session_id\": \"12333\"}},\n",
    ")"
   ],
   "id": "ce9a708517103486",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3mHello Bob! How can I assist you today?\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"hi! I'm bob\",\n",
       " 'chat_history': [HumanMessage(content=\"hi! I'm bob\", additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Hello Bob! How can I assist you today?', additional_kwargs={}, response_metadata={})],\n",
       " 'output': 'Hello Bob! How can I assist you today?'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T05:44:51.396836Z",
     "start_time": "2025-02-17T05:44:50.860810Z"
    }
   },
   "cell_type": "code",
   "source": [
    "agent_with_chat_history.invoke(\n",
    "    {\"input\": \"what's my name?\"},\n",
    "    # This is needed because in most real world scenarios, a session id is needed\n",
    "    # It isn't really used here because we are using a simple in memory ChatMessageHistory\n",
    "    config={\"configurable\": {\"session_id\": \"222\"}},\n",
    ")"
   ],
   "id": "314b564715ba11ae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3mYour name is Bob! How can I help you, Bob?\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"what's my name?\",\n",
       " 'chat_history': [HumanMessage(content=\"hi! I'm bob\", additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Hello Bob! How can I assist you today?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content=\"hi! I'm bob\", additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Hello Bob! How can I assist you today?', additional_kwargs={}, response_metadata={})],\n",
       " 'output': 'Your name is Bob! How can I help you, Bob?'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
