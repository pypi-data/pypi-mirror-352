import logging
import os
from Orange.widgets.widget import OWWidget, Input, Output
from Orange.widgets import gui, settings
from Orange.data import Table, Domain, ContinuousVariable, StringVariable, DiscreteVariable, TimeVariable, Variable
import pandas as pd
import numpy as np
import tempfile
from autogluon.timeseries import TimeSeriesPredictor, TimeSeriesDataFrame
from datetime import datetime, timedelta
from pathlib import Path
import traceback
from Orange.widgets.utils.widgetpreview import WidgetPreview
from PyQt5.QtWidgets import QPlainTextEdit, QCheckBox, QComboBox, QLabel
from PyQt5.QtCore import QCoreApplication
from PyQt5.QtGui import QFont
import holidays # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –±–∏–±–ª–∏–æ—Ç–µ–∫—É holidays
import warnings

warnings.filterwarnings('ignore')
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class OWAutoGluonTimeSeries(OWWidget):
    name = "AutoGluon Time Series"
    description = "–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤ —Å AutoGluon"
    icon = "icons/autogluon.png"
    priority = 0
    keywords = ["timeseries", "forecast", "autogluon"]

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏
    prediction_length = settings.Setting(10)
    time_limit = settings.Setting(60)
    selected_metric = settings.Setting("MAE")
    selected_preset = settings.Setting("best_quality")
    target_column = settings.Setting("sales")
    id_column = settings.Setting("item_id")
    timestamp_column = settings.Setting("timestamp")
    include_holidays = settings.Setting(False)
    #use_current_date = settings.Setting(True)  # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ç–µ–∫—É—â–µ–π –¥–∞—Ç—ã
    frequency = settings.Setting("D")  # –ß–∞—Å—Ç–æ—Ç–∞ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–Ω–∏)
    auto_frequency = settings.Setting(True)  # –ê–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —á–∞—Å—Ç–æ—Ç—ã
    selected_model = settings.Setting("auto") # –≤—ã–±–æ—Ä –º–æ–¥–µ–ª–µ–π
    holiday_country = settings.Setting("RU") # –°—Ç—Ä–∞–Ω–∞ –¥–ª—è –ø—Ä–∞–∑–¥–Ω–∏–∫–æ–≤

    # –ú–µ—Ç—Ä–∏–∫–∏
    METRICS = ["MAE", "MAPE", "MSE", "RMSE", "RMSLE", "SMAPE", "WAPE", "WQL", "SQL", "MASE", "RMSSE"]
    
    # –ß–∞—Å—Ç–æ—Ç—ã
    FREQUENCIES = [
        ("D", "–î–µ–Ω—å"),
        ("W", "–ù–µ–¥–µ–ª—è"),
        ("M", "–ú–µ—Å—è—Ü"),
        ("Q", "–ö–≤–∞—Ä—Ç–∞–ª"),
        ("Y", "–ì–æ–¥"),
        ("H", "–ß–∞—Å"),
        ("T", "–ú–∏–Ω—É—Ç–∞"),
        ("B", "–†–∞–±–æ—á–∏–π –¥–µ–Ω—å")
    ]
    # –î–æ—Å—Ç—É–ø–Ω—ã–µ —Å—Ç—Ä–∞–Ω—ã –¥–ª—è –ø—Ä–∞–∑–¥–Ω–∏–∫–æ–≤ (–º–æ–∂–Ω–æ —Ä–∞—Å—à–∏—Ä–∏—Ç—å)
    HOLIDAY_COUNTRIES = ["RU", "US", "GB", "DE", "FR", "CA"]


    class Inputs:
        data = Input("Data", Table)

    class Outputs:
        prediction = Output("Prediction", Table)
        leaderboard = Output("Leaderboard", Table)
        model_info = Output("Model Info", Table)
        log_messages = Output("Log", str)

    def __init__(self):
        super().__init__()
        self.data = None
        self.predictor = None
        self.log_messages = ""
        self.detected_frequency = "D"  # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–∞—è —á–∞—Å—Ç–æ—Ç–∞ –¥–∞–Ω–Ω—ã—Ö –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        self.mainArea.hide()
        self.setup_ui()
        self.warning("")
        self.error("")
        self.log("–í–∏–¥–∂–µ—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        
        # –î–∞–Ω–Ω—ã–µ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–ª–∏–Ω—ã –ø—Ä–æ–≥–Ω–æ–∑–∞
        self.max_allowed_prediction = 0
        self.data_length = 0
        self.from_form_timeseries = False  # –§–ª–∞–≥ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∏—Å—Ç–æ—á–Ω–∏–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        self.categorical_mapping = {} # –¥–ª—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π

    def setup_ui(self):

        # –û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        box = gui.widgetBox(self.controlArea, "–ü–∞—Ä–∞–º–µ—Ç—Ä—ã")
        self.prediction_spin = gui.spin(box, self, "prediction_length", 1, 365, 1, label="–î–ª–∏–Ω–∞ –ø—Ä–æ–≥–Ω–æ–∑–∞:")
        self.prediction_spin.valueChanged.connect(self.on_prediction_length_changed)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—É—é –º–µ—Ç–∫—É –æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω–µ –ø—Ä–æ–≥–Ω–æ–∑–∞
        self.max_length_label = QLabel("–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –ø—Ä–æ–≥–Ω–æ–∑–∞: N/A")
        box.layout().addWidget(self.max_length_label)
        
        gui.spin(box, self, "time_limit", 10, 86400, 10, label="–õ–∏–º–∏—Ç –≤—Ä–µ–º–µ–Ω–∏ (—Å–µ–∫):")
        
        # –ö–∞—Å—Ç–æ–º–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ –º–µ—Ç—Ä–∏–∫
        from PyQt5.QtGui import QStandardItemModel, QStandardItem
        from PyQt5.QtCore import Qt, QVariant

        self.metric_combo = QComboBox()
        model = QStandardItemModel()

        def add_group(title, items):
            title_item = QStandardItem(f"‚Äî {title} ‚Äî")
            title_item.setFlags(Qt.NoItemFlags)  # –ó–∞–≥–æ–ª–æ–≤–æ–∫ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è –≤—ã–±–æ—Ä–∞
            model.appendRow(title_item)
            for metric in items:
                item = QStandardItem(metric)
                item.setData(metric, Qt.UserRole)
                model.appendRow(item)

        add_group("Probabilistic", ["SQL", "WQL"])
        add_group("Point forecast (median)", ["MAE", "MASE", "WAPE"])
        add_group("Point forecast (mean)", ["MSE", "RMSE", "RMSLE", "RMSSE", "MAPE", "SMAPE"])

        self.metric_combo.setModel(model)

        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞ –º–µ—Ç—Ä–∏–∫–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (MAPE)
        for i in range(model.rowCount()):
            item = model.item(i)
            if item and item.data(Qt.UserRole) == "MAPE":
                self.metric_combo.setCurrentIndex(i)
                self.selected_metric = "MAPE"
                break

        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ QComboBox –≤ layout
        box.layout().addWidget(QLabel("–ú–µ—Ç—Ä–∏–∫–∞:"))
        box.layout().addWidget(self.metric_combo)

        # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –Ω–∞—á–∞–ª—å–Ω–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è (–±–ª–æ–∫ –∑–∞–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –∫–æ–Ω—Ñ–ª–∏–∫—Ç–∞)
        # if isinstance(self.selected_metric, int):
        #     self.metric_combo.setCurrentIndex(self.selected_metric)
        # else:
        #     self.metric_combo.setCurrentText(self.selected_metric)

        # –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –≤—ã–±–æ—Ä–∞, —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤—ã–±—Ä–∞–Ω–Ω—É—é –º–µ—Ç—Ä–∏–∫—É
        def on_metric_changed(index):
            metric = self.metric_combo.currentText()
            if metric.startswith("‚Äî"):
                return  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏
            self.selected_metric = metric
            self.log(f"–í—ã–±—Ä–∞–Ω–∞ –º–µ—Ç—Ä–∏–∫–∞: {self.selected_metric}")

        self.metric_combo.currentIndexChanged.connect(on_metric_changed)
        
        self.model_selector = gui.comboBox(
            box, self, "selected_preset",
            items=["best_quality", "high_quality", "medium_quality", "fast_training"],
            label="–ü—Ä–µ—Å–µ—Ç:",
            sendSelectedValue=True
        )

        # –ü–æ–ª—É—á–∞–µ–º –º–æ–¥–µ–ª–∏ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏
        available_models = self._get_available_models()
        # –î–æ–±–∞–≤–ª—è–µ–º –≤—ã–±–æ—Ä –º–æ–¥–µ–ª–µ–π
        self.model_selector = gui.comboBox(
            box, self, "selected_model",
            items=available_models,
            label="–ú–æ–¥–µ–ª—å autogluon:",
            sendSelectedValue=True
        )
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å—Ç–æ–ª–±—Ü–æ–≤
        col_box = gui.widgetBox(self.controlArea, "–°—Ç–æ–ª–±—Ü—ã")
        # –•—Ä–∞–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –≤—ã–ø–∞–¥–∞—é—â–µ–≥–æ —Å–ø–∏—Å–∫–∞
        self.all_columns = []
        
        # –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è
        self.target_combo = gui.comboBox(col_box, self, "target_column", label="–¶–µ–ª–µ–≤–∞—è:", 
                                         items=[], sendSelectedValue=True,
                                         callback=self.on_target_column_changed) 
        # ID —Ä—è–¥–∞
        self.id_combo = gui.comboBox(col_box, self, "id_column", label="ID —Ä—è–¥–∞:", 
                                     items=[], sendSelectedValue=True,
                                     callback=self.on_id_column_changed) 
        # –í—Ä–µ–º–µ–Ω–Ω–∞—è –º–µ—Ç–∫–∞
        self.timestamp_combo = gui.comboBox(col_box, self, "timestamp_column", label="–í—Ä–µ–º—è:", 
                                            items=[], sendSelectedValue=True,
                                            callback=self.on_timestamp_column_changed) 
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —á–∞—Å—Ç–æ—Ç—ã
        freq_box = gui.widgetBox(self.controlArea, "–ß–∞—Å—Ç–æ—Ç–∞ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞")
        
        # –ß–µ–∫–±–æ–∫—Å –¥–ª—è –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —á–∞—Å—Ç–æ—Ç—ã
        self.auto_freq_checkbox = QCheckBox("–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è—Ç—å —á–∞—Å—Ç–æ—Ç—É")
        self.auto_freq_checkbox.setChecked(self.auto_frequency)
        self.auto_freq_checkbox.stateChanged.connect(self.on_auto_frequency_changed)
        freq_box.layout().addWidget(self.auto_freq_checkbox)
        
        # –í—ã–ø–∞–¥–∞—é—â–∏–π —Å–ø–∏—Å–æ–∫ —á–∞—Å—Ç–æ—Ç
        self.freq_combo = gui.comboBox(freq_box, self, "frequency", 
              items=[f[0] for f in self.FREQUENCIES], 
              label="–ß–∞—Å—Ç–æ—Ç–∞:",
              callback=self.on_frequency_changed)
        # –ó–∞–º–µ–Ω—è–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –æ–±–æ–∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ –ø–æ–Ω—è—Ç–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è
        for i, (code, label) in enumerate(self.FREQUENCIES):
            self.freq_combo.setItemText(i, f"{label} ({code})")
        
        # –û—Ç–∫–ª—é—á–∞–µ–º –∫–æ–º–±–æ–±–æ–∫—Å, –µ—Å–ª–∏ –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–∫–ª—é—á–µ–Ω–æ
        self.freq_combo.setDisabled(self.auto_frequency)
        
        # –ú–µ—Ç–∫–∞ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–π —á–∞—Å—Ç–æ—Ç—ã
        self.detected_freq_label = QLabel("–û–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–∞—è —á–∞—Å—Ç–æ—Ç–∞: N/A")
        freq_box.layout().addWidget(self.detected_freq_label)

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        extra_box = gui.widgetBox(self.controlArea, "–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ")
        self.holidays_checkbox = QCheckBox("–£—á–∏—Ç—ã–≤–∞—Ç—å –ø—Ä–∞–∑–¥–Ω–∏–∫–∏")
        self.holidays_checkbox.setChecked(self.include_holidays)
        self.holidays_checkbox.stateChanged.connect(self.on_holidays_changed)
        extra_box.layout().addWidget(self.holidays_checkbox)

        # –î–æ–±–∞–≤–ª—è–µ–º –≤—ã–±–æ—Ä —Å—Ç—Ä–∞–Ω—ã –¥–ª—è –ø—Ä–∞–∑–¥–Ω–∏–∫–æ–≤
        self.holiday_country_combo = gui.comboBox(extra_box, self, "holiday_country",
                                                  label="–°—Ç—Ä–∞–Ω–∞ –¥–ª—è –ø—Ä–∞–∑–¥–Ω–∏–∫–æ–≤:",
                                                  items=self.HOLIDAY_COUNTRIES,
                                                  sendSelectedValue=True)
        self.holiday_country_combo.setEnabled(self.include_holidays) # –ê–∫—Ç–∏–≤–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω—ã –ø—Ä–∞–∑–¥–Ω–∏–∫–∏
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –¥–ª—è –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ç–µ–∫—É—â–µ–π –¥–∞—Ç—ã
        """self.date_checkbox = QCheckBox("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–µ–∫—É—â—É—é –¥–∞—Ç—É (–∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å –¥–∞—Ç—ã –≤ –¥–∞–Ω–Ω—ã—Ö)")
        self.date_checkbox.setChecked(self.use_current_date)
        self.date_checkbox.stateChanged.connect(self.on_date_option_changed)
        extra_box.layout().addWidget(self.date_checkbox)"""

        # –∫–Ω–æ–ø–∫–∞
        self.run_button = gui.button(self.controlArea, self, "–ó–∞–ø—É—Å—Ç–∏—Ç—å", callback=self.run_model)

        # –ª–æ–≥–∏
        log_box_main = gui.widgetBox(self.controlArea, "–õ–æ–≥–∏", addSpace=True)
        self.log_widget = QPlainTextEdit(readOnly=True)
        self.log_widget.setMinimumHeight(200)
        font = QFont("Monospace")
        font.setStyleHint(QFont.TypeWriter)
        self.log_widget.setFont(font)
        log_box_main.layout().addWidget(self.log_widget)
    
    def _get_available_models(self):
        """–ü–û–õ–ù–´–ô —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π AutoGluon"""
        try:
            print("–ü–æ–ª—É—á–∞–µ–º –ü–û–õ–ù–´–ô —Å–ø–∏—Å–æ–∫ —á–µ—Ä–µ–∑ –∏–º–ø–æ—Ä—Ç –∫–ª–∞—Å—Å–æ–≤")
            
            # –ü–æ–ª–Ω—ã–π —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –∏–∑ GitHub AutoGluon
            all_models = [
                "auto",
                # –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ
                "Naive", "SeasonalNaive", "Zero", "Average", "SeasonalAverage",
                "ETS", "AutoETS", "ARIMA", "AutoARIMA", "AutoCES",
                "Theta", "DynamicOptimizedTheta", "IMAPA", "ADIDA", "Croston",
                
                # –¢–∞–±–ª–∏—á–Ω—ã–µ
                "DirectTabular", "RecursiveTabular",
                
                # Deep Learning
                "DeepAR", "SimpleFeedForward", "TemporalFusionTransformer",
                "PatchTST", "TiDE", "DLinear", "WaveNet", "NPTS",
                
                # –ü—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ
                "Chronos"
            ]
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∫–∏–µ —Ä–µ–∞–ª—å–Ω–æ –¥–æ—Å—Ç—É–ø–Ω—ã –≤ –≤–∞—à–µ–π —É—Å—Ç–∞–Ω–æ–≤–∫–µ
            available_models = ["auto"]
            
            try:
                import autogluon.timeseries.models as ag_models
                for model_name in all_models[1:]:  # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º "auto"
                    try:
                        model_class = getattr(ag_models, f"{model_name}Model", None)
                        if model_class is not None:
                            available_models.append(model_name)
                            print(f"‚úÖ {model_name} –¥–æ—Å—Ç—É–ø–Ω–∞")
                        else:
                            print(f"‚ùå {model_name} –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")
                    except AttributeError:
                        print(f"‚ùå {model_name} –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")
                        
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏: {e}")
                # Fallback –Ω–∞ –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ –º–æ–¥–µ–ª–∏
                available_models = [
                    "auto", "Naive", "SeasonalNaive", "ETS", "AutoETS", 
                    "DirectTabular", "RecursiveTabular", "DeepAR", 
                    "TemporalFusionTransformer", "PatchTST", "TiDE"
                ]
                
            print(f"–ò—Ç–æ–≥–æ –¥–æ—Å—Ç—É–ø–Ω–æ: {len(available_models)} –º–æ–¥–µ–ª–µ–π")
            return available_models
            
        except Exception as e:
            print(f"–ü–æ–ª–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ failed: {e}")
            return [
                "auto", "Naive", "SeasonalNaive", "ETS", "AutoETS",
                "DirectTabular", "RecursiveTabular", "DeepAR", 
                "TemporalFusionTransformer", "PatchTST", "TiDE"
            ]

    def on_frequency_changed(self):
        """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∏–∑–º–µ–Ω–µ–Ω–∏—è —á–∞—Å—Ç–æ—Ç—ã"""
        self.log(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤—ã–±—Ä–∞–ª —á–∞—Å—Ç–æ—Ç—É: {self.get_current_frequency()}")
        if self.data is not None:
            self.update_frequency_info()

    def get_current_frequency(self):
        """–ü–æ–ª—É—á–∞–µ—Ç —Ç–µ–∫—É—â—É—é –≤—ã–±—Ä–∞–Ω–Ω—É—é —á–∞—Å—Ç–æ—Ç—É"""
        if self.auto_frequency:
            return self.detected_frequency
        else:
            freq_index = self.frequency
            if isinstance(freq_index, int) and 0 <= freq_index < len(self.FREQUENCIES):
                return self.FREQUENCIES[freq_index][0]
            else:
                return self.frequency

    def estimate_points_after_aggregation(self, freq_code):
        """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ—á–µ–∫ –ø–æ—Å–ª–µ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ –ø–æ —á–∞—Å—Ç–æ—Ç–µ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ ID"""
        if self.data is None:
            return {'min_points': 0, 'max_points': 0, 'details': {}}
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –≤—Ä–µ–º–µ–Ω–Ω–∞—è –∫–æ–ª–æ–Ω–∫–∞
        if self.timestamp_column not in self.data.columns:
            return {'min_points': 0, 'max_points': 0, 'details': {}}
        
        try:
            points_by_id = {}
            
            if self.id_column in self.data.columns:
                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π ID –æ—Ç–¥–µ–ª—å–Ω–æ
                unique_ids = self.data[self.id_column].unique()
                
                for uid in unique_ids:
                    id_data = self.data[self.data[self.id_column] == uid].copy()
                    id_data = id_data.sort_values(self.timestamp_column)
                    
                    if len(id_data) == 0:
                        continue
                        
                    start_date = id_data[self.timestamp_column].min()
                    end_date = id_data[self.timestamp_column].max()
                    
                    # –°–æ–∑–¥–∞–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç —Å –Ω—É–∂–Ω–æ–π —á–∞—Å—Ç–æ—Ç–æ–π
                    date_range = pd.date_range(start=start_date, end=end_date, freq=freq_code)
                    estimated_points = len(date_range)
                    
                    # –ü–æ–ª—É—á–∞–µ–º —á–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ ID –µ—Å–ª–∏ –µ—Å—Ç—å –º–∞–ø–ø–∏–Ω–≥
                    display_id = uid
                    if self.id_column in self.categorical_mapping:
                        mapping = self.categorical_mapping[self.id_column]
                        try:
                            id_index = int(float(uid))
                            if 0 <= id_index < len(mapping):
                                display_id = f"{mapping[id_index]} ({uid})"
                        except:
                            pass
                    
                    points_by_id[display_id] = {
                        'points': estimated_points,
                        'start': start_date,
                        'end': end_date,
                        'original_records': len(id_data)
                    }
            else:
                # –ï—Å–ª–∏ –Ω–µ—Ç ID –∫–æ–ª–æ–Ω–∫–∏, –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –∫–∞–∫ –æ–¥–∏–Ω —Ä—è–¥
                sample_data = self.data.copy().sort_values(self.timestamp_column)
                start_date = sample_data[self.timestamp_column].min()
                end_date = sample_data[self.timestamp_column].max()
                date_range = pd.date_range(start=start_date, end=end_date, freq=freq_code)
                estimated_points = len(date_range)
                
                points_by_id['–ï–¥–∏–Ω—ã–π —Ä—è–¥'] = {
                    'points': estimated_points,
                    'start': start_date,
                    'end': end_date,
                    'original_records': len(sample_data)
                }
            
            if not points_by_id:
                return {'min_points': 0, 'max_points': 0, 'details': {}}
            
            all_points = [info['points'] for info in points_by_id.values()]
            result = {
                'min_points': min(all_points),
                'max_points': max(all_points),
                'details': points_by_id
            }
            
            return result
            
        except Exception as e:
            self.log(f"–û—à–∏–±–∫–∞ –æ—Ü–µ–Ω–∫–∏ —Ç–æ—á–µ–∫ –¥–ª—è —á–∞—Å—Ç–æ—Ç—ã {freq_code}: {str(e)}")
            # –ó–∞–ø–∞—Å–Ω–æ–π —Ä–∞—Å—á–µ—Ç
            freq_ratios = {
                'T': self.data_length,           
                'H': self.data_length // 60,     
                'D': self.data_length,           
                'B': int(self.data_length * 0.7), 
                'W': self.data_length // 7,     
                'M': self.data_length // 30,    
                'Q': self.data_length // 90,    
                'Y': self.data_length // 365    
            }
            fallback_points = max(1, freq_ratios.get(freq_code, self.data_length // 30))
            return {'min_points': fallback_points, 'max_points': fallback_points, 'details': {}}

    def update_frequency_info(self):
        # –æ—á–∏—â–∞–µ–º –ø—É–ª –æ—à–∏–±–æ–∫
        self.clear_messages()
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —á–∞—Å—Ç–æ—Ç–µ –ë–ï–ó –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ - —Ç–æ–ª—å–∫–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ"""
        if self.data_length == 0:
            return
            
        # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â—É—é —á–∞—Å—Ç–æ—Ç—É
        current_freq = self.get_current_frequency()
        
        # –û—Ü–µ–Ω–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ—á–µ–∫ –ø–æ—Å–ª–µ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ –¥–ª—è –≤—Å–µ—Ö ID
        aggregation_info = self.estimate_points_after_aggregation(current_freq)
        min_points = aggregation_info['min_points']
        max_points = aggregation_info['max_points']
        details = aggregation_info['details']
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤
        num_series = len(details) if details else 1
        
        # –ü–æ–ª—É—á–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ —á–∞—Å—Ç–æ—Ç—ã
        freq_name = current_freq
        for code, label in self.FREQUENCIES:
            if code == current_freq:
                freq_name = f"{label} ({code})"
                break
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        if details:
            details_text = []
            for id_name, info in details.items():
                details_text.append(f"{id_name}: {info['points']} —Ç–æ—á–µ–∫")
            details_str = " | ".join(details_text[:3])  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3
            if len(details) > 3:
                details_str += f" | –∏ –µ—â–µ {len(details)-3}..."
        else:
            details_str = f"~{min_points} —Ç–æ—á–µ–∫"
        """
        # –û—Ü–µ–Ω–∫–∞ –≤–æ–∑–º–æ–∂–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º
        likely_problems = []
        if min_points < 10:
            likely_problems.append("–û—á–µ–Ω—å –º–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
        if min_points < self.prediction_length + 5:
            likely_problems.append("–ú–æ–∂–µ—Ç –Ω–µ —Ö–≤–∞—Ç–∏—Ç—å –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–π –¥–ª–∏–Ω—ã –ø—Ä–æ–≥–Ω–æ–∑–∞")
        """
        
        # –û—Ü–µ–Ω–∫–∞ –≤–æ–∑–º–æ–∂–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º —Å —Ü–≤–µ—Ç–æ–≤–æ–π –∏–Ω–¥–∏–∫–∞—Ü–∏–µ–π
        likely_problems = []
        if min_points < 10:
            likely_problems.append("–û—á–µ–Ω—å –º–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")

        # –ß–µ—Ç—ã—Ä–µ—Ö—É—Ä–æ–≤–Ω–µ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π
        if self.prediction_length >= min_points:
            likely_problems.append("üî¥ –ö–†–ò–¢–ò–ß–ù–û: –ü—Ä–æ–≥–Ω–æ–∑ –±–æ–ª—å—à–µ –∏–ª–∏ —Ä–∞–≤–µ–Ω –¥–∞–Ω–Ω—ã–º!")
        elif self.prediction_length > min_points * 0.6:  # –ë–æ–ª—å—à–µ 60%
            likely_problems.append("üü† –†–ò–°–ö–û–í–ê–ù–ù–û: –ü—Ä–æ–≥–Ω–æ–∑ –±–æ–ª—å—à–µ 60% –æ—Ç –¥–∞–Ω–Ω—ã—Ö")
        elif self.prediction_length > min_points * 0.4:  # –ë–æ–ª—å—à–µ 40%
            likely_problems.append("üü° –û–°–¢–û–†–û–ñ–ù–û: –ü—Ä–æ–≥–Ω–æ–∑ –±–æ–ª—å—à–µ 40% –æ—Ç –¥–∞–Ω–Ω—ã—Ö")
        # –ï—Å–ª–∏ –º–µ–Ω—å—à–µ 40% - –≤—Å–µ —Ö–æ—Ä–æ—à–æ, –Ω–∏—á–µ–≥–æ –Ω–µ –¥–æ–±–∞–≤–ª—è–µ–º

        # –û–±–Ω–æ–≤–ª—è–µ–º –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ —Å –ò–ù–§–û–†–ú–ê–¶–ò–ï–ô
        if min_points == max_points:
            points_info = f"{min_points} —Ç–æ—á–µ–∫"
        else:
            points_info = f"{min_points}-{max_points} —Ç–æ—á–µ–∫"
        
        info_text = f"–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —á–∞—Å—Ç–æ—Ç–µ: {freq_name}\n"
        info_text += f"–ü–æ—Å–ª–µ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏: {points_info} ({num_series} —Ä—è–¥–æ–≤)\n"
        info_text += f"{details_str}"
        
        if likely_problems:
            info_text += f"\n‚ö†Ô∏è –í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã: {', '.join(likely_problems)}"
            info_text += f"\nüí° AutoGluon —Å–∞–º –ø—Ä–æ–≤–µ—Ä–∏—Ç —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ"
            style = "color: orange; background-color: #fff7e6; padding: 5px; border-radius: 3px;"
        else:
            info_text += f"\n‚úÖ –î–∞–Ω–Ω—ã–µ –≤—ã–≥–ª—è–¥—è—Ç —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–º–∏ —Å –≤—ã–±—Ä–∞–Ω–Ω–æ–π —á–∞—Å—Ç–æ—Ç–æ–π"
            style = "color: green; background-color: #f0fff0; padding: 5px; border-radius: 3px;"
        
        self.max_length_label.setText(info_text)
        self.max_length_label.setStyleSheet(style)
        
        # –õ–æ–≥–∏—Ä—É–µ–º –ø–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏
        self.log(f"–ß–∞—Å—Ç–æ—Ç–∞: {current_freq}, —Ä—è–¥–æ–≤: {num_series}, —Ç–æ—á–µ–∫: {min_points}-{max_points}")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –¥—Ä—É–≥–∏—Ö –º–µ—Ç–æ–¥–∞—Ö
        self.min_points_current = min_points


    def on_target_column_changed(self):
        self.log(f"–í—ã –≤—ã–±—Ä–∞–ª–∏ —Ü–µ–ª–µ–≤—É—é –∫–æ–ª–æ–Ω–∫—É: {self.target_column}")
    def on_id_column_changed(self):
        self.log(f"–í—ã –≤—ã–±—Ä–∞–ª–∏ ID –∫–æ–ª–æ–Ω–∫—É: {self.id_column}")
        self.log(f"DEBUG: self.data is None = {self.data is None}")  # ‚Üê –î–û–ë–ê–í–ò–¢–¨
        if self.data is not None:
            self.log("DEBUG: –í—ã–∑—ã–≤–∞—é update_frequency_info()")  # ‚Üê –î–û–ë–ê–í–ò–¢–¨
            self.update_frequency_info()
        else:
            self.log("DEBUG: self.data —Ä–∞–≤–Ω–æ None, –ø—Ä–æ–ø—É—Å–∫–∞—é –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ")  # ‚Üê –î–û–ë–ê–í–ò–¢–¨
    def on_timestamp_column_changed(self):
        self.log(f"–í—ã –≤—ã–±—Ä–∞–ª–∏ –≤—Ä–µ–º–µ–Ω–Ω—É—é –∫–æ–ª–æ–Ω–∫—É: {self.timestamp_column}")

    def on_holidays_changed(self, state):
        self.include_holidays = state > 0
        self.holiday_country_combo.setEnabled(self.include_holidays) # –í–∫–ª—é—á–∞–µ–º/–æ—Ç–∫–ª—é—á–∞–µ–º –≤—ã–±–æ—Ä —Å—Ç—Ä–∞–Ω—ã

    """def on_date_option_changed(self, state):
        self.use_current_date = state > 0"""
        
    def on_auto_frequency_changed(self, state):
        self.auto_frequency = state > 0
        self.freq_combo.setDisabled(self.auto_frequency)
        if self.data is not None:
            if self.auto_frequency:
                self.detected_freq_label.setText(f"–û–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–∞—è —á–∞—Å—Ç–æ—Ç–∞: {self.detected_frequency}")
            self.update_frequency_info()

    def on_prediction_length_changed(self, value):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –ø—Ä–æ–≤–µ—Ä–∫—É –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ –¥–ª–∏–Ω—ã –ø—Ä–æ–≥–Ω–æ–∑–∞"""
        if self.data is not None:
            self.check_prediction_length()

    def detect_frequency(self, data):
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —á–∞—Å—Ç–æ—Ç—É –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö"""
        try:
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –¥–∞—Ç—ã
            dates = data[self.timestamp_column].sort_values()
            
            # –ï—Å–ª–∏ –º–µ–Ω—å—à–µ 2 —Ç–æ—á–µ–∫, –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å
            if len(dates) < 2:
                return "D"  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–µ–Ω—å
                
            # –í—ã—á–∏—Å–ª—è–µ–º —Ä–∞–∑–Ω–∏—Ü—É –º–µ–∂–¥—É –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–º–∏ –¥–∞—Ç–∞–º–∏
            diffs = []
            for i in range(1, min(10, len(dates))):
                diff = dates.iloc[i] - dates.iloc[i-1]
                diffs.append(diff.total_seconds())
                
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–µ–¥–∏–∞–Ω—É –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–∏—á–Ω–æ–≥–æ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞
            if not diffs:
                return "D"
                
            median_diff = pd.Series(diffs).median()
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —á–∞—Å—Ç–æ—Ç—É –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞
            if median_diff <= 60:  # –¥–æ 1 –º–∏–Ω—É—Ç—ã
                freq = "T"
            elif median_diff <= 3600:  # –¥–æ 1 —á–∞—Å–∞
                freq = "H"
            elif median_diff <= 86400:  # –¥–æ 1 –¥–Ω—è
                freq = "D"
            elif median_diff <= 604800:  # –¥–æ 1 –Ω–µ–¥–µ–ª–∏
                freq = "W"
            elif median_diff <= 2678400:  # –¥–æ ~1 –º–µ—Å—è—Ü–∞ (31 –¥–µ–Ω—å)
                freq = "M"
            elif median_diff <= 7948800:  # –¥–æ ~3 –º–µ—Å—è—Ü–µ–≤ (92 –¥–Ω—è)
                freq = "Q"
            else:  # –±–æ–ª–µ–µ 3 –º–µ—Å—è—Ü–µ–≤
                freq = "Y"
                
            self.log(f"–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ —á–∞—Å—Ç–æ—Ç–∞ –¥–∞–Ω–Ω—ã—Ö: {freq} (–º–µ–¥–∏–∞–Ω–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª: {median_diff/3600:.1f} —á–∞—Å–æ–≤)")
            return freq
            
        except Exception as e:
            self.log(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ —á–∞—Å—Ç–æ—Ç—ã: {str(e)}")
            return "D"  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–µ–Ω—å

    def check_prediction_length(self):
        # –æ—á–∏—â–∞–µ–º –ø—É–ª –æ—à–∏–±–æ–∫
        self.clear_messages() 
        """–ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª–∏–Ω—ã –ø—Ä–æ–≥–Ω–æ–∑–∞ –±–µ–∑ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–π –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏"""
        if self.data_length == 0:
            self.max_allowed_prediction = 365  # –ë–æ–ª—å—à–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            self.max_length_label.setText("–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –ø—Ä–æ–≥–Ω–æ–∑–∞: –ù/–î (–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö)")
            return
        
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ä–∞–∑—É–º–Ω—ã–µ –ª–∏–º–∏—Ç—ã, –Ω–æ –ù–ï –±–ª–æ–∫–∏—Ä—É–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        reasonable_limits = {
            'Y': 10,   # –ù–µ –±–æ–ª–µ–µ 10 –ª–µ—Ç
            'Q': 20,   # –ù–µ –±–æ–ª–µ–µ 20 –∫–≤–∞—Ä—Ç–∞–ª–æ–≤
            'M': 36,   # –ù–µ –±–æ–ª–µ–µ 36 –º–µ—Å—è—Ü–µ–≤
            'W': 104,  # –ù–µ –±–æ–ª–µ–µ 2 –ª–µ—Ç –Ω–µ–¥–µ–ª—å
            'D': 365,  # –ù–µ –±–æ–ª–µ–µ –≥–æ–¥–∞ –¥–Ω–µ–π
            'B': 260,  # –ù–µ –±–æ–ª–µ–µ –≥–æ–¥–∞ —Ä–∞–±–æ—á–∏—Ö –¥–Ω–µ–π
            'H': 8760, # –ù–µ –±–æ–ª–µ–µ –≥–æ–¥–∞ —á–∞—Å–æ–≤
            'T': 525600 # –ù–µ –±–æ–ª–µ–µ –≥–æ–¥–∞ –º–∏–Ω—É—Ç
        }
        
        current_freq = self.get_current_frequency()
        self.max_allowed_prediction = reasonable_limits.get(current_freq, 100)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —á–∞—Å—Ç–æ—Ç–µ
        self.update_frequency_info()
        
        # –ù–ï –±–ª–æ–∫–∏—Ä—É–µ–º –∫–Ω–æ–ø–∫—É - –ø–æ–∑–≤–æ–ª—è–µ–º AutoGluon —Ä–µ—à–∞—Ç—å!
        self.run_button.setDisabled(False)
        
        """
        # –¢–æ–ª—å–∫–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ–µ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –ø—Ä–∏ –æ—á–µ–Ω—å –±–æ–ª—å—à–∏—Ö –∑–Ω–∞—á–µ–Ω–∏—è—Ö
        if self.prediction_length > self.max_allowed_prediction:
            self.warning(f"–î–ª–∏–Ω–∞ –ø—Ä–æ–≥–Ω–æ–∑–∞ ({self.prediction_length}) –∫–∞–∂–µ—Ç—Å—è –æ—á–µ–Ω—å –±–æ–ª—å—à–æ–π –¥–ª—è —á–∞—Å—Ç–æ—Ç—ã {current_freq}. "
                        f"AutoGluon –º–æ–∂–µ—Ç –≤—ã–¥–∞—Ç—å –æ—à–∏–±–∫—É –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏.")
        else:
            self.warning("")
        """
        # –ü–æ–ª—É—á–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ—á–µ–∫ –¥–ª—è —Ç–µ–∫—É—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö
        if hasattr(self, 'min_points_current') and self.min_points_current:
            min_points = self.min_points_current
            
            if self.prediction_length >= min_points:
                self.error(f"üî¥ –ü—Ä–æ–≥–Ω–æ–∑ ({self.prediction_length}) –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö ({min_points})!")
                return
            elif self.prediction_length > min_points * 0.6:
                self.warning(f"üü† –ü—Ä–æ–≥–Ω–æ–∑ ({self.prediction_length}) —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç {self.prediction_length/min_points*100:.0f}% –æ—Ç –¥–∞–Ω–Ω—ã—Ö")
                return

        if self.prediction_length > self.max_allowed_prediction:
            self.warning(f"–î–ª–∏–Ω–∞ –ø—Ä–æ–≥–Ω–æ–∑–∞ ({self.prediction_length}) –∫–∞–∂–µ—Ç—Å—è –æ—á–µ–Ω—å –±–æ–ª—å—à–æ–π...")

    def log(self, message):
        """–ù–∞–¥–µ–∂–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ"""
        log_entry = f"{datetime.now().strftime('%H:%M:%S')} - {message}"
        self.log_messages += log_entry + "\n"
        self.log_widget.appendPlainText(log_entry)
        self.log_widget.verticalScrollBar().setValue(
            self.log_widget.verticalScrollBar().maximum()
        )
        QCoreApplication.processEvents()

    @Inputs.data
    def set_data(self, dataset):
        self.error("")
        self.warning("")
        try:
            if dataset is None:
                self.data = None
                self.log("–î–∞–Ω–Ω—ã–µ –æ—á–∏—â–µ–Ω—ã")
                self.data_length = 0
                self.max_length_label.setText("–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –ø—Ä–æ–≥–Ω–æ–∑–∞: N/A")
                self.detected_freq_label.setText("–û–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–∞—è —á–∞—Å—Ç–æ—Ç–∞: N/A")
                return
            
            # –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê: –ß—Ç–æ –∏–º–µ–Ω–Ω–æ –ø—Ä–∏—Ö–æ–¥–∏—Ç –æ—Ç FormTimeseries
            self.log("=== –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –í–•–û–î–ù–´–• –î–ê–ù–ù–´–• ===")
            self.log(f"–¢–∏–ø dataset: {type(dataset)}")
            self.log(f"–†–∞–∑–º–µ—Ä dataset: {dataset.X.shape if hasattr(dataset, 'X') else 'N/A'}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ–º–µ–Ω
            domain = dataset.domain
            self.log(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞—Ç—Ä–∏–±—É—Ç–æ–≤: {len(domain.attributes)}")
            self.log(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–µ—Ç–∞: {len(domain.metas)}")
            self.log(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤: {len(domain.class_vars) if domain.class_vars else 0}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
            all_vars = list(domain.attributes) + list(domain.metas) + (list(domain.class_vars) if domain.class_vars else [])
            for var in all_vars:
                self.log(f"–ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è '{var.name}': —Ç–∏–ø {type(var).__name__}")
                if isinstance(var, TimeVariable):
                    self.log(f"  TimeVariable –Ω–∞–π–¥–µ–Ω–∞: {var.name}")
            
            # –ü–æ–ª—É—á–∞–µ–º —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
            temp_df = self.prepare_data(dataset, for_type_check_only=True)
            if temp_df is not None and len(temp_df) > 0:
                self.log("=== –û–ë–†–ê–ó–ï–¶ –°–´–†–´–• –î–ê–ù–ù–´–• ===")
                for col in temp_df.columns:
                    sample_vals = temp_df[col].head(3).tolist()
                    self.log(f"–ö–æ–ª–æ–Ω–∫–∞ '{col}' ({temp_df[col].dtype}): {sample_vals}")
                    
                    # –û—Å–æ–±–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
                    if 'date' in col.lower() or 'time' in col.lower():
                        if pd.api.types.is_numeric_dtype(temp_df[col]):
                            min_val, max_val = temp_df[col].min(), temp_df[col].max()
                            self.log(f"  –ß–∏—Å–ª–æ–≤–æ–π –¥–∏–∞–ø–∞–∑–æ–Ω: {min_val} - {max_val}")
                            
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –ø–æ—Ö–æ–∂–µ –ª–∏ –Ω–∞ timestamp
                            if min_val > 1e9:  # –ë–æ–ª—å—à–µ –º–∏–ª–ª–∏–∞—Ä–¥–∞ - –≤–µ—Ä–æ—è—Ç–Ω–æ timestamp
                                sample_timestamp = pd.to_datetime(min_val, unit='s', errors='ignore')
                                self.log(f"  –ö–∞–∫ timestamp (—Å–µ–∫): {sample_timestamp}")
                                sample_timestamp_ms = pd.to_datetime(min_val, unit='ms', errors='ignore')
                                self.log(f"  –ö–∞–∫ timestamp (–º—Å): {sample_timestamp_ms}")
            
            self.log("=== –ö–û–ù–ï–¶ –î–ò–ê–ì–ù–û–°–¢–ò–ö–ò ===")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö –∞—Ç—Ä–∏–±—É—Ç–æ–≤ –æ—Ç FormTimeseries
            self.from_form_timeseries = False  # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Ñ–ª–∞–≥
            if hasattr(dataset, 'from_form_timeseries') and dataset.from_form_timeseries:
                self.from_form_timeseries = True
                self.log("–î–∞–Ω–Ω—ã–µ –ø–æ–ª—É—á–µ–Ω—ã –∏–∑ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ FormTimeseries")
                # –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –æ—Ç FormTimeseries, –º–æ–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
                if hasattr(dataset, 'time_variable') and dataset.time_variable:
                    self.timestamp_column = dataset.time_variable
                    self.log(f"–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –≤—Ä–µ–º–µ–Ω–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è: {self.timestamp_column}")
            
            # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏ –∏–∑ dataset –î–û prepare_data
            domain = dataset.domain
            attr_cols = [var.name for var in domain.attributes]
            meta_cols = [var.name for var in domain.metas]
            class_cols = [var.name for var in domain.class_vars] if domain.class_vars else []
            self.all_columns = attr_cols + class_cols + meta_cols
            
            # –ù–∞—Ö–æ–¥–∏–º –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –º–∞–ø–ø–∏–Ω–≥–∏
            self.categorical_mapping = {}  # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–µ –º–∞–ø–ø–∏–Ω–≥–∏
            for var in domain.variables + domain.metas:
                if hasattr(var, 'values') and var.values:
                    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –∑–Ω–∞—á–µ–Ω–∏–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
                    values = var.values
                    if values:
                        self.log(f"–°–æ—Ö—Ä–∞–Ω—è–µ–º –º–∞–ø–ø–∏–Ω–≥ –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π '{var.name}': {values}")
                        self.categorical_mapping[var.name] = values

            # –î–û–ë–ê–í–õ–ï–ù–û: –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ TimeVariable
            time_vars = []
            for var in domain.variables + domain.metas:
                if isinstance(var, TimeVariable):
                    time_vars.append(var.name)
            
            if time_vars:
                self.log(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ: {', '.join(time_vars)}")
                if self.timestamp_column not in time_vars:
                    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–±–∏—Ä–∞–µ–º –ø–µ—Ä–≤—É—é –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é
                    self.timestamp_column = time_vars[0]
                    self.log(f"–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–±—Ä–∞–Ω–∞ –≤—Ä–µ–º–µ–Ω–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è (TimeVariable –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é): {self.timestamp_column}")
            
            if not self.all_columns:
                raise ValueError("–ù–µ—Ç –∫–æ–ª–æ–Ω–æ–∫ –≤ –¥–∞–Ω–Ω—ã—Ö!")
            
            # --- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–æ–≤ ---
            # –ü—ã—Ç–∞–µ–º—Å—è –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å, —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Ç–µ–∫—É—â–∏–π –≤—ã–±–æ—Ä –Ω–µ–≤–∞–ª–∏–¥–µ–Ω –∏–ª–∏ –Ω–µ —Å–¥–µ–ª–∞–Ω
            
            # –ü–æ–ª—É—á–∞–µ–º DataFrame –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ç–∏–ø–æ–≤, –µ—Å–ª–∏ –µ—â–µ –Ω–µ —Å–æ–∑–¥–∞–Ω
            temp_df_for_types = None
            if not isinstance(dataset, pd.DataFrame): # –ï—Å–ª–∏ –Ω–∞ –≤—Ö–æ–¥ –ø—Ä–∏—à–µ–ª Orange.data.Table
                temp_df_for_types = self.prepare_data(dataset, for_type_check_only=True)
            else: # –ï—Å–ª–∏ –Ω–∞ –≤—Ö–æ–¥ —É–∂–µ –ø—Ä–∏—à–µ–ª DataFrame (–º–∞–ª–æ–≤–µ—Ä–æ—è—Ç–Ω–æ –¥–ª—è set_data, –Ω–æ –¥–ª—è –ø–æ–ª–Ω–æ—Ç—ã)
                temp_df_for_types = dataset

            # –¶–µ–ª–µ–≤–æ–π —Å—Ç–æ–ª–±–µ—Ü
            if not self.target_column or self.target_column not in self.all_columns:
                self.log(f"–¶–µ–ª–µ–≤–æ–π —Å—Ç–æ–ª–±–µ—Ü '{self.target_column}' –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∏–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Ç–µ–∫—É—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö. –ü–æ–ø—ã—Ç–∫–∞ –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è...")
                potential_target = None
                
                # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º Orange Class Variable
                if domain.class_vars:
                    for cv in domain.class_vars:
                        if isinstance(cv, ContinuousVariable) or \
                        (temp_df_for_types is not None and cv.name in temp_df_for_types.columns and pd.api.types.is_numeric_dtype(temp_df_for_types[cv.name])):
                            potential_target = cv.name
                            self.log(f"–ù–∞–π–¥–µ–Ω–∞ —Ü–µ–ª–µ–≤–∞—è –∫–æ–ª–æ–Ω–∫–∞ –∏–∑ Orange Class Variable: '{potential_target}'")
                            break
                
                if not potential_target:
                    # 2. –ò—â–µ–º –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–º —Ç–æ—á–Ω—ã–º –∏–º–µ–Ω–∞–º
                    priority_names = ["Target", "target", "sales", "Sales", "value", "Value"]
                    for name in priority_names:
                        if name in self.all_columns and \
                        (temp_df_for_types is not None and name in temp_df_for_types.columns and pd.api.types.is_numeric_dtype(temp_df_for_types[name])):
                            potential_target = name
                            self.log(f"–ù–∞–π–¥–µ–Ω–∞ —Ü–µ–ª–µ–≤–∞—è –∫–æ–ª–æ–Ω–∫–∞ –ø–æ —Ç–æ—á–Ω–æ–º—É –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω–æ–º—É –∏–º–µ–Ω–∏: '{potential_target}'")
                            break
                
                if not potential_target and self.all_columns and temp_df_for_types is not None:
                    # 3. –ò—â–µ–º –ø–æ –ø–æ–¥—Å—Ç—Ä–æ–∫–∞–º (—á–∏—Å–ª–æ–≤—ã–µ)
                    search_terms = ["target", "sales", "value"]
                    for term in search_terms:
                        for col_name in self.all_columns:
                            if term in col_name.lower() and col_name in temp_df_for_types.columns and \
                            pd.api.types.is_numeric_dtype(temp_df_for_types[col_name]):
                                potential_target = col_name
                                self.log(f"–ù–∞–π–¥–µ–Ω–∞ —Ü–µ–ª–µ–≤–∞—è –∫–æ–ª–æ–Ω–∫–∞ –ø–æ –ø–æ–¥—Å—Ç—Ä–æ–∫–µ '{term}': '{potential_target}' (—á–∏—Å–ª–æ–≤–∞—è)")
                                break
                        if potential_target: break

                if not potential_target and self.all_columns and temp_df_for_types is not None:
                    # 4. –ë–µ—Ä–µ–º –ø–µ—Ä–≤—É—é —á–∏—Å–ª–æ–≤—É—é Orange ContinuousVariable, –Ω–µ —è–≤–ª—è—é—â—É—é—Å—è ID –∏–ª–∏ Timestamp
                    for var in domain.attributes: # –ê—Ç—Ä–∏–±—É—Ç—ã –æ–±—ã—á–Ω–æ —á–∏—Å–ª–æ–≤—ã–µ –∏–ª–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ
                        if isinstance(var, ContinuousVariable) and var.name not in [self.id_column, self.timestamp_column]:
                            potential_target = var.name
                            self.log(f"–í –∫–∞—á–µ—Å—Ç–≤–µ —Ü–µ–ª–µ–≤–æ–π –∫–æ–ª–æ–Ω–∫–∏ –≤—ã–±—Ä–∞–Ω–∞ –ø–µ—Ä–≤–∞—è Orange ContinuousVariable: '{potential_target}'")
                            break
                    if not potential_target: # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —Å—Ä–µ–¥–∏ –∞—Ç—Ä–∏–±—É—Ç–æ–≤, –∏—â–µ–º –ø—Ä–æ—Å—Ç–æ —á–∏—Å–ª–æ–≤—É—é
                        for col in self.all_columns:
                            if col not in [self.id_column, self.timestamp_column] and \
                            col in temp_df_for_types.columns and pd.api.types.is_numeric_dtype(temp_df_for_types[col]):
                                potential_target = col
                                self.log(f"–í –∫–∞—á–µ—Å—Ç–≤–µ —Ü–µ–ª–µ–≤–æ–π –∫–æ–ª–æ–Ω–∫–∏ –≤—ã–±—Ä–∞–Ω–∞ –ø–µ—Ä–≤–∞—è —á–∏—Å–ª–æ–≤–∞—è: '{potential_target}'")
                                break

                self.target_column = potential_target if potential_target else (self.all_columns[0] if self.all_columns else "")
                self.log(f"–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–±—Ä–∞–Ω —Ü–µ–ª–µ–≤–æ–π —Å—Ç–æ–ª–±–µ—Ü: '{self.target_column}'")

            # ID —Å—Ç–æ–ª–±–µ—Ü
            if not self.id_column or self.id_column not in self.all_columns:
                self.log(f"ID —Å—Ç–æ–ª–±–µ—Ü '{self.id_column}' –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∏–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Ç–µ–∫—É—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö. –ü–æ–ø—ã—Ç–∫–∞ –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è...")
                potential_id = None
                # 1. –ò—â–µ–º Orange DiscreteVariable –∏–ª–∏ StringVariable (–Ω–µ —Ü–µ–ª—å –∏ –Ω–µ –≤—Ä–µ–º—è)
                for var_list in [domain.attributes, domain.metas]:
                    for var in var_list:
                        if var.name not in [self.target_column, self.timestamp_column] and \
                        (isinstance(var, DiscreteVariable) or isinstance(var, StringVariable)):
                            potential_id = var.name
                            self.log(f"–ù–∞–π–¥–µ–Ω–∞ ID –∫–æ–ª–æ–Ω–∫–∞ –∏–∑ Orange Discrete/String Variable: '{potential_id}'")
                            break
                    if potential_id: break
                
                if not potential_id:
                    # 2. –ü–æ–∏—Å–∫ –ø–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–º –∏–º–µ–Ω–∞–º
                    potential_id = next((name for name in ["item_id", "id", "ID", "Country", "Shop", "City"] if name in self.all_columns and name not in [self.target_column, self.timestamp_column]), None)
                    if potential_id: self.log(f"–ù–∞–π–¥–µ–Ω–∞ ID –∫–æ–ª–æ–Ω–∫–∞ –ø–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–º—É –∏–º–µ–Ω–∏: '{potential_id}'")

                if not potential_id and self.all_columns and temp_df_for_types is not None:
                    # 3. –ò—â–µ–º –ø–æ–¥—Ö–æ–¥—è—â–∏–π —Ç–∏–ø (—Å—Ç—Ä–æ–∫–∞/–æ–±—ä–µ–∫—Ç/–∫–∞—Ç–µ–≥–æ—Ä–∏—è), –Ω–µ —Ü–µ–ª—å –∏ –Ω–µ –≤—Ä–µ–º—è
                    for col in self.all_columns:
                        if col not in [self.target_column, self.timestamp_column] and col in temp_df_for_types.columns and \
                        (pd.api.types.is_string_dtype(temp_df_for_types[col]) or \
                            pd.api.types.is_object_dtype(temp_df_for_types[col]) or \
                            pd.api.types.is_categorical_dtype(temp_df_for_types[col])):
                            potential_id = col
                            self.log(f"–ù–∞–π–¥–µ–Ω–∞ –ø–æ–¥—Ö–æ–¥—è—â–∞—è –ø–æ —Ç–∏–ø—É ID –∫–æ–ª–æ–Ω–∫–∞: '{potential_id}'")
                            break
                self.id_column = potential_id if potential_id else (next((c for c in self.all_columns if c not in [self.target_column, self.timestamp_column]), self.all_columns[0] if self.all_columns else ""))
                self.log(f"–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–±—Ä–∞–Ω ID —Å—Ç–æ–ª–±–µ—Ü: '{self.id_column}'")

            # –í—Ä–µ–º–µ–Ω–Ω–æ–π —Å—Ç–æ–ª–±–µ—Ü (–µ—Å–ª–∏ –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω –∫–∞–∫ TimeVariable –∏ –Ω–µ–≤–∞–ª–∏–¥–µ–Ω)
            if not self.timestamp_column or self.timestamp_column not in self.all_columns:
                self.log(f"–í—Ä–µ–º–µ–Ω–Ω–æ–π —Å—Ç–æ–ª–±–µ—Ü '{self.timestamp_column}' –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω/–Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è TimeVariable. –ü–æ–ø—ã—Ç–∫–∞ –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è...")
                potential_ts = None
                # 1. Orange TimeVariable —É–∂–µ –¥–æ–ª–∂–µ–Ω –±—ã–ª –±—ã—Ç—å –≤—ã–±—Ä–∞–Ω —Ä–∞–Ω–µ–µ –≤ set_data.
                # –ó–¥–µ—Å—å –º—ã –∏—â–µ–º, –µ—Å–ª–∏ –æ–Ω –Ω–µ –±—ã–ª TimeVariable –∏–ª–∏ —Å—Ç–∞–ª –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–º.
                
                # 2. –ü–æ–∏—Å–∫ –ø–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–º –∏–º–µ–Ω–∞–º
                potential_ts = next((name for name in ["timestamp", "Timestamp", "time", "Time", "Date", "date"] if name in self.all_columns and name not in [self.target_column, self.id_column]), None)
                if potential_ts: self.log(f"–ù–∞–π–¥–µ–Ω–∞ –≤—Ä–µ–º–µ–Ω–Ω–∞—è –∫–æ–ª–æ–Ω–∫–∞ –ø–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–º—É –∏–º–µ–Ω–∏: '{potential_ts}'")

                if not potential_ts and self.all_columns and temp_df_for_types is not None:
                    # 3. –ü—ã—Ç–∞–µ–º—Å—è —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å
                    for col in self.all_columns:
                        if col not in [self.target_column, self.id_column] and col in temp_df_for_types.columns:
                            try:
                                parsed_sample = pd.to_datetime(temp_df_for_types[col].dropna().iloc[:5], errors='coerce')
                                if not parsed_sample.isna().all():
                                    potential_ts = col
                                    self.log(f"–ù–∞–π–¥–µ–Ω–∞ –ø–æ–¥—Ö–æ–¥—è—â–∞—è –ø–æ —Ç–∏–ø—É –≤—Ä–µ–º–µ–Ω–Ω–∞—è –∫–æ–ª–æ–Ω–∫–∞: '{potential_ts}' (–º–æ–∂–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ –¥–∞—Ç—É)")
                                    break
                            except Exception:
                                continue
                self.timestamp_column = potential_ts if potential_ts else (next((c for c in self.all_columns if c not in [self.target_column, self.id_column]), self.all_columns[0] if self.all_columns else ""))
                self.log(f"–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–±—Ä–∞–Ω –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Å—Ç–æ–ª–±–µ—Ü: '{self.timestamp_column}'")
            
            self.log("–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
            self.data = self.prepare_data(dataset)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –≤—ã–ø–∞–¥–∞—é—â–∏–µ —Å–ø–∏—Å–∫–∏ –∫–æ–ª–æ–Ω–æ–∫
            self.target_combo.clear()
            self.id_combo.clear()
            self.timestamp_combo.clear()
            
            self.target_combo.addItems(self.all_columns)
            self.id_combo.addItems(self.all_columns)
            self.timestamp_combo.addItems(self.all_columns)
            
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤—ã–±—Ä–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ comboBox'–∞—Ö
            self.target_combo.setCurrentText(self.target_column)
            self.id_combo.setCurrentText(self.id_column)
            self.timestamp_combo.setCurrentText(self.timestamp_column)
            
            # –õ–æ–≥–∏—Ä—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –≤—ã–±–æ—Ä –∫–æ–ª–æ–Ω–æ–∫ –ø–æ—Å–ª–µ –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è (–µ—Å–ª–∏ –æ–Ω–æ –±—ã–ª–æ) –∏ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –≤ UI
            self.log(f"–ê–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã –∫–æ–ª–æ–Ω–∫–∏ ‚Äî Target: {self.target_column}, ID: {self.id_column}, Timestamp: {self.timestamp_column}")
            
            required = {self.timestamp_column, self.target_column, self.id_column}
            if not required.issubset(set(self.data.columns)):
                missing = required - set(self.data.columns)
                raise ValueError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç —Å—Ç–æ–ª–±—Ü—ã: {missing}")
                
            # –ü–æ–ª—É—á–∞–µ–º –¥–ª–∏–Ω—É –¥–∞–Ω–Ω—ã—Ö
            self.data_length = len(self.data)
            self.log(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {self.data_length} –∑–∞–ø–∏—Å–µ–π")
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —á–∞—Å—Ç–æ—Ç—É –¥–∞–Ω–Ω—ã—Ö
            if pd.api.types.is_datetime64_dtype(self.data[self.timestamp_column]):
                self.detected_frequency = self.detect_frequency(self.data)
                self.detected_freq_label.setText(f"–û–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–∞—è —á–∞—Å—Ç–æ—Ç–∞: {self.detected_frequency}")
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É –ø—Ä–æ–≥–Ω–æ–∑–∞
            self.check_prediction_length()
            
            """
            # –ï—Å–ª–∏ –Ω—É–∂–Ω–æ –∑–∞–º–µ–Ω–∏—Ç—å –¥–∞—Ç—ã –Ω–∞ —Ç–µ–∫—É—â—É—é
            if self.use_current_date and self.timestamp_column in self.data.columns:
                self.log("–ü—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è –∑–∞–º–µ–Ω–∞ –¥–∞—Ç –Ω–∞ –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ")
                
                # –ü–æ–ª—É—á–∞–µ–º —á–∞—Å—Ç–æ—Ç—É
                freq = self.detected_frequency if self.auto_frequency else self.frequency
                
                try:
                    # –°–æ–∑–¥–∞–µ–º –¥–∞—Ç—ã –æ—Ç —Å–µ–≥–æ–¥–Ω—è –Ω–∞–∑–∞–¥ —Å –Ω—É–∂–Ω–æ–π —á–∞—Å—Ç–æ—Ç–æ–π
                    today = pd.Timestamp.now().normalize()
                    dates = pd.date_range(end=today, periods=len(self.data), freq=freq)
                    dates = dates.sort_values()  # –°–æ—Ä—Ç–∏—Ä—É–µ–º –æ—Ç —Ä–∞–Ω–Ω–∏—Ö –∫ –ø–æ–∑–¥–Ω–∏–º
                    
                    # –ó–∞–º–µ–Ω—è–µ–º —Å—Ç–æ–ª–±–µ—Ü –≤—Ä–µ–º–µ–Ω–∏
                    self.data[self.timestamp_column] = dates
                    self.log(f"–î–∞—Ç—ã –∑–∞–º–µ–Ω–µ–Ω—ã: –æ—Ç {dates.min().strftime('%Y-%m-%d')} –¥–æ {dates.max().strftime('%Y-%m-%d')}")
                except Exception as e:
                    self.log(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –¥–∞—Ç —Å —á–∞—Å—Ç–æ—Ç–æ–π {freq}: {str(e)}. –ò—Å–ø–æ–ª—å–∑—É–µ–º –µ–∂–µ–¥–Ω–µ–≤–Ω—É—é —á–∞—Å—Ç–æ—Ç—É.")
                    # –†–µ–∑–µ—Ä–≤–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç - –µ–∂–µ–¥–Ω–µ–≤–Ω–∞—è —á–∞—Å—Ç–æ—Ç–∞
                    dates = pd.date_range(end=pd.Timestamp.now().normalize(), periods=len(self.data), freq='D')
                    self.data[self.timestamp_column] = dates
            """
            
        except Exception as e:
            self.log(f"–û–®–ò–ë–ö–ê: {str(e)}\n{traceback.format_exc()}")
            self.error(f"–û—à–∏–±–∫–∞ –¥–∞–Ω–Ω—ã—Ö: {str(e)}")
            self.data = None
            self.data_length = 0
            self.max_length_label.setText("–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –ø—Ä–æ–≥–Ω–æ–∑–∞: N/A")

    def prepare_data(self, table, for_type_check_only=False):
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö"""
        self.log(f"prepare_data –≤—ã–∑–≤–∞–Ω–∞: for_type_check_only={for_type_check_only}")
        
        if table is None:
            return None

        domain = table.domain
        # –ü–æ–ª—É—á–∞–µ–º –∞—Ç—Ä–∏–±—É—Ç—ã
        attr_cols = [var.name for var in domain.attributes]
        df = pd.DataFrame(table.X, columns=attr_cols)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–ª–∞—Å—Å—ã, –µ—Å–ª–∏ –µ—Å—Ç—å
        if domain.class_vars:
            class_cols = [var.name for var in domain.class_vars]
            class_data = table.Y
            if len(domain.class_vars) == 1:
                class_data = class_data.reshape(-1, 1)
            df_class = pd.DataFrame(class_data, columns=class_cols)
            df = pd.concat([df, df_class], axis=1)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞-–∞—Ç—Ä–∏–±—É—Ç—ã
        if domain.metas:
            meta_cols = [var.name for var in domain.metas]
            meta_data = table.metas
            df_meta = pd.DataFrame(meta_data, columns=meta_cols)
            df = pd.concat([df, df_meta], axis=1)
        
        if for_type_check_only:
            return df

        # –ü–†–û–°–¢–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê –ë–ï–ó –ü–†–û–í–ï–†–û–ö "–ö–û–†–†–ï–ö–¢–ù–û–°–¢–ò"
        self.log("–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
        
        # 1. –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–ª–æ–Ω–∫–∏ –≤—Ä–µ–º–µ–Ω–∏
        if self.timestamp_column and self.timestamp_column in df.columns:
            if not pd.api.types.is_datetime64_dtype(df[self.timestamp_column]):
                try:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ, —á—Ç–æ–±—ã –ø–æ–Ω—è—Ç—å —Ñ–æ—Ä–º–∞—Ç
                    first_value = df[self.timestamp_column].iloc[0] if len(df) > 0 else None
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –ø–µ—Ä–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —á–∏—Å–ª–æ–º (–¥–∞–∂–µ –µ—Å–ª–∏ dtype=object)
                    if first_value is not None:
                        try:
                            float_val = float(first_value)
                            if float_val > 1e9:  # –ü–æ—Ö–æ–∂–µ –Ω–∞ Unix timestamp
                                df[self.timestamp_column] = pd.to_datetime(df[self.timestamp_column].astype(float), unit='s')
                                self.log("‚úÖ –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω—ã Unix timestamps –≤ –¥–∞—Ç—ã (–∏–∑ object dtype)")
                            else:
                                df[self.timestamp_column] = pd.to_datetime(df[self.timestamp_column])
                                self.log("‚úÖ –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω—ã —á–∏—Å–ª–æ–≤—ã–µ –¥–∞—Ç—ã")
                        except (ValueError, TypeError):
                            # –≠—Ç–æ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ —Å—Ç—Ä–æ–∫–∏
                            df[self.timestamp_column] = pd.to_datetime(df[self.timestamp_column])
                            self.log("‚úÖ –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω—ã —Å—Ç—Ä–æ–∫–æ–≤—ã–µ –¥–∞—Ç—ã")
                    else:
                        df[self.timestamp_column] = pd.to_datetime(df[self.timestamp_column])
                        self.log("‚úÖ –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω—ã –¥–∞—Ç—ã")
                        
                    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —á—Ç–æ –ø–æ–ª—É—á–∏–ª–æ—Å—å
                    self.log(f"–î–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç: {df[self.timestamp_column].min()} - {df[self.timestamp_column].max()}")
                    if self.id_column in df.columns:
                        for country in df[self.id_column].unique()[:3]:
                            country_data = df[df[self.id_column] == country]
                            self.log(f"  {country}: {len(country_data)} –∑–∞–ø–∏—Å–µ–π, "
                                f"{country_data[self.timestamp_column].min()} - "
                                f"{country_data[self.timestamp_column].max()}")
                            
                except Exception as e:
                    self.log(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –¥–∞—Ç—ã: {str(e)}")
                    self.log("–°–æ–∑–¥–∞–µ–º –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–µ –¥–∞—Ç—ã –∫–∞–∫ –∑–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç")
                    df = self.create_reasonable_dates(df)
        
        # 2. –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ü–µ–ª–µ–≤–æ–π –∫–æ–ª–æ–Ω–∫–∏
        if self.target_column and self.target_column in df.columns:
            df[self.target_column] = pd.to_numeric(df[self.target_column], errors="coerce")
            self.log(f"Target –∫–æ–ª–æ–Ω–∫–∞: {df[self.target_column].dtype}")

        # 3. –û–±—Ä–∞–±–æ—Ç–∫–∞ ID –∫–æ–ª–æ–Ω–∫–∏
        if self.id_column and self.id_column in df.columns:
            df[self.id_column] = df[self.id_column].astype(str)
            self.log(f"ID –∫–æ–ª–æ–Ω–∫–∞: {df[self.id_column].dtype}")
        
        # 4. –£–¥–∞–ª—è–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
        cols_to_check = [col for col in [self.timestamp_column, self.target_column, self.id_column] 
                        if col and col in df.columns]
        if cols_to_check:
            df = df.dropna(subset=cols_to_check)
        
        self.log(f"–ò—Ç–æ–≥–æ: {len(df)} –∑–∞–ø–∏—Å–µ–π")
        return df

    def create_reasonable_dates(self, df):
        """–°–æ–∑–¥–∞–µ—Ç —Ä–∞–∑—É–º–Ω—ã–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–µ –¥–∞—Ç—ã –¥–ª—è –∫–∞–∂–¥–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏"""
        self.log("–°–æ–∑–¥–∞–Ω–∏–µ —Ä–∞–∑—É–º–Ω—ã—Ö –¥–∞—Ç –¥–ª—è –∫–∞–∂–¥–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏...")
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å ID –∫–æ–ª–æ–Ω–∫–∞, —Å–æ–∑–¥–∞–µ–º –¥–∞—Ç—ã –¥–ª—è –∫–∞–∂–¥–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –æ—Ç–¥–µ–ª—å–Ω–æ
        if self.id_column and self.id_column in df.columns:
            df_list = []
            start_date = pd.Timestamp('2023-01-01')
            
            for id_val in df[self.id_column].unique():
                id_data = df[df[self.id_column] == id_val].copy()
                num_records = len(id_data)
                
                # –°–æ–∑–¥–∞–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–µ –¥–∞—Ç—ã –¥–ª—è —ç—Ç–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
                dates = pd.date_range(start=start_date, periods=num_records, freq='D')
                id_data[self.timestamp_column] = dates
                
                df_list.append(id_data)
                
                # –°–ª–µ–¥—É—é—â–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è –ø–æ—Å–ª–µ –æ–∫–æ–Ω—á–∞–Ω–∏—è –ø—Ä–µ–¥—ã–¥—É—â–µ–π
                start_date = dates[-1] + pd.Timedelta(days=1)
                
                self.log(f"–ö–∞—Ç–µ–≥–æ—Ä–∏—è {id_val}: {num_records} –¥–∞—Ç –æ—Ç {dates[0].date()} –¥–æ {dates[-1].date()}")
            
            return pd.concat(df_list, ignore_index=True)
        else:
            # –ï—Å–ª–∏ –Ω–µ—Ç ID –∫–æ–ª–æ–Ω–∫–∏, —Å–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç—É—é –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å
            start_date = pd.Timestamp('2023-01-01')
            dates = pd.date_range(start=start_date, periods=len(df), freq='D')
            df[self.timestamp_column] = dates
            self.log(f"–°–æ–∑–¥–∞–Ω–∞ –µ–¥–∏–Ω–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –¥–∞—Ç –æ—Ç {dates[0].date()} –¥–æ {dates[-1].date()}")
            return df

    def create_future_dates(self, periods):
        """–°–æ–∑–¥–∞–µ—Ç –±—É–¥—É—â–∏–µ –¥–∞—Ç—ã —Å —É—á–µ—Ç–æ–º –Ω—É–∂–Ω–æ–π —á–∞—Å—Ç–æ—Ç—ã"""
        """
        # ‚úÖ –í—ã–±–æ—Ä —Å—Ç–∞—Ä—Ç–æ–≤–æ–π –¥–∞—Ç—ã
        if self.use_current_date:
            last_date = pd.Timestamp.now().normalize()
            self.log("–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–µ–∫—É—â–∞—è –¥–∞—Ç–∞ –¥–ª—è —Å—Ç–∞—Ä—Ç–∞ –ø—Ä–æ–≥–Ω–æ–∑–∞")
        else:
        """
        # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –¥–∞—Ç—É –∏–∑ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞
        try:
            self.log(f"DEBUG create_future_dates: self.data[{self.timestamp_column}].dtype = {self.data[self.timestamp_column].dtype}")
            self.log(f"DEBUG create_future_dates: –ø–æ—Å–ª–µ–¥–Ω–∏–µ –¥–∞—Ç—ã = \n{self.data[self.timestamp_column].tail().to_string()}")
            
            # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –¥–∞–Ω–Ω—ã–µ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –ø–æ –¥–∞—Ç–µ
            if not self.data[self.timestamp_column].is_monotonic_increasing:
                self.log("–î–∞–Ω–Ω—ã–µ –Ω–µ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –ø–æ –¥–∞—Ç–µ, –≤—ã–ø–æ–ª–Ω—è–µ–º —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫—É...")
                self.data = self.data.sort_values([self.id_column, self.timestamp_column])
            
            # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –¥–∞—Ç—É
            raw_last_date = self.data[self.timestamp_column].iloc[-1]  # –ò—Å–ø–æ–ª—å–∑—É–µ–º iloc[-1] –≤–º–µ—Å—Ç–æ max()
            self.log(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–æ—Å–ª–µ–¥–Ω—è—è –¥–∞—Ç–∞ –∏–∑ –¥–∞–Ω–Ω—ã—Ö (–ø–æ –ø–æ—Ä—è–¥–∫—É): {raw_last_date}, —Ç–∏–ø: {type(raw_last_date)}")
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ Timestamp –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if isinstance(raw_last_date, pd.Timestamp):
                last_date = raw_last_date
            elif pd.api.types.is_datetime64_any_dtype(raw_last_date):
                last_date = pd.Timestamp(raw_last_date)
            elif isinstance(raw_last_date, str):
                try:
                    last_date = pd.to_datetime(raw_last_date)
                    self.log(f"–°—Ç—Ä–æ–∫–æ–≤–∞—è –¥–∞—Ç–∞ —É—Å–ø–µ—à–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∞: {last_date}")
                except Exception as e_str:
                    self.log(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è —Å—Ç—Ä–æ–∫–æ–≤–æ–π –¥–∞—Ç—ã: {e_str}")
                    last_date = pd.Timestamp.now().normalize()
            elif isinstance(raw_last_date, (int, float)):
                self.log(f"–ß–∏—Å–ª–æ–≤–∞—è –¥–∞—Ç–∞: {raw_last_date}. –ü–æ–ø—ã—Ç–∫–∞ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –∏–∑ Unix timestamp.")
                if pd.Timestamp("2000-01-01").timestamp() < raw_last_date < pd.Timestamp("2050-01-01").timestamp():
                    last_date = pd.Timestamp(raw_last_date, unit='s')
                    self.log(f"–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–æ –∏–∑ —Å–µ–∫—É–Ω–¥: {last_date}")
                elif pd.Timestamp("2000-01-01").timestamp() * 1000 < raw_last_date < pd.Timestamp("2050-01-01").timestamp() * 1000:
                    last_date = pd.Timestamp(raw_last_date, unit='ms')
                    self.log(f"–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–æ –∏–∑ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥: {last_date}")
                else:
                    try:
                        last_date = pd.to_datetime(raw_last_date)
                        self.log(f"–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–æ pd.to_datetime (–∞–≤—Ç–æ): {last_date}")
                    except:
                        last_date = pd.Timestamp.now().normalize()
                        self.log(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –º–∞—Å—à—Ç–∞–± timestamp. –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ–∫—É—â—É—é –¥–∞—Ç—É: {last_date}")
            else:
                try:
                    last_date = pd.to_datetime(raw_last_date)
                    self.log(f"–î–∞—Ç–∞ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∞ –∏–∑ —Ç–∏–ø–∞ {type(raw_last_date)}: {last_date}")
                except Exception as e_conv:
                    self.log(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –¥–∞—Ç—É '{raw_last_date}' –≤ datetime: {e_conv}. –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ–∫—É—â—É—é –¥–∞—Ç—É.")
                    last_date = pd.Timestamp.now().normalize()

        except Exception as e:
            self.log(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏/–æ–±—Ä–∞–±–æ—Ç–∫–µ –ø–æ—Å–ª–µ–¥–Ω–µ–π –¥–∞—Ç—ã: {e}")
            last_date = pd.Timestamp.now().normalize()

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —á–∞—Å—Ç–æ—Ç—É
        #freq = self.detected_frequency if self.auto_frequency else self.frequency
        if self.auto_frequency:
            freq = self.detected_frequency
        else:
            freq_index = self.frequency
            if isinstance(freq_index, int) and 0 <= freq_index < len(self.FREQUENCIES):
                freq = self.FREQUENCIES[freq_index][0]
            else:
                freq = self.frequency
        self.log(f"–°–æ–∑–¥–∞–Ω–∏–µ –±—É–¥—É—â–∏—Ö –¥–∞—Ç –æ—Ç {last_date} —Å —á–∞—Å—Ç–æ—Ç–æ–π {freq}")
        
        try:
            # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ù–∞—á–∏–Ω–∞–µ–º —Å –°–õ–ï–î–£–Æ–©–ï–ì–û –¥–Ω—è –ø–æ—Å–ª–µ –ø–æ—Å–ª–µ–¥–Ω–µ–π –¥–∞—Ç—ã
            start_date = last_date + pd.tseries.frequencies.to_offset(freq)
            self.log(f"–ù–∞—á–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞: {start_date}")
            
            # –°–æ–∑–¥–∞–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç
            if freq == 'B':
                all_dates = pd.date_range(start=start_date, periods=periods * 2, freq='D')
                dates = all_dates[all_dates.weekday < 5][:periods]
            else:
                dates = pd.date_range(start=start_date, periods=periods, freq=freq)
                
        except Exception as e:
            self.log(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –¥–∞—Ç: {e}")
            
            try:
                start_date = last_date + pd.Timedelta(days=1)
                dates = pd.date_range(start=start_date, periods=periods, freq='D')
                self.log(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –¥–∞—Ç—ã —Å {start_date}")
            except:
                base_date = pd.Timestamp('2024-01-01')
                dates = pd.date_range(start=base_date, periods=periods, freq='D')
                self.log(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞—Ç—ã —Å {base_date}")

        self.log(f"–°–æ–∑–¥–∞–Ω –¥–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞: —Å {dates[0]} –ø–æ {dates[-1]}")
        return dates

    def create_future_dates_for_specific_id(self, last_date, model_freq):
        """
        –£–ù–ò–í–ï–†–°–ê–õ–¨–ù–ê–Ø —Ñ—É–Ω–∫—Ü–∏—è —Å–æ–∑–¥–∞–Ω–∏—è –±—É–¥—É—â–∏—Ö –¥–∞—Ç –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ ID
        –†–∞–±–æ—Ç–∞–µ—Ç —Å –ª—é–±—ã–º–∏ —Ç–∏–ø–∞–º–∏ –¥–∞—Ç –∏ —á–∞—Å—Ç–æ—Ç–∞–º–∏
        """
        try:
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –¥–∞—Ç—É
            if not isinstance(last_date, pd.Timestamp):
                last_date = pd.to_datetime(last_date)
            
            # –ü–æ–ª—É—á–∞–µ–º —á–∞—Å—Ç–æ—Ç—É            
            freq = model_freq
            self.log(f"[DEBUG] –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞—Ç —Å —á–∞—Å—Ç–æ—Ç–æ–π: {freq}")

            # –°–æ–∑–¥–∞–µ–º —Å–ª–µ–¥—É—é—â—É—é –¥–∞—Ç—É
            try:
                offset = pd.tseries.frequencies.to_offset(freq)
                start_date = last_date + offset
            except:
                start_date = last_date + pd.Timedelta(days=1)
            
            # –°–æ–∑–¥–∞–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç
            try:
                if freq == 'B':  # –†–∞–±–æ—á–∏–µ –¥–Ω–∏
                    all_dates = pd.date_range(start=start_date, periods=self.prediction_length * 2, freq='D')
                    dates = all_dates[all_dates.weekday < 5][:self.prediction_length]
                else:
                    dates = pd.date_range(start=start_date, periods=self.prediction_length, freq=freq)
            except:
                # –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∑–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç
                dates = pd.date_range(start=start_date, periods=self.prediction_length, freq='D')
            
            return dates
            
        except Exception as e:
            self.log(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –¥–∞—Ç: {e}")
            # –ö—Ä–∞–π–Ω–∏–π –∑–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç
            try:
                start_date = pd.to_datetime(last_date) + pd.Timedelta(days=1)
                dates = pd.date_range(start=start_date, periods=self.prediction_length, freq='D')
                return dates
            except:
                # –ï—Å–ª–∏ —Å–æ–≤—Å–µ–º –Ω–∏—á–µ–≥–æ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç
                base_date = pd.Timestamp('2024-01-01')
                dates = pd.date_range(start=base_date, periods=self.prediction_length, freq='D')
                return dates

    def run_model(self):
        if self.data is None:
            self.error("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö")
            self.log("–û—à–∏–±–∫–∞: –¥–∞–Ω–Ω—ã–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
            return
            
        # –ì–ª—É–±–æ–∫–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö
        self.log(f"=== –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –î–ê–ù–ù–´–• ===")
        self.log(f"–¢–∏–ø –æ–±—ä–µ–∫—Ç–∞ –¥–∞–Ω–Ω—ã—Ö: {type(self.data)}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, DataFrame –ª–∏ —ç—Ç–æ
        if not isinstance(self.data, pd.DataFrame):
            self.log("–î–∞–Ω–Ω—ã–µ –Ω–µ —è–≤–ª—è—é—Ç—Å—è pandas DataFrame, –ø—ã—Ç–∞—é—Å—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å")
            # –ü–æ–ø—ã—Ç–∫–∞ –ø–æ–ª—É—á–∏—Ç—å –∏—Å—Ö–æ–¥–Ω—ã–π Table, –µ—Å–ª–∏ self.data –±—ã–ª –∏–∑–º–µ–Ω–µ–Ω
            # –≠—Ç–æ —Ä–∏—Å–∫–æ–≤–∞–Ω–Ω–æ, –µ—Å–ª–∏ set_data –Ω–µ –≤—ã–∑—ã–≤–∞–ª—Å—è —Å Table
            # –î–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏, –ª—É—á—à–µ –ø–æ–ª–∞–≥–∞—Ç—å—Å—è –Ω–∞ —Ç–æ, —á—Ç–æ self.data —É–∂–µ DataFrame
            try:
                # –ï—Å–ª–∏ self.data —ç—Ç–æ Table, –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º
                if isinstance(self.data, Table): # type: ignore
                    self.data = self.prepare_data(self.data) # prepare_data –æ–∂–∏–¥–∞–µ—Ç Table
                    self.log("–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∏–∑ Table –≤ DataFrame —É—Å–ø–µ—à–Ω–æ")
                else:
                    # –ï—Å–ª–∏ —ç—Ç–æ —á—Ç–æ-—Ç–æ –¥—Ä—É–≥–æ–µ, –Ω–æ –Ω–µ DataFrame, —ç—Ç–æ –ø—Ä–æ–±–ª–µ–º–∞
                    self.error("–î–∞–Ω–Ω—ã–µ –∏–º–µ—é—Ç –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ç–∏–ø –∏ –Ω–µ –º–æ–≥—É—Ç –±—ã—Ç—å –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã.")
                    return
            except Exception as e:
                self.log(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –≤ DataFrame: {str(e)}")
                self.error("–ù–µ–≤–æ–∑–º–æ–∂–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –≤ –Ω—É–∂–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç")
                return
        
        # –¢–µ–ø–µ—Ä—å —É –Ω–∞—Å –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å DataFrame
        self.log(f"–ö–æ–ª–æ–Ω–∫–∏ –≤ DataFrame –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞: {list(self.data.columns)}")
        self.log(f"–ö–æ–ª–æ–Ω–∫–∏, –≤—ã–±—Ä–∞–Ω–Ω—ã–µ –≤ UI (–∏–ª–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é): ID='{self.id_column}', –í—Ä–µ–º—è='{self.timestamp_column}', –¶–µ–ª—å='{self.target_column}'")

        # --- –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ ---
        # ID –∫–æ–ª–æ–Ω–∫–∞
        if not self.id_column or self.id_column not in self.data.columns:
            self.error(f"–í—ã–±—Ä–∞–Ω–Ω–∞—è ID –∫–æ–ª–æ–Ω–∫–∞ '{self.id_column}' –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –¥–∞–Ω–Ω—ã—Ö. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—É—é –∫–æ–ª–æ–Ω–∫—É.")
            return
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º ID –∫–æ–ª–æ–Ω–∫—É –≤ —Å—Ç—Ä–æ–∫—É –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π, –µ—Å–ª–∏ –æ–Ω–∞ –µ—â–µ –Ω–µ —Ç–∞–∫–∞—è
        if not pd.api.types.is_string_dtype(self.data[self.id_column]):
            self.data[self.id_column] = self.data[self.id_column].astype(str)
            self.log(f"ID –∫–æ–ª–æ–Ω–∫–∞ '{self.id_column}' –ø—Ä–∏–≤–µ–¥–µ–Ω–∞ –∫ —Å—Ç—Ä–æ–∫–æ–≤–æ–º—É —Ç–∏–ø—É.")

        # –í—Ä–µ–º–µ–Ω–Ω–∞—è –∫–æ–ª–æ–Ω–∫–∞
        if not self.timestamp_column or self.timestamp_column not in self.data.columns:
            self.error(f"–í—ã–±—Ä–∞–Ω–Ω–∞—è –≤—Ä–µ–º–µ–Ω–Ω–∞—è –∫–æ–ª–æ–Ω–∫–∞ '{self.timestamp_column}' –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –¥–∞–Ω–Ω—ã—Ö. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—É—é –∫–æ–ª–æ–Ω–∫—É.")
            return
        if not pd.api.types.is_datetime64_any_dtype(self.data[self.timestamp_column]):
             # –ü–æ–ø—ã—Ç–∫–∞ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è, –µ—Å–ª–∏ –µ—â–µ –Ω–µ datetime
            try:
                self.data[self.timestamp_column] = pd.to_datetime(self.data[self.timestamp_column], errors='raise')
                self.log(f"–í—Ä–µ–º–µ–Ω–Ω–∞—è –∫–æ–ª–æ–Ω–∫–∞ '{self.timestamp_column}' —É—Å–ø–µ—à–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∞ –≤ datetime.")
            except Exception as e:
                self.error(f"–í—ã–±—Ä–∞–Ω–Ω–∞—è –≤—Ä–µ–º–µ–Ω–Ω–∞—è –∫–æ–ª–æ–Ω–∫–∞ '{self.timestamp_column}' –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∞ –≤ —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç—ã/–≤—Ä–µ–º–µ–Ω–∏: {e}")
                return

        # –¶–µ–ª–µ–≤–∞—è –∫–æ–ª–æ–Ω–∫–∞
        if not self.target_column or self.target_column not in self.data.columns:
            self.error(f"–í—ã–±—Ä–∞–Ω–Ω–∞—è —Ü–µ–ª–µ–≤–∞—è –∫–æ–ª–æ–Ω–∫–∞ '{self.target_column}' –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –¥–∞–Ω–Ω—ã—Ö. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—É—é –∫–æ–ª–æ–Ω–∫—É.")
            return
        if not pd.api.types.is_numeric_dtype(self.data[self.target_column]):
            # –ü–æ–ø—ã—Ç–∫–∞ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –≤ —á–∏—Å–ª–æ–≤–æ–π —Ç–∏–ø
            try:
                self.data[self.target_column] = pd.to_numeric(self.data[self.target_column], errors='raise')
                self.log(f"–¶–µ–ª–µ–≤–∞—è –∫–æ–ª–æ–Ω–∫–∞ '{self.target_column}' —É—Å–ø–µ—à–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∞ –≤ —á–∏—Å–ª–æ–≤–æ–π —Ç–∏–ø.")
            except Exception as e:
                self.error(f"–í—ã–±—Ä–∞–Ω–Ω–∞—è —Ü–µ–ª–µ–≤–∞—è –∫–æ–ª–æ–Ω–∫–∞ '{self.target_column}' –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —á–∏—Å–ª–æ–≤–æ–π –∏ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∞: {e}")
                return
            
        # –¢–µ–ø–µ—Ä—å –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –Ω–∞–π–¥–µ–Ω—ã –≤—Å–µ –∫–æ–ª–æ–Ω–∫–∏
        self.log(f"–§–∏–Ω–∞–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –º–æ–¥–µ–ª–∏: ID='{self.id_column}', –í—Ä–µ–º—è='{self.timestamp_column}', –¶–µ–ª—å='{self.target_column}'")
        
        # –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
        try:
            self.log("–ü–æ–ø—ã—Ç–∫–∞ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö...")
            df_sorted = self.data.sort_values([self.id_column, self.timestamp_column])
            self.log("–°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ —É—Å–ø–µ—à–Ω–∞")
            # –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
            self.log("üìç –û–¢–õ–ê–î–ö–ê run_model: –ü—Ä–æ–≤–µ—Ä–∫–∞ df_sorted –ø–æ—Å–ª–µ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏")
            for country_id in df_sorted[self.id_column].unique():
                country_data = df_sorted[df_sorted[self.id_column] == country_id]
                first_date = country_data[self.timestamp_column].iloc[0]
                last_date = country_data[self.timestamp_column].iloc[-1]
                self.log(f"  {country_id}: {len(country_data)} –∑–∞–ø–∏—Å–µ–π, {first_date} - {last_date}")
        except Exception as e:
            self.log(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–µ: {str(e)}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –º–æ–∂–µ—Ç –ª–∏ —ç—Ç–æ –±—ã—Ç—å –ø—Ä–æ–±–ª–µ–º–∞ —Å –∏–Ω–¥–µ–∫—Å–æ–º –≤–º–µ—Å—Ç–æ –∏–º–µ–Ω–∏ –∫–æ–ª–æ–Ω–∫–∏
            if "KeyError: 1" in str(e) or "KeyError: 0" in str(e):
                self.log("–û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –æ—à–∏–±–∫–∞ —Å –∏–Ω–¥–µ–∫—Å–æ–º. –ü—Ä–æ–±—É—é –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –ø–æ–¥—Ö–æ–¥")
                # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é —Å –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –∫–æ–ª–æ–Ω–∫–∞–º–∏
                df_temp = self.data.copy()
                
                # –ï—Å–ª–∏ –Ω—É–∂–Ω–∞—è –∫–æ–ª–æ–Ω–∫–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∏–ª–∏ –∏–º–µ–µ—Ç –Ω–µ–≤–µ—Ä–Ω–æ–µ –∏–º—è, —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é
                if self.id_column not in df_temp.columns:
                    df_temp['item_id'] = 'single_item'
                    self.id_column = 'item_id'
                
                try:
                    df_sorted = df_temp.sort_values([self.id_column, self.timestamp_column])
                    self.log("–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–∞—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ —É—Å–ø–µ—à–Ω–∞")
                except:
                    # –ï—Å–ª–∏ –∏ —ç—Ç–æ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç, —Å–æ–∑–¥–∞–µ–º –ø–æ–ª–Ω–æ—Å—Ç—å—é –Ω–æ–≤—ã–π DataFrame
                    self.log("–°–æ–∑–¥–∞—é –Ω–æ–≤—ã–π DataFrame —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π")
                    df_new = pd.DataFrame()
                    df_new['item_id'] = ['item_1'] * len(self.data)
                    df_new[self.timestamp_column] = self.data[self.timestamp_column].copy()
                    df_new[self.target_column] = self.data[self.target_column].copy()
                    df_sorted = df_new.sort_values(['item_id', self.timestamp_column])
                    self.id_column = 'item_id'
                    self.log("–ù–æ–≤—ã–π DataFrame —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω –∏ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω")
            else:
                # –î—Ä—É–≥–∞—è –æ—à–∏–±–∫–∞, –Ω–µ —Å–≤—è–∑–∞–Ω–Ω–∞—è —Å –∏–Ω–¥–µ–∫—Å–∞–º–∏
                self.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–µ –¥–∞–Ω–Ω—ã—Ö: {str(e)}")
                return
            
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª–∏–Ω—ã –ø—Ä–æ–≥–Ω–æ–∑–∞ –ø–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º
        if self.prediction_length > self.max_allowed_prediction and self.max_allowed_prediction > 0:
            self.error(f"–î–ª–∏–Ω–∞ –ø—Ä–æ–≥–Ω–æ–∑–∞ ({self.prediction_length}) –ø—Ä–µ–≤—ã—à–∞–µ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –¥–æ–ø—É—Å—Ç–∏–º—É—é ({self.max_allowed_prediction}) –¥–ª—è –≤–∞—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö. –£–º–µ–Ω—å—à–∏—Ç–µ –¥–ª–∏–Ω—É –ø—Ä–æ–≥–Ω–æ–∑–∞.")
            self.log(f"–û–®–ò–ë–ö–ê: –î–ª–∏–Ω–∞ –ø—Ä–æ–≥–Ω–æ–∑–∞ —Å–ª–∏—à–∫–æ–º –≤–µ–ª–∏–∫–∞. –ú–∞–∫—Å–∏–º—É–º: {self.max_allowed_prediction}")
            return
            
        self.progressBarInit()
        try:
            self.log_widget.clear()
            self.log("=== –ù–ê–ß–ê–õ–û ===")
            
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
            self.log("–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ TimeSeriesDataFrame...")
            df_sorted = self.data.sort_values([self.id_column, self.timestamp_column])
            
            # –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
            self.log("üìç –û–¢–õ–ê–î–ö–ê run_model: –ü—Ä–æ–≤–µ—Ä–∫–∞ df_sorted –ø–æ—Å–ª–µ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏")
            for country_id in df_sorted[self.id_column].unique():
                country_data = df_sorted[df_sorted[self.id_column] == country_id]
                first_date = country_data[self.timestamp_column].iloc[0]
                last_date = country_data[self.timestamp_column].iloc[-1]
                self.log(f"  {country_id}: {len(country_data)} –∑–∞–ø–∏—Å–µ–π, {first_date} - {last_date}")
                
                self.log(f"–ü–æ—Å–ª–µ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏: {len(df_sorted)} –∑–∞–ø–∏—Å–µ–π")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Å—Ç–æ–ª–±—Ü—ã –∏–º–µ—é—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Ç–∏–ø—ã
            self.log(f"–¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö: {df_sorted.dtypes.to_dict()}")

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è timestamp –≤ datetime
            self.log("–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞ –∫–æ–ª–æ–Ω–∫–∏ –≤—Ä–µ–º–µ–Ω–∏...")
            if pd.api.types.is_numeric_dtype(df_sorted[self.timestamp_column]):
                self.log(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ —á–∏—Å–ª–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –≤ –∫–æ–ª–æ–Ω–∫–µ –≤—Ä–µ–º–µ–Ω–∏. –ü—Ä–æ–±—É—é –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –∏–∑ timestamp...")
                try:
                    # –ü—Ä–æ–±—É–µ–º –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –∏–∑ timestamp –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
                    df_sorted[self.timestamp_column] = pd.to_datetime(df_sorted[self.timestamp_column], unit='s')
                    self.log("–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∏–∑ —Å–µ–∫—É–Ω–¥ —É—Å–ø–µ—à–Ω–∞")
                except Exception as e1:
                    self.log(f"–û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –∏–∑ —Å–µ–∫—É–Ω–¥: {str(e1)}")
                    try:
                        # –ü—Ä–æ–±—É–µ–º –∏–∑ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥
                        df_sorted[self.timestamp_column] = pd.to_datetime(df_sorted[self.timestamp_column], unit='ms')
                        self.log("–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∏–∑ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥ —É—Å–ø–µ—à–Ω–∞")
                    except Exception as e2:
                        self.log(f"–û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –∏–∑ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥: {str(e2)}")
                        # –°–æ–∑–¥–∞–µ–º –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–µ –¥–∞—Ç—ã –∫–∞–∫ –ø–æ—Å–ª–µ–¥–Ω–µ–µ —Å—Ä–µ–¥—Å—Ç–≤–æ
                        self.log("–°–æ–∑–¥–∞–Ω–∏–µ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã—Ö –¥–∞—Ç...")
                        try:
                            start_date = pd.Timestamp('2020-01-01')
                            dates = pd.date_range(start=start_date, periods=len(df_sorted), freq='D')
                            df_sorted[self.timestamp_column] = dates
                            self.log(f"–°–æ–∑–¥–∞–Ω—ã –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–µ –¥–∞—Ç—ã —Å {start_date} —Å —à–∞–≥–æ–º 1 –¥–µ–Ω—å")
                        except Exception as e3:
                            self.log(f"–ù–µ–≤–æ–∑–º–æ–∂–Ω–æ —Å–æ–∑–¥–∞—Ç—å –¥–∞—Ç—ã: {str(e3)}")
                            self.error("–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –∫–æ–ª–æ–Ω–∫—É –≤—Ä–µ–º–µ–Ω–∏")
                            return
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –¥–∞—Ç–∞ —Ç–µ–ø–µ—Ä—å –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
            if not pd.api.types.is_datetime64_dtype(df_sorted[self.timestamp_column]):
                self.log("–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ datetime...")
                try:
                    df_sorted[self.timestamp_column] = pd.to_datetime(df_sorted[self.timestamp_column], errors='coerce')
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –Ω–∞–ª–∏—á–∏–µ NaT (Not a Time)
                    if df_sorted[self.timestamp_column].isna().any():
                        self.log("–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–µ –¥–∞—Ç—ã, –∑–∞–º–µ–Ω–∞ –Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–µ")
                        # –ó–∞–º–µ–Ω—è–µ–º NaT –Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–µ –¥–∞—Ç—ã
                        valid_mask = ~df_sorted[self.timestamp_column].isna()
                        if valid_mask.any():
                            # –ï—Å–ª–∏ –µ—Å—Ç—å —Ö–æ—Ç—å –æ–¥–Ω–∞ –≤–∞–ª–∏–¥–Ω–∞—è –¥–∞—Ç–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ—ë –∫–∞–∫ –Ω–∞—á–∞–ª—å–Ω—É—é
                            first_valid = df_sorted.loc[valid_mask, self.timestamp_column].min()
                            self.log(f"–ü–µ—Ä–≤–∞—è –≤–∞–ª–∏–¥–Ω–∞—è –¥–∞—Ç–∞: {first_valid}")
                        else:
                            # –ò–Ω–∞—á–µ –Ω–∞—á–∏–Ω–∞–µ–º —Å —Å–µ–≥–æ–¥–Ω—è
                            first_valid = pd.Timestamp.now().normalize()
                            self.log("–ù–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –¥–∞—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ–∫—É—â—É—é –¥–∞—Ç—É")
                            
                        # –°–æ–∑–¥–∞–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –¥–∞—Ç
                        dates = pd.date_range(start=first_valid, periods=len(df_sorted), freq='D')
                        df_sorted[self.timestamp_column] = dates
                except Exception as e:
                    self.log(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –¥–∞—Ç: {str(e)}")
                    self.error("–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –¥–∞—Ç—ã")
                    return
            
            # –î–æ–±–∞–≤—å—Ç–µ –ø–æ—Å–ª–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ñ–æ—Ä–º–∞—Ç–∞ –¥–∞—Ç—ã –∏ –ø–µ—Ä–µ–¥ —Å–æ–∑–¥–∞–Ω–∏–µ–º TimeSeriesDataFrame
            self.log("–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –¥–∞—Ç...")
            # –ó–ê–ö–û–ú–ú–ï–ù–¢–ò–†–û–í–ê–ù–û: –õ–æ–≥–∏–∫–∞ –¥–ª—è —Å–ª—É—á–∞—è, –∫–æ–≥–¥–∞ –¥–∞—Ç—ã —Å–ª–∏—à–∫–æ–º –±–ª–∏–∑–∫–∏.
            # –ï—Å–ª–∏ –≤–∞—à–∏ –¥–∞–Ω–Ω—ã–µ –≤—Å–µ–≥–¥–∞ –∏–º–µ—é—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω, —ç—Ç–æ—Ç –±–ª–æ–∫ –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ –Ω—É–∂–µ–Ω –∏–ª–∏ —Ç—Ä–µ–±–æ–≤–∞—Ç—å –¥–æ—Ä–∞–±–æ—Ç–∫–∏.
            """
            if pd.api.types.is_datetime64_dtype(df_sorted[self.timestamp_column]):
                 if df_sorted[self.timestamp_column].max() - df_sorted[self.timestamp_column].min() < pd.Timedelta(days=1):
                     self.log("–í–ù–ò–ú–ê–ù–ò–ï: –í—Å–µ –¥–∞—Ç—ã —Å–ª–∏—à–∫–æ–º –±–ª–∏–∑–∫–∏ –¥—Ä—É–≥ –∫ –¥—Ä—É–≥—É. –°–æ–∑–¥–∞—é –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–µ –¥–∞—Ç—ã —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–º.")
                     # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–µ –¥–∞—Ç—ã
                     start_date = pd.Timestamp('2023-01-01')
                     # dates = pd.date_range(start=start_date, periods=len(df_sorted), freq='D') # –≠—Ç–∞ —Å—Ç—Ä–æ–∫–∞ –±—ã–ª–∞ –¥–ª—è –≤—Å–µ–≥–æ df_sorted
                    
                     # –°–æ—Ä—Ç–∏—Ä—É–µ–º –¥–∞—Ç–∞—Ñ—Ä–µ–π–º —Å–Ω–∞—á–∞–ª–∞ –ø–æ ID, –∑–∞—Ç–µ–º –ø–æ –∏—Å—Ö–æ–¥–Ω—ã–º –¥–∞—Ç–∞–º
                     df_sorted = df_sorted.sort_values([self.id_column, self.timestamp_column])
                    
                     # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ—Ä—è–¥–æ–∫ –∑–∞–ø–∏—Å–µ–π –¥–ª—è –∫–∞–∂–¥–æ–≥–æ ID
                     all_ids = df_sorted[self.id_column].unique()
                     new_df_list = []
                    
                     for id_val in all_ids:
                         # –ü–æ–ª—É—á–∞–µ–º –ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ ID
                         id_df = df_sorted[df_sorted[self.id_column] == id_val].copy()
                        
                         # –°–æ–∑–¥–∞–µ–º –¥–∞—Ç—ã –¥–ª—è —ç—Ç–æ–≥–æ ID
                         id_dates = pd.date_range(start=start_date, periods=len(id_df), freq='D')
                        
                         # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –Ω–æ–≤—ã–µ –¥–∞—Ç—ã
                         id_df[self.timestamp_column] = id_dates
                        
                         # –î–æ–±–∞–≤–ª—è–µ–º –≤ –Ω–æ–≤—ã–π –¥–∞—Ç–∞—Ñ—Ä–µ–π–º
                         new_df_list.append(id_df)
                    
            #         # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –æ–±—Ä–∞—Ç–Ω–æ
                     df_sorted = pd.concat(new_df_list)
                     # –í–ê–ñ–ù–û: –û–±–Ω–æ–≤–ª—è–µ–º self.data, –µ—Å–ª–∏ –¥–∞—Ç—ã –±—ã–ª–∏ –∏–∑–º–µ–Ω–µ–Ω—ã,
                     # —á—Ç–æ–±—ã create_future_dates –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –¥–∞—Ç—ã.
                     self.data = df_sorted.copy()
                     self.log(f"self.data –æ–±–Ω–æ–≤–ª–µ–Ω –Ω–æ–≤—ã–º–∏ –¥–∞—Ç–∞–º–∏. –î–∏–∞–ø–∞–∑–æ–Ω: —Å {self.data[self.timestamp_column].min()} –ø–æ {self.data[self.timestamp_column].max()}")
                     self.log(f"–°–æ–∑–¥–∞–Ω—ã –Ω–æ–≤—ã–µ –¥–∞—Ç—ã (–≤ df_sorted) —Å {df_sorted[self.timestamp_column].min()} –ø–æ {df_sorted[self.timestamp_column].max()}")
            """
            self.log(f"–§–∏–Ω–∞–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –≤—Ä–µ–º–µ–Ω–∏: {df_sorted[self.timestamp_column].dtype}")
            self.log(f"–î–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç: —Å {df_sorted[self.timestamp_column].min()} –ø–æ {df_sorted[self.timestamp_column].max()}")

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —á–∞—Å—Ç–æ—Ç—É –¥–ª—è –º–æ–¥–µ–ª–∏
            if self.auto_frequency:
                model_freq = self.detected_frequency
            else:
                # –ü–æ–ª—É—á–∞–µ–º –∫–æ–¥ —á–∞—Å—Ç–æ—Ç—ã –∏–∑ FREQUENCIES –ø–æ –∏–Ω–¥–µ–∫—Å—É
                freq_index = self.frequency
                if isinstance(freq_index, int) and 0 <= freq_index < len(self.FREQUENCIES):
                    model_freq = self.FREQUENCIES[freq_index][0]  # –ë–µ—Ä–µ–º –∫–æ–¥ (D, W, M, Q –∏ —Ç.–¥.)
                else:
                    model_freq = self.frequency
            self.log(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º–∞—è —á–∞—Å—Ç–æ—Ç–∞: {model_freq}")

            # –ï—Å–ª–∏ –≤—ã–±—Ä–∞–Ω–∞ –Ω–µ –¥–Ω–µ–≤–Ω–∞—è —á–∞—Å—Ç–æ—Ç–∞, –∞–≥—Ä–µ–≥–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
            if model_freq != 'D':
                self.log(f"–ê–≥—Ä–µ–≥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –ø–æ —á–∞—Å—Ç–æ—Ç–µ: {model_freq}")

                df_sorted = df_sorted.groupby([
                    self.id_column,
                    pd.Grouper(key=self.timestamp_column, freq=model_freq)
                ]).agg({
                    self.target_column: 'sum'
                    # –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –∞–≥—Ä–µ–≥–∞—Ç—ã –¥—Ä—É–≥–∏—Ö –∫–æ–ª–æ–Ω–æ–∫
                }).reset_index()

                self.log(f"–ü–æ—Å–ª–µ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏: {len(df_sorted)} –∑–∞–ø–∏—Å–µ–π")

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è ID –∫–æ–ª–æ–Ω–∫–∏
            self.log(f"–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞ ID –∫–æ–ª–æ–Ω–∫–∏ '{self.id_column}'...")
            if self.id_column in df_sorted.columns:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö
                if pd.api.types.is_float_dtype(df_sorted[self.id_column]):
                    self.log("ID –∫–æ–ª–æ–Ω–∫–∞ –∏–º–µ–µ—Ç —Ç–∏–ø float, –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É—é –≤ —Å—Ç—Ä–æ–∫—É")
                    try:
                        # –ü–æ–ø—ã—Ç–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –≤ —Å—Ç—Ä–æ–∫—É
                        df_sorted[self.id_column] = df_sorted[self.id_column].astype(str)
                        self.log("–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è ID –≤ —Å—Ç—Ä–æ–∫—É —É—Å–ø–µ—à–Ω–∞")
                    except Exception as e:
                        self.log(f"–û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ ID –≤ —Å—Ç—Ä–æ–∫—É: {str(e)}")
                        # –ï—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∞–µ—Ç—Å—è, —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é ID –∫–æ–ª–æ–Ω–∫—É
                        self.log("–°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–π ID –∫–æ–ª–æ–Ω–∫–∏...")
                        df_sorted['virtual_id'] = 'item_1'
                        self.id_column = 'virtual_id'
            else:
                self.log(f"ID –∫–æ–ª–æ–Ω–∫–∞ '{self.id_column}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, —Å–æ–∑–¥–∞—é –≤–∏—Ä—Ç—É–∞–ª—å–Ω—É—é")
                df_sorted['virtual_id'] = 'item_1'
                self.id_column = 'virtual_id'
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤—Å–µ –∫–æ–ª–æ–Ω–∫–∏ –∏–º–µ—é—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ç–∏–ø
            self.log(f"–û–±–µ—Å–ø–µ—á–∏–≤–∞–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤—Å–µ—Ö –∫–æ–ª–æ–Ω–æ–∫...")
            # ID –∫–æ–ª–æ–Ω–∫–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Å—Ç—Ä–æ–∫–æ–π –∏–ª–∏ —Ü–µ–ª—ã–º —á–∏—Å–ª–æ–º
            if self.id_column in df_sorted.columns:
                if not (pd.api.types.is_string_dtype(df_sorted[self.id_column]) or 
                        pd.api.types.is_integer_dtype(df_sorted[self.id_column])):
                    df_sorted[self.id_column] = df_sorted[self.id_column].astype(str)
            
            # –¶–µ–ª–µ–≤–∞—è –∫–æ–ª–æ–Ω–∫–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —á–∏—Å–ª–æ–º
            if self.target_column in df_sorted.columns:
                if not pd.api.types.is_numeric_dtype(df_sorted[self.target_column]):
                    try:
                        df_sorted[self.target_column] = pd.to_numeric(df_sorted[self.target_column], errors='coerce')
                        # –ï—Å–ª–∏ –µ—Å—Ç—å NaN, –∑–∞–º–µ–Ω—è–µ–º –Ω—É–ª—è–º–∏
                        if df_sorted[self.target_column].isna().any():
                            df_sorted[self.target_column] = df_sorted[self.target_column].fillna(0)
                    except:
                        self.log(f"–ù–µ–≤–æ–∑–º–æ–∂–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å —Ü–µ–ª–µ–≤—É—é –∫–æ–ª–æ–Ω–∫—É '{self.target_column}' –≤ —á–∏—Å–ª–æ–≤–æ–π —Ñ–æ—Ä–º–∞—Ç")
            
            self.log(f"–§–∏–Ω–∞–ª—å–Ω—ã–µ —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö: {df_sorted.dtypes.to_dict()}")
            
            if self.timestamp_column in df_sorted.columns:
                if not pd.api.types.is_datetime64_dtype(df_sorted[self.timestamp_column]):
                    try:
                        df_sorted[self.timestamp_column] = pd.to_datetime(df_sorted[self.timestamp_column])
                        self.log(f"–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–ª–∏ {self.timestamp_column} –≤ datetime")
                    except Exception as e:
                        self.log(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –≤ datetime: {str(e)}")
                else:
                    self.log(f"–ö–æ–ª–æ–Ω–∫–∞ {self.timestamp_column} —É–∂–µ –∏–º–µ–µ—Ç —Ç–∏–ø datetime")
            
            # –î–æ–±–∞–≤—å—Ç–µ —ç—Ç–æ—Ç –±–ª–æ–∫ –ø–µ—Ä–µ–¥ —Å–æ–∑–¥–∞–Ω–∏–µ–º TimeSeriesDataFrame
            if self.from_form_timeseries:
                self.log("–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–ª—è –¥–∞–Ω–Ω—ã—Ö –∏–∑ FormTimeseries")
                # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ ID –∫–æ–ª–æ–Ω–∫–∞ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∏ –∏–º–µ–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ç–∏–ø
                if self.id_column not in df_sorted.columns:
                    self.log(f"ID –∫–æ–ª–æ–Ω–∫–∞ '{self.id_column}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –°–æ–∑–¥–∞—ë–º –∫–æ–ª–æ–Ω–∫—É —Å –µ–¥–∏–Ω—ã–º ID.")
                    df_sorted['item_id'] = 'item_1'
                    self.id_column = 'item_id'
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –≤—Ä–µ–º–µ–Ω–Ω–æ–π –∫–æ–ª–æ–Ω–∫–∏ —Å –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º —Ç–∏–ø–æ–º
                if not pd.api.types.is_datetime64_dtype(df_sorted[self.timestamp_column]):
                    self.log(f"–ö–æ–ª–æ–Ω–∫–∞ –≤—Ä–µ–º–µ–Ω–∏ '{self.timestamp_column}' –∏–º–µ–µ—Ç –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ç–∏–ø. –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ datetime.")
                    try:
                        df_sorted[self.timestamp_column] = pd.to_datetime(df_sorted[self.timestamp_column])
                    except Exception as e:
                        self.log(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –≤ datetime: {str(e)}")
                        # –ü—Ä–æ–≤–µ—Ä–∫–∞, –º–æ–∂–Ω–æ –ª–∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –∫–∞–∫ timestamp –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
                        try:
                            df_sorted[self.timestamp_column] = pd.to_datetime(df_sorted[self.timestamp_column], unit='s')
                            self.log("–ü—Ä–∏–º–µ–Ω–µ–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∏–∑ timestamp –≤ —Å–µ–∫—É–Ω–¥–∞—Ö")
                        except:
                            self.error("–ù–µ–≤–æ–∑–º–æ–∂–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—É—é –∫–æ–ª–æ–Ω–∫—É")
                            return
            
            # –î–æ–±–∞–≤–∏—Ç—å –ø–µ—Ä–µ–¥ —Å–æ–∑–¥–∞–Ω–∏–µ–º TimeSeriesDataFrame
            self.log(f"–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö –ø–µ—Ä–µ–¥ —Å–æ–∑–¥–∞–Ω–∏–µ–º TimeSeriesDataFrame...")
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ ID –∫–æ–ª–æ–Ω–∫–µ
            unique_ids = df_sorted[self.id_column].nunique()
            self.log(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö ID: {unique_ids}")

            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–ª–∏–Ω—É –∫–∞–∂–¥–æ–≥–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞
            id_counts = df_sorted[self.id_column].value_counts()
            self.log(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π –ø–æ ID: –º–∏–Ω={id_counts.min()}, –º–∞–∫—Å={id_counts.max()}, —Å—Ä–µ–¥–Ω–µ–µ={id_counts.mean():.1f}")

            # –ï—Å–ª–∏ –µ—Å—Ç—å —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω ID –∏ –º–Ω–æ–≥–æ –∑–∞–ø–∏—Å–µ–π, –Ω—É–∂–Ω–æ —Ä–∞–∑–¥–µ–ª–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤
            if unique_ids == 1 and len(df_sorted) > 50:
                self.log("–û–±–Ω–∞—Ä—É–∂–µ–Ω –æ–¥–∏–Ω –¥–ª–∏–Ω–Ω—ã–π –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥. –°–æ–∑–¥–∞—ë–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤...")
                
                # –°–æ–∑–¥–∞—ë–º –∫–æ–ø–∏—é DataFrame
                df_multi = df_sorted.copy()
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã—Ö –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤ —Å —É—á–µ—Ç–æ–º –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è
                # AutoGluon —Ç—Ä–µ–±—É–µ—Ç –º–∏–Ω–∏–º—É–º 29 —Ç–æ—á–µ–∫ –Ω–∞ —Ä—è–¥, –¥–æ–±–∞–≤–∏–º –∑–∞–ø–∞—Å –∏ —Å–¥–µ–ª–∞–µ–º 35
                min_points_per_series = 35  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ—á–µ–∫ –Ω–∞ —Ä—è–¥ (—Å –∑–∞–ø–∞—Å–æ–º)
                max_series = len(df_sorted) // min_points_per_series  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –≤–æ–∑–º–æ–∂–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä—è–¥–æ–≤
                n_series = min(3, max_series)  # –ù–µ –±–æ–ª–µ–µ 3 —Ä—è–¥–æ–≤, –Ω–æ —É—á–∏—Ç—ã–≤–∞–µ–º –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ
                
                if n_series < 1:
                    # –ï—Å–ª–∏ –¥–∞–∂–µ –¥–ª—è –æ–¥–Ω–æ–≥–æ —Ä—è–¥–∞ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç —Ç–æ—á–µ–∫, –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –∫–∞–∫ –æ–¥–∏–Ω —Ä—è–¥
                    self.log("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ—á–µ–∫ –¥–ª—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è. –ò—Å–ø–æ–ª—å–∑—É–µ–º –µ–¥–∏–Ω—ã–π –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥.")
                    df_sorted[self.id_column] = 'single_series'
                else:
                    self.log(f"–°–æ–∑–¥–∞—ë–º {n_series} –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã—Ö –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤ —Å –º–∏–Ω–∏–º—É–º {min_points_per_series} —Ç–æ—á–∫–∞–º–∏ –≤ –∫–∞–∂–¥–æ–º")
                    
                    # –í—ã—á–∏—Å–ª—è–µ–º, —Å–∫–æ–ª—å–∫–æ —Ç–æ—á–µ–∫ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –≤ –∫–∞–∂–¥–æ–º —Ä—è–¥—É
                    points_per_series = len(df_sorted) // n_series
                    
                    # –°–æ–∑–¥–∞—ë–º –Ω–æ–≤—É—é –∫–æ–ª–æ–Ω–∫—É ID, —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è—è —Ç–æ—á–∫–∏ –ø–æ —Ä—è–¥–∞–º
                    ids = []
                    for i in range(len(df_sorted)):
                        series_idx = i // points_per_series
                        # –ï—Å–ª–∏ –ø—Ä–µ–≤—ã—Å–∏–ª–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä—è–¥–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ä—è–¥
                        if series_idx >= n_series:
                            series_idx = n_series - 1
                        ids.append(f"series_{series_idx + 1}")
                    
                    df_multi['series_id'] = ids
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—É—é –∫–æ–ª–æ–Ω–∫—É ID –≤–º–µ—Å—Ç–æ —Å—Ç–∞—Ä–æ–π
                    self.id_column = 'series_id'
                    
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—ã–π DataFrame –≤–º–µ—Å—Ç–æ —Å—Ç–∞—Ä–æ–≥–æ
                    df_sorted = df_multi
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–ª—É—á–∏–≤—à–µ–µ—Å—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
                    id_counts = df_sorted[self.id_column].value_counts()
                    self.log(f"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–æ—á–µ–∫ –ø–æ —Ä—è–¥–∞–º: {id_counts.to_dict()}")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ—Ç –ª–∏ –¥—É–±–ª–∏—Ä—É—é—â–∏—Ö—Å—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫ –¥–ª—è –æ–¥–Ω–æ–≥–æ ID
            duplicate_check = df_sorted.duplicated(subset=[self.id_column, self.timestamp_column])
            if duplicate_check.any():
                dup_count = duplicate_check.sum()
                self.log(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {dup_count} –¥—É–±–ª–∏—Ä—É—é—â–∏—Ö—Å—è –∑–∞–ø–∏—Å–µ–π —Å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º–∏ ID –∏ –¥–∞—Ç–æ–π!")
                
                # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 1: –£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
                df_sorted = df_sorted.drop_duplicates(subset=[self.id_column, self.timestamp_column])
                self.log(f"–£–¥–∞–ª–µ–Ω—ã –¥—É–±–ª–∏—Ä—É—é—â–∏–µ—Å—è –∑–∞–ø–∏—Å–∏. –û—Å—Ç–∞–ª–æ—Å—å {len(df_sorted)} –∑–∞–ø–∏—Å–µ–π.")
                
                # –ï—Å–ª–∏ –ø–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –æ—Å—Ç–∞–ª–æ—Å—å —Å–ª–∏—à–∫–æ–º –º–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö, —Å–æ–∑–¥–∞–µ–º –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ä—è–¥—ã
                if df_sorted[self.id_column].nunique() == 1 and df_sorted.groupby(self.id_column).size().max() < 10:
                    self.log("–ü–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –¥–∞–Ω–Ω—ã—Ö —Å–ª–∏—à–∫–æ–º –º–∞–ª–æ. –ü—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –ø–æ–¥—Ö–æ–¥.")
                    # –°–æ–∑–¥–∞—ë–º –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥ —Å –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–π —á–∞—Å—Ç–æ—Ç–æ–π
                    dates = pd.date_range(start='2022-01-01', periods=30, freq='D')
                    artificial_df = pd.DataFrame({
                        'artificial_id': ['series_1'] * 10 + ['series_2'] * 10 + ['series_3'] * 10,
                        'timestamp': dates.tolist(),
                        'target': np.random.randint(10, 100, 30)
                    })
                    
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                    df_sorted = artificial_df
                    self.id_column = 'artificial_id'
                    self.timestamp_column = 'timestamp'
                    self.target_column = 'target'
                    self.log("–°–æ–∑–¥–∞–Ω—ã –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏.")

            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–∞–∑–¥–Ω–∏–∫–æ–≤, –µ—Å–ª–∏ –æ–ø—Ü–∏—è –≤–∫–ª—é—á–µ–Ω–∞
            # known_covariates_to_pass = None
            if self.include_holidays:
                self.log(f"–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø—Ä–∞–∑–¥–Ω–∏–∫–æ–≤ –¥–ª—è —Å—Ç—Ä–∞–Ω—ã: {self.holiday_country}...")
                try:
                    # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –≤—Ä–µ–º–µ–Ω–Ω–∞—è –∫–æ–ª–æ–Ω–∫–∞ –≤ df_sorted - —ç—Ç–æ datetime
                    df_sorted[self.timestamp_column] = pd.to_datetime(df_sorted[self.timestamp_column])
                    
                    # –ü–æ–ª—É—á–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –¥–∞—Ç—ã –∏–∑ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –¥–∏–∞–ø–∞–∑–æ–Ω–∞
                    unique_dates_for_holidays = df_sorted[self.timestamp_column].dt.normalize().unique()
                    if len(unique_dates_for_holidays) > 0:
                        min_holiday_date = unique_dates_for_holidays.min()
                        max_holiday_date = unique_dates_for_holidays.max()
                        
                        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø—Ä–∞–∑–¥–Ω–∏–∫–∏ –¥–ª—è –¥–∏–∞–ø–∞–∑–æ–Ω–∞ –¥–∞—Ç
                        country_holidays_obj = holidays.CountryHoliday(self.holiday_country, years=range(min_holiday_date.year, max_holiday_date.year + 1))
                        
                        # –°–æ–∑–¥–∞–µ–º —Å—Ç–æ–ª–±–µ—Ü is_holiday
                        df_sorted['is_holiday'] = df_sorted[self.timestamp_column].dt.normalize().apply(lambda date: 1 if date in country_holidays_obj else 0)
                        # known_covariates_to_pass = ['is_holiday']
                        self.log(f"–î–æ–±–∞–≤–ª–µ–Ω –ø—Ä–∏–∑–Ω–∞–∫ 'is_holiday' –≤ df_sorted. –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {df_sorted['is_holiday'].sum()} –ø—Ä–∞–∑–¥–Ω–∏—á–Ω—ã—Ö –¥–Ω–µ–π.")
                    else:
                        self.log("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –¥–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç –¥–ª—è –ø—Ä–∞–∑–¥–Ω–∏–∫–æ–≤.")
                except Exception as e_holiday:
                    self.log(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø—Ä–∞–∑–¥–Ω–∏–∫–æ–≤: {str(e_holiday)}")


            # –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ—Ç–ª–∞–¥–∫–∞
            self.log("–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ TimeSeriesDataFrame...")
            self.log(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –≤ df_sorted: {len(df_sorted)}")
            self.log(f"–ü—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö:\n{df_sorted.head(3).to_string()}")

            # –ü–µ—Ä–µ–¥ —Å—Ç—Ä–æ–∫–æ–π: ts_data = TimeSeriesDataFrame.from_data_frame(...)
            self.log("üîç –û–¢–õ–ê–î–ö–ê: –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ–¥ TimeSeriesDataFrame")
            for country_id in df_sorted[self.id_column].unique():
                country_data = df_sorted[df_sorted[self.id_column] == country_id]
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ –∏ –ø–æ—Å–ª–µ–¥–Ω–∏–µ –¥–∞—Ç—ã
                dates = country_data[self.timestamp_column].sort_values()
                self.log(f"  {country_id}: –ø–µ—Ä–≤—ã–µ 3 –¥–∞—Ç—ã: {dates.head(3).tolist()}")
                self.log(f"  {country_id}: –ø–æ—Å–ª–µ–¥–Ω–∏–µ 3 –¥–∞—Ç—ã: {dates.tail(3).tolist()}")

            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç TimeSeriesDataFrame
            ts_data = TimeSeriesDataFrame.from_data_frame(
                df_sorted,
                id_column=self.id_column,
                timestamp_column=self.timestamp_column
                # known_covariates_names=known_covariates_to_pass # –ü–µ—Ä–µ–¥–∞–µ–º –∏–∑–≤–µ—Å—Ç–Ω—ã–µ –∫–æ–≤–∞—Ä–∏–∞—Ç—ã
            )
            
            # –ß–∞—Å—Ç–æ—Ç–∞ —É–∂–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∞ –ø—Ä–∏ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏
            self.log(f"–ß–∞—Å—Ç–æ—Ç–∞ {model_freq} —É–∂–µ –±—ã–ª–∞ –ø—Ä–∏–º–µ–Ω–µ–Ω–∞ –ø—Ä–∏ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º asfreq()")

            """
            # –ü—ã—Ç–∞–µ–º—Å—è —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —á–∞—Å—Ç–æ—Ç—É –ø–æ—Å–ª–µ —Å–æ–∑–¥–∞–Ω–∏—è
            try:
                if model_freq != 'D':
                    self.log(f"–£—Å—Ç–∞–Ω–æ–≤–∫–∞ —á–∞—Å—Ç–æ—Ç—ã –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞: {model_freq}")
                    ts_data = ts_data.asfreq(model_freq)
            except Exception as freq_err:
                self.log(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —É—Å—Ç–∞–Ω–æ–≤–∫–µ —á–∞—Å—Ç–æ—Ç—ã {model_freq}: {str(freq_err)}. –ò—Å–ø–æ–ª—å–∑—É–µ–º –¥–Ω–µ–≤–Ω—É—é —á–∞—Å—Ç–æ—Ç—É.")
            
            self.log(f"–°–æ–∑–¥–∞–Ω –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥ —Å {len(ts_data)} –∑–∞–ø–∏—Å—è–º–∏")
            """
            # –û–±—É—á–µ–Ω–∏–µ
            with tempfile.TemporaryDirectory() as temp_dir:
                model_path = Path(temp_dir)

                # üõ†Ô∏è –°–æ–∑–¥–∞—ë–º –ø–∞–ø–∫—É –¥–ª—è –ª–æ–≥–æ–≤, –∏–Ω–∞—á–µ –±—É–¥–µ—Ç FileNotFoundError
                log_dir = model_path / "logs"
                log_dir.mkdir(parents=True, exist_ok=True)

                self.log(f"–ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏, –≤—Ä–µ–º—è: {self.time_limit} —Å–µ–∫...")                

                # –ü–æ–ª—É—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏ (—É–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ —ç—Ç–æ —Å—Ç—Ä–æ–∫–∞)
                metric = self.selected_metric
                if isinstance(metric, int) and 0 <= metric < len(self.METRICS):
                    metric = self.METRICS[metric]
                self.log(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º–∞—è –º–µ—Ç—Ä–∏–∫–∞: {metric}")

                # –ø—Ä–æ–≤–µ—Ä–∫–∞ –º–æ–¥–µ–ª–∏
                models = None
                if self.selected_model != "auto":
                    models = [self.selected_model]

                try:
                    # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä–∞
                    predictor = TimeSeriesPredictor(
                        path=model_path,
                        prediction_length=self.prediction_length,
                        target=self.target_column,
                        eval_metric=metric.lower(),
                        freq=model_freq
                    )
                    
                    # –û–±—É—á–µ–Ω–∏–µ
                    fit_args = {
                        "time_limit": self.time_limit,
                        "num_val_windows": 1,  # –£–º–µ–Ω—å—à–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–∫–æ–Ω –≤–∞–ª–∏–¥–∞—Ü–∏–∏
                        "val_step_size": 1    # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —à–∞–≥–∞ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
                    }

                    # if self.include_holidays: # –í—Ä–µ–º–µ–Ω–Ω–æ –æ—Ç–∫–ª—é—á–∞–µ–º, –ø–æ–∫–∞ Prophet –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω
                        # –ü—ã—Ç–∞–µ–º—Å—è –ø–µ—Ä–µ–¥–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–∞–∑–¥–Ω–∏–∫–∞—Ö —á–µ—Ä–µ–∑ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –º–æ–¥–µ–ª–µ–π,
                        # –∫–æ—Ç–æ—Ä—ã–µ —ç—Ç–æ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç, –Ω–∞–ø—Ä–∏–º–µ—Ä, Prophet.
                        # –î–ª—è Prophet –ø–∞—Ä–∞–º–µ—Ç—Ä –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è 'country_holidays_name'.
                        # fit_args['hyperparameters'] = {
                        #     'Prophet': {'country_holidays_name': 'RU'}
                        # }
                        # self.log("–í–∫–ª—é—á–µ–Ω–∞ –æ–ø—Ü–∏—è —É—á–µ—Ç–∞ –ø—Ä–∞–∑–¥–Ω–∏–∫–æ–≤. –ù–∞—Å—Ç—Ä–æ–µ–Ω—ã –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è Prophet (–∏, –≤–æ–∑–º–æ–∂–Ω–æ, –¥—Ä—É–≥–∏—Ö –º–æ–¥–µ–ª–µ–π).")
                    if self.include_holidays and 'is_holiday' not in df_sorted.columns:
                        self.log("–û–ø—Ü–∏—è '–£—á–∏—Ç—ã–≤–∞—Ç—å –ø—Ä–∞–∑–¥–Ω–∏–∫–∏' –≤–∫–ª—é—á–µ–Ω–∞, –Ω–æ –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∏ –ø—Ä–∞–∑–¥–Ω–∏–∫–æ–≤. –ü—Ä–∞–∑–¥–Ω–∏–∫–∏ –º–æ–≥—É—Ç –Ω–µ —É—á–∏—Ç—ã–≤–∞—Ç—å—Å—è.")
                    elif self.include_holidays and 'is_holiday' in df_sorted.columns:
                        self.log("–û–ø—Ü–∏—è '–£—á–∏—Ç—ã–≤–∞—Ç—å –ø—Ä–∞–∑–¥–Ω–∏–∫–∏' –≤–∫–ª—é—á–µ–Ω–∞, –ø—Ä–∏–∑–Ω–∞–∫ 'is_holiday' –¥–æ–±–∞–≤–ª–µ–Ω –≤ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è.")

                    
                    fit_args["num_val_windows"] = 1  # –£–º–µ–Ω—å—à–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–∫–æ–Ω –≤–∞–ª–∏–¥–∞—Ü–∏–∏
                    fit_args["val_step_size"] = 1     # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —à–∞–≥–∞ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
                    
                    # —Å–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—Ç–∞—Ä—ã–π –ª–æ–≥–≥–µ—Ä
                    import logging
                    
                    logger = logging.getLogger("autogluon")
                    for handler in logger.handlers[:]:
                        try:
                            handler.close()
                        except:
                            pass
                        logger.removeHandler(handler)
                        
                    # –í—ã–∑–æ–≤ –º–µ—Ç–æ–¥–∞ fit —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–º–∏ –∞—Ä–≥—É–º–µ–Ω—Ç–∞–º–∏
                    predictor.fit(
                        ts_data,
                        **fit_args
                    )
                    
                except ValueError as ve:
                    error_msg = str(ve)
                    self.log(f"–ü–æ–ª–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ: {error_msg}")
                    
                    # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–æ–∫ TimeSeriesPredictor
                    if "observations" in error_msg:
                        self.log("–û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –æ—à–∏–±–∫–∞ –æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ –Ω–∞–±–ª—é–¥–µ–Ω–∏–π. –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö...")
                        
                        # –ü–µ—á–∞—Ç–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
                        self.log(f"–§–æ—Ä–º–∞ –¥–∞–Ω–Ω—ã—Ö: {ts_data.shape}")
                        self.log(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö ID: {ts_data.index.get_level_values(0).nunique()}")
                        self.log(f"–ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ—á–µ–∫ –Ω–∞ —Ä—è–¥: {ts_data.groupby(level=0).size().min()}")
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —Å–ª–∏—à–∫–æ–º –ª–∏ –∫–æ—Ä–æ—Ç–∫–∏–π –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥ —É –∫–∞–∫–æ–≥–æ-—Ç–æ ID
                        ts_lengths = ts_data.groupby(level=0).size()
                        min_ts_id = ts_lengths.idxmin()
                        min_ts_len = ts_lengths.min()
                        
                        if min_ts_len < 10:  # –ï—Å–ª–∏ –∫–∞–∫–æ–π-—Ç–æ —Ä—è–¥ –∫–æ—Ä–æ—á–µ 10 —Ç–æ—á–µ–∫
                            self.log(f"–í—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥ '{min_ts_id}' –∏–º–µ–µ—Ç –≤—Å–µ–≥–æ {min_ts_len} —Ç–æ—á–µ–∫, —á—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ")
                            self.log("–ü–æ–ø—Ä–æ–±—É–µ–º —Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å –∫–æ—Ä–æ—Ç–∫–∏–µ —Ä—è–¥—ã...")
                            
                            # –û—Ç—Ñ–∏–ª—å—Ç—Ä—É–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã –∫–æ—Ä–æ—á–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–π –¥–ª–∏–Ω—ã
                            long_enough_ids = ts_lengths[ts_lengths >= 10].index
                            if len(long_enough_ids) > 0:
                                ts_data = ts_data.loc[long_enough_ids]
                                self.log(f"–û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ –¥–æ {len(long_enough_ids)} —Ä—è–¥–æ–≤ —Å –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω–æ–π 10")
                                
                                # –ü—Ä–æ–±—É–µ–º –æ–±—É—á–µ–Ω–∏–µ —Å –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
                                try:
                                    predictor.fit(ts_data, **fit_args)
                                except Exception as e2:
                                    self.log(f"–û—à–∏–±–∫–∞ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: {str(e2)}")
                                    raise
                            else:
                                self.error("–í—Å–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏")
                                return
                        
                        # –ï—Å–ª–∏ –Ω–µ —Å–º–æ–≥–ª–∏ –∏—Å–ø—Ä–∞–≤–∏—Ç—å –æ—à–∏–±–∫—É —Å –Ω–∞–±–ª—é–¥–µ–Ω–∏—è–º–∏, –¥–∞–¥–∏–º –±–æ–ª–µ–µ –ø–æ–Ω—è—Ç–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
                        import re
                        match = re.search(r"must have >= (\d+) observations", error_msg)
                        if match:
                            required_obs = int(match.group(1))
                            self.error(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ—á–µ–∫ –≤ –∫–∞–∂–¥–æ–º –≤—Ä–µ–º–µ–Ω–Ω–æ–º —Ä—è–¥—É: —Ç—Ä–µ–±—É–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º {required_obs}.")
                            self.log(f"–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ–π. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ ID –∫–æ–ª–æ–Ω–∫—É –∏ –≤—Ä–µ–º–µ–Ω–Ω—É—é –∫–æ–ª–æ–Ω–∫—É.")
                        else:
                            self.error(f"–ü—Ä–æ–±–ª–µ–º–∞ —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –Ω–∞–±–ª—é–¥–µ–Ω–∏–π: {error_msg}")
                        return
                    else:
                        # –î–ª—è –¥—Ä—É–≥–∏—Ö –æ—à–∏–±–æ–∫ ValueError
                        raise
                
                # –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ
                self.log("–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–æ–≥–Ω–æ–∑–∞...")
                known_covariates_for_prediction = None
                if self.include_holidays and 'is_holiday' in df_sorted.columns:
                    self.log("–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –±—É–¥—É—â–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø—Ä–∞–∑–¥–Ω–∏–∫–æ–≤ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞...")
                    try:
                        # –°–æ–∑–¥–∞–µ–º DataFrame —Å –±—É–¥—É—â–∏–º–∏ –¥–∞—Ç–∞–º–∏
                        future_dates_for_holidays = self.create_future_dates(self.prediction_length)
                        
                        # –°–æ–∑–¥–∞–µ–º DataFrame –¥–ª—è –±—É–¥—É—â–∏—Ö –∫–æ–≤–∞—Ä–∏–∞—Ç –¥–ª—è –∫–∞–∂–¥–æ–≥–æ item_id
                        future_df_list = []
                        all_item_ids = ts_data.item_ids
                        
                        for item_id_val in all_item_ids:
                            item_future_df = pd.DataFrame({
                                'item_id': item_id_val,  # ‚Üê –ò–ó–ú–ï–ù–ò–¢–¨: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –∏–º—è
                                'timestamp': pd.to_datetime(future_dates_for_holidays)  # ‚Üê –ò–ó–ú–ï–ù–ò–¢–¨: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –∏–º—è
                            })
                            future_df_list.append(item_future_df)
                        
                        if future_df_list:
                            future_df_for_covariates = pd.concat(future_df_list)
                            
                            # ‚Üê –ò–ó–ú–ï–ù–ò–¢–¨: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –∏–º–µ–Ω–∞ –∫–æ–ª–æ–Ω–æ–∫
                            future_df_for_covariates = future_df_for_covariates.set_index(['item_id', 'timestamp'])
                            
                            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø—Ä–∞–∑–¥–Ω–∏–∫–∏ –¥–ª—è –±—É–¥—É—â–∏—Ö –¥–∞—Ç
                            country_holidays_obj_future = holidays.CountryHoliday(
                                self.holiday_country, 
                                years=range(future_dates_for_holidays.min().year, future_dates_for_holidays.max().year + 1)
                            )
                            
                            # ‚Üê –ò–ó–ú–ï–ù–ò–¢–¨: –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –æ–±—Ä–∞—â–µ–Ω–∏–µ –∫ timestamp –≤ –∏–Ω–¥–µ–∫—Å–µ
                            future_df_for_covariates['is_holiday'] = future_df_for_covariates.index.get_level_values('timestamp').to_series().dt.normalize().apply(
                                lambda date: 1 if date in country_holidays_obj_future else 0
                            ).values
                            
                            known_covariates_for_prediction = future_df_for_covariates[['is_holiday']]
                            
                            self.log(f"–°–æ–∑–¥–∞–Ω—ã –±—É–¥—É—â–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –ø—Ä–∞–∑–¥–Ω–∏–∫–æ–≤: {known_covariates_for_prediction.shape[0]} –∑–∞–ø–∏—Å–µ–π.")
                            self.log(f"–ü—Ä–∏–º–µ—Ä –±—É–¥—É—â–∏—Ö –∫–æ–≤–∞—Ä–∏–∞—Ç:\n{known_covariates_for_prediction.head().to_string()}")
                        else:
                            self.log("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å DataFrame –¥–ª—è –±—É–¥—É—â–∏—Ö –∫–æ–≤–∞—Ä–∏–∞—Ç (–Ω–µ—Ç item_id).")

                    except Exception as e_fut_holiday:
                        self.log(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–µ –±—É–¥—É—â–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø—Ä–∞–∑–¥–Ω–∏–∫–æ–≤: {str(e_fut_holiday)}\n{traceback.format_exc()}")
                        known_covariates_for_prediction = None  # —Å–±—Ä–æ—Å –ø—Ä–∏ –æ—à–∏–±–∫–µ

                predictions = predictor.predict(ts_data, known_covariates=known_covariates_for_prediction)
                
                # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ —Å –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–æ–π –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ –¥–∞—Ç
                try:
                    self.log(f"–¢–∏–ø –ø—Ä–æ–≥–Ω–æ–∑–∞: {type(predictions)}")
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ TimeSeriesDataFrame —Å MultiIndex
                    if hasattr(predictions, 'index') and hasattr(predictions.index, 'nlevels') and predictions.index.nlevels == 2:
                        self.log("–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º TimeSeriesDataFrame —Å MultiIndex")
                        
                        # –ü–æ–ª—É—á–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ ID –∏–∑ –ø—Ä–æ–≥–Ω–æ–∑–∞ (–≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ!)
                        forecast_numeric_ids = predictions.index.get_level_values(0).unique()
                        self.log(f"–ß–∏—Å–ª–æ–≤—ã–µ ID –≤ –ø—Ä–æ–≥–Ω–æ–∑–µ (–æ—Ç AutoGluon): {forecast_numeric_ids.tolist()}")
                        
                        # –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ —Å—Ç—Ä–æ–∫–æ–≤—ã–µ ID –∏–∑ –¥–∞–Ω–Ω—ã—Ö
                        original_string_ids = self.data[self.id_column].unique()
                        self.log(f"–ò—Å—Ö–æ–¥–Ω—ã–µ —Å—Ç—Ä–æ–∫–æ–≤—ã–µ ID –≤ –¥–∞–Ω–Ω—ã—Ö: {original_string_ids}")
                        
                        # –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê: –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –¥–∞—Ç—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ ID –≤ –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                        self.log("=== –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –ò–°–•–û–î–ù–´–• –î–ê–ù–ù–´–• ===")
                        for orig_id in original_string_ids:
                            id_subset = self.data[self.data[self.id_column] == orig_id]
                            if len(id_subset) > 0:
                                sorted_subset = id_subset.sort_values(self.timestamp_column)
                                first_date = sorted_subset[self.timestamp_column].iloc[0]
                                last_date = sorted_subset[self.timestamp_column].iloc[-1]
                                self.log(f"ID '{orig_id}': {len(id_subset)} –∑–∞–ø–∏—Å–µ–π, –ø–µ—Ä–≤–∞—è: {first_date.date()}, –ø–æ—Å–ª–µ–¥–Ω—è—è: {last_date.date()}")
                            else:
                                self.log(f"ID '{orig_id}': –¥–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!")
                        self.log("=== –ö–û–ù–ï–¶ –î–ò–ê–ì–ù–û–°–¢–ò–ö–ò ===")
                        
                        # –ü—Ä–∏–º–µ–Ω—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–π –º–∞–ø–ø–∏–Ω–≥ –µ—Å–ª–∏ –µ—Å—Ç—å
                        if self.id_column in self.categorical_mapping:
                            mapping = self.categorical_mapping[self.id_column]
                            self.log(f"–ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–π –º–∞–ø–ø–∏–Ω–≥: {mapping}")
                            
                            # –°–æ–∑–¥–∞–µ–º –¥–≤—É—Å—Ç–æ—Ä–æ–Ω–Ω–∏–π –º–∞–ø–ø–∏–Ω–≥
                            numeric_to_country = {}
                            country_to_numeric = {}
                            
                            for i, country_name in enumerate(mapping):
                                numeric_id = str(float(i))  # '0.0', '1.0', '2.0'
                                numeric_to_country[numeric_id] = country_name
                                country_to_numeric[country_name] = numeric_id
                            
                            self.log(f"–ú–∞–ø–ø–∏–Ω–≥ —á–∏—Å–ª–æ–≤–æ–π -> —Å—Ç—Ä–∞–Ω–∞: {numeric_to_country}")
                            self.log(f"–ú–∞–ø–ø–∏–Ω–≥ —Å—Ç—Ä–∞–Ω–∞ -> —á–∏—Å–ª–æ–≤–æ–π: {country_to_numeric}")
                        else:
                            numeric_to_country = {str(uid): str(uid) for uid in forecast_numeric_ids}
                            country_to_numeric = {str(uid): str(uid) for uid in original_string_ids}
                        
                        # –°–æ–∑–¥–∞–µ–º –∏—Ç–æ–≥–æ–≤—ã–π DataFrame
                        all_forecast_data = []
                        
                        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π —á–∏—Å–ª–æ–≤–æ–π ID –∏–∑ –ø—Ä–æ–≥–Ω–æ–∑–∞
                        for numeric_id in forecast_numeric_ids:
                            numeric_id_str = str(numeric_id)
                            self.log(f"\n--- –û–±—Ä–∞–±–æ—Ç–∫–∞ —á–∏—Å–ª–æ–≤–æ–≥–æ ID: {numeric_id_str} ---")
                            
                            # –ü–æ–ª—É—á–∞–µ–º —á–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ
                            country_name = numeric_to_country.get(numeric_id_str, f"Unknown_{numeric_id_str}")
                            self.log(f"–ú–∞–ø–ø–∏–Ω–≥: {numeric_id_str} -> {country_name}")
                            
                            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—Ä–æ–≥–Ω–æ–∑ –¥–ª—è —ç—Ç–æ–≥–æ ID
                            id_predictions = predictions.loc[numeric_id]
                            self.log(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–≥–Ω–æ–∑–Ω—ã—Ö —Ç–æ—á–µ–∫ –¥–ª—è {country_name}: {len(id_predictions)}")
                            
                            # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ò—â–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ —á–∏—Å–ª–æ–≤–æ–º—É ID (—Ç–∞–∫ –∫–∞–∫ –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å–æ–¥–µ—Ä–∂–∞—Ç —á–∏—Å–ª–æ–≤—ã–µ ID)
                            id_data = self.data[self.data[self.id_column] == numeric_id_str]
                            
                            if len(id_data) == 0:
                                self.log(f"–ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —á–∏—Å–ª–æ–≤–æ–≥–æ ID {numeric_id_str} –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                                last_date = pd.Timestamp('2024-01-01')
                            else:
                                self.log(f"–ù–∞–π–¥–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –¥–ª—è {country_name} –ø–æ —á–∏—Å–ª–æ–≤–æ–º—É ID {numeric_id_str}: {len(id_data)} –∑–∞–ø–∏—Å–µ–π")
                                id_data_sorted = id_data.sort_values(self.timestamp_column)
                                
                                # –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–ê–Ø –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê
                                first_date = id_data_sorted[self.timestamp_column].iloc[0]
                                last_date = id_data_sorted[self.timestamp_column].iloc[-1]
                                self.log(f"–î–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç –¥–ª—è {country_name}: {first_date.date()} - {last_date.date()}")
                                
                                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 3 –∑–∞–ø–∏—Å–∏ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
                                last_records = id_data_sorted.tail(3)
                                self.log(f"–ü–æ—Å–ª–µ–¥–Ω–∏–µ –∑–∞–ø–∏—Å–∏ –¥–ª—è {country_name}:")
                                for _, row in last_records.iterrows():
                                    self.log(f"  –î–∞—Ç–∞: {row[self.timestamp_column].date()}, Target: {row[self.target_column]}")
                            
                            # –°–æ–∑–¥–∞–µ–º –±—É–¥—É—â–∏–µ –¥–∞—Ç—ã –¥–ª—è —ç—Ç–æ–≥–æ ID
                            future_dates = self.create_future_dates_for_specific_id(last_date, model_freq)
                            self.log(f"–ü—Ä–æ–≥–Ω–æ–∑–Ω—ã–µ –¥–∞—Ç—ã –¥–ª—è {country_name}: {future_dates[0].strftime('%Y-%m-%d')} - {future_dates[-1].strftime('%Y-%m-%d')}")
                            
                            # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—ã–π –ø—Ä–æ–≥–Ω–æ–∑ –¥–ª—è —ç—Ç–æ–≥–æ ID
                            id_forecast = pd.DataFrame()
                            id_forecast[self.id_column] = [country_name] * len(future_dates)
                            id_forecast['timestamp'] = [d.strftime('%Y-%m-%d') for d in future_dates]
                            
                            # –ö–æ–ø–∏—Ä—É–µ–º —á–∏—Å–ª–æ–≤—ã–µ –ø—Ä–æ–≥–Ω–æ–∑–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
                            for col in id_predictions.columns:
                                if pd.api.types.is_numeric_dtype(id_predictions[col]):
                                    values = id_predictions[col].values
                                    if len(values) >= len(future_dates):
                                        cleaned_values = np.maximum(values[:len(future_dates)], 0).round(0).astype(int)
                                    else:
                                        cleaned_values = np.maximum(values, 0).round(0).astype(int)
                                        if len(cleaned_values) < len(future_dates):
                                            last_val = cleaned_values[-1] if len(cleaned_values) > 0 else 0
                                            additional = [last_val] * (len(future_dates) - len(cleaned_values))
                                            cleaned_values = np.concatenate([cleaned_values, additional])
                                    
                                    id_forecast[col] = cleaned_values
                            
                            all_forecast_data.append(id_forecast)
                            self.log(f"–î–æ–±–∞–≤–ª–µ–Ω –ø—Ä–æ–≥–Ω–æ–∑ –¥–ª—è {country_name}")
                        
                        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –ø—Ä–æ–≥–Ω–æ–∑—ã
                        if all_forecast_data:
                            forecast_df = pd.concat(all_forecast_data, ignore_index=True)
                            self.log(f"\n–ò—Ç–æ–≥–æ–≤—ã–π –ø—Ä–æ–≥–Ω–æ–∑: {len(forecast_df)} –∑–∞–ø–∏—Å–µ–π –¥–ª—è {len(all_forecast_data)} —Å—Ç—Ä–∞–Ω")
                            
                            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏—Ç–æ–≥–æ–≤–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
                            for country in forecast_df[self.id_column].unique():
                                country_data = forecast_df[forecast_df[self.id_column] == country]
                                dates = country_data['timestamp'].tolist()
                                self.log(f"–ò—Ç–æ–≥–æ–≤—ã–µ –¥–∞—Ç—ã –¥–ª—è {country}: {dates[0]} - {dates[-1]}")
                            
                            pred_df = forecast_df.copy()
                        else:
                            self.log("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –ø—Ä–æ–≥–Ω–æ–∑–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")
                            pred_df = predictions.reset_index()
                    
                    else:
                        # –ó–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç –¥–ª—è –ø–ª–æ—Å–∫–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞
                        self.log("–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–ª–æ—Å–∫–∏–π DataFrame (–∑–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç)")
                        pred_df = predictions.reset_index() if hasattr(predictions, 'reset_index') else predictions
                        
                        unique_ids = self.data[self.id_column].unique()
                        records_per_id = self.prediction_length
                        all_forecast_data = []
                        
                        for idx, uid in enumerate(unique_ids):
                            start_idx = idx * records_per_id
                            end_idx = start_idx + records_per_id
                            
                            if end_idx <= len(pred_df):
                                id_data = self.data[self.data[self.id_column] == uid]
                                if len(id_data) > 0:
                                    id_data_sorted = id_data.sort_values(self.timestamp_column)
                                    last_date = id_data_sorted[self.timestamp_column].iloc[-1]
                                else:
                                    last_date = pd.Timestamp('2024-01-01')
                                
                                future_dates = self.create_future_dates_for_specific_id(last_date)
                                id_predictions = pred_df.iloc[start_idx:end_idx]
                                
                                id_forecast = pd.DataFrame()
                                id_forecast[self.id_column] = [uid] * len(future_dates)
                                id_forecast['timestamp'] = [d.strftime('%Y-%m-%d') for d in future_dates]
                                
                                for col in id_predictions.columns:
                                    if (pd.api.types.is_numeric_dtype(id_predictions[col]) and 
                                        col not in [self.id_column, 'timestamp']):
                                        values = id_predictions[col].values
                                        cleaned_values = np.maximum(values, 0).round(0).astype(int)
                                        id_forecast[col] = cleaned_values
                                
                                all_forecast_data.append(id_forecast)
                        
                        if all_forecast_data:
                            pred_df = pd.concat(all_forecast_data, ignore_index=True)
                        
                    # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                    self.log(f"–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∏—Ç–æ–≥–æ–≤–æ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑–∞: {pred_df.dtypes}")
                    self.log(f"–ü—Ä–∏–º–µ—Ä –ø—Ä–æ–≥–Ω–æ–∑–∞:\n{pred_df.head(3).to_string()}")
                                    
                except Exception as e:
                    self.log(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–µ –ø—Ä–æ–≥–Ω–æ–∑–∞: {str(e)}\n{traceback.format_exc()}")
                    pred_df = predictions.reset_index() if hasattr(predictions, 'reset_index') else predictions
                
                # –û—Ç–ø—Ä–∞–≤–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                self.log("–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–≥–Ω–æ–∑–∞ –≤ —Ç–∞–±–ª–∏—Ü—É Orange...")
                pred_table = self.df_to_table(pred_df)
                self.Outputs.prediction.send(pred_table)
                
                # –õ–∏–¥–µ—Ä–±–æ—Ä–¥
                try:
                    lb = predictor.leaderboard()
                    if lb is not None and not lb.empty:
                        self.log("–§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –ª–∏–¥–µ—Ä–±–æ—Ä–¥–∞...")
                        # –û–∫—Ä—É–≥–ª–µ–Ω–∏–µ —á–∏—Å–ª–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
                        for col in lb.select_dtypes(include=['float']).columns:
                            lb[col] = lb[col].round(4)
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º/–∏—Å–ø—Ä–∞–≤–ª—è–µ–º –∏–º–µ–Ω–∞ –∫–æ–ª–æ–Ω–æ–∫
                        lb.columns = [str(col).replace(' ', '_').replace('-', '_') for col in lb.columns]
                        
                        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤—Å–µ –æ–±—ä–µ–∫—Ç–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –≤ —Å—Ç—Ä–æ–∫–∏
                        for col in lb.select_dtypes(include=['object']).columns:
                            lb[col] = lb[col].astype(str)
                            
                        self.log(f"–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ª–∏–¥–µ—Ä–±–æ—Ä–¥–∞: {lb.dtypes}")
                        
                        lb_table = self.df_to_table(lb)
                        self.Outputs.leaderboard.send(lb_table)
                except Exception as lb_err:
                    self.log(f"–û—à–∏–±–∫–∞ –ª–∏–¥–µ—Ä–±–æ—Ä–¥–∞: {str(lb_err)}\n{traceback.format_exc()}")
                
                # –ò–Ω—Ñ–æ –æ –º–æ–¥–µ–ª–∏
                self.log("–§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–æ–¥–µ–ª–∏...")
                
                # –ü–æ–ª—É—á–∞–µ–º –ø–æ–Ω—è—Ç–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —á–∞—Å—Ç–æ—Ç—ã
                freq_name = model_freq
                for code, label in self.FREQUENCIES:
                    if code == model_freq:
                        freq_name = f"{label} ({code})"
                        break
                
                # –ü–æ–ª—É—á–∞–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å, –µ—Å–ª–∏ –ª–∏–¥–µ—Ä–±–æ—Ä–¥ –¥–æ—Å—Ç—É–ø–µ–Ω
                best_model_name = "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
                best_model_score = "–ù/–î"
                
                try:
                    if 'lb' in locals() and lb is not None and not lb.empty:
                        best_model_name = lb.iloc[0]['model']
                        best_model_score = f"{lb.iloc[0]['score_val']:.4f}"
                        
                        # –õ–æ–≥–∏—Ä—É–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ª—É—á—à–∏—Ö –º–æ–¥–µ–ª—è—Ö
                        self.log(f"–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: {best_model_name}, –û—Ü–µ–Ω–∫–∞: {best_model_score}")
                        
                        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ø-3 –º–æ–¥–µ–ª–∏ –µ—Å–ª–∏ –∏—Ö —Å—Ç–æ–ª—å–∫–æ –µ—Å—Ç—å
                        if len(lb) > 1:
                            self.log("–¢–æ–ø –º–æ–¥–µ–ª–∏:")
                            for i in range(min(3, len(lb))):
                                model = lb.iloc[i]['model']
                                score = lb.iloc[i]['score_val']
                                self.log(f"  {i+1}. {model}: {score:.4f}")
                except Exception as e:
                    self.log(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏: {str(e)}")
                
                # –°–æ–∑–¥–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏
                model_info = pd.DataFrame({
                    'Parameter': ['–í–µ—Ä—Å–∏—è', '–¶–µ–ª—å', '–î–ª–∏–Ω–∞', '–ú–µ—Ç—Ä–∏–∫–∞', '–ü—Ä–µ—Å–µ—Ç', 
                                '–í—Ä–µ–º—è', '–ü—Ä–∞–∑–¥–Ω–∏–∫–∏', '–ß–∞—Å—Ç–æ—Ç–∞', '–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å', '–û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏'],
                    'Value': ['1.2.0', self.target_column, str(self.prediction_length),
                              metric, self.selected_preset, 
                              f"{self.time_limit} —Å–µ–∫", 
                              "–í–∫–ª—é—á–µ–Ω—ã" if self.include_holidays else "–û—Ç–∫–ª—é—á–µ–Ω—ã",
                              freq_name,
                              best_model_name,
                              best_model_score]
                })
                self.Outputs.model_info.send(self.df_to_table(model_info))
                
                # –ó–∞–∫—Ä—ã–≤–∞–µ–º –ª–æ–≥–≥–µ—Ä—ã, —á—Ç–æ–±—ã –Ω–µ –±—ã–ª–æ WinError 32
                import logging
                logging.shutdown()
                
            self.log("=== –£–°–ü–ï–®–ù–û ===")
            
        except Exception as e:
            self.log(f"–û–®–ò–ë–ö–ê: {str(e)}\n{traceback.format_exc()}")
            self.error(str(e))
        finally:
            self.progressBarFinished()
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∂—É—Ä–Ω–∞–ª
            self.Outputs.log_messages.send(self.log_messages)

    def df_to_table(self, df):
        """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ DataFrame –≤ —Ç–∞–±–ª–∏—Ü—É Orange"""
        try:
            # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ DataFrame –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∏–Ω–¥–µ–∫—Å–æ–≤
            df = df.reset_index(drop=True).copy()
            
            # –†–∞–∑–¥–µ–ª—å–Ω—ã–µ —Å–ø–∏—Å–∫–∏ –¥–ª—è –∞—Ç—Ä–∏–±—É—Ç–æ–≤, –∫–ª–∞—Å—Å–æ–≤ –∏ –º–µ—Ç–∞-–ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
            attrs = []
            metas = []
            
            # –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤—Å–µ—Ö —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö –∏ —Å–æ–∑–¥–∞–Ω–∏–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
            X_cols = []  # –î–ª—è –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö (–∞—Ç—Ä–∏–±—É—Ç–æ–≤)
            M_cols = []  # –î–ª—è —Å—Ç—Ä–æ–∫–æ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö (–º–µ—Ç–∞)
            
            for col in df.columns:
                # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è ID –∫–æ–ª–æ–Ω–∫–∏
                if col == self.id_column:
                    # ID –∫–æ–ª–æ–Ω–∫—É –≤—Å–µ–≥–¥–∞ —Ö—Ä–∞–Ω–∏–º –∫–∞–∫ –º–µ—Ç–∞-–ø–µ—Ä–µ–º–µ–Ω–Ω—É—é
                    df[col] = df[col].fillna('').astype(str)
                    metas.append(StringVariable(name=str(col)))
                    M_cols.append(col)
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —á–∏—Å–ª–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ - –∏–¥—É—Ç –≤ X
                elif pd.api.types.is_numeric_dtype(df[col]):
                    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ float, –∫–æ—Ç–æ—Ä—ã–π Orange –º–æ–∂–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å
                    df[col] = pd.to_numeric(df[col], errors='coerce').fillna(float('nan')).astype(float)
                    attrs.append(ContinuousVariable(name=str(col)))
                    X_cols.append(col)
                else:
                    # –í—Å–µ –Ω–µ—á–∏—Å–ª–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–¥—É—Ç –≤ –º–µ—Ç–∞
                    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–∞—Ç—ã
                    if pd.api.types.is_datetime64_dtype(df[col]):
                        df[col] = df[col].dt.strftime('%Y-%m-%d')
                    
                    # –í—Å–µ –æ—Å—Ç–∞–ª—å–Ω–æ–µ - –≤ —Å—Ç—Ä–æ–∫–∏
                    df[col] = df[col].fillna('').astype(str)
                    metas.append(StringVariable(name=str(col)))
                    M_cols.append(col)
            
            self.log(f"–ê—Ç—Ä–∏–±—É—Ç—ã: {[v.name for v in attrs]}")
            self.log(f"–ú–µ—Ç–∞: {[v.name for v in metas]}")
            
            # –°–æ–∑–¥–∞–µ–º –¥–æ–º–µ–Ω
            domain = Domain(attrs, metas=metas)
            
            # –°–æ–∑–¥–∞–µ–º –º–∞—Å—Å–∏–≤—ã –¥–ª—è X –∏ M
            if X_cols:
                X = df[X_cols].values
            else:
                X = np.zeros((len(df), 0))
                
            if M_cols:
                M = df[M_cols].values
            else:
                M = np.zeros((len(df), 0), dtype=object)
            
            # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É —Å –ø–æ–º–æ—â—å—é from_numpy
            return Table.from_numpy(domain, X, metas=M)
            
        except Exception as e:
            self.log(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è DataFrame –≤ Table: {str(e)}\n{traceback.format_exc()}")
            raise

if __name__ == "__main__":
    WidgetPreview(OWAutoGluonTimeSeries).run()
