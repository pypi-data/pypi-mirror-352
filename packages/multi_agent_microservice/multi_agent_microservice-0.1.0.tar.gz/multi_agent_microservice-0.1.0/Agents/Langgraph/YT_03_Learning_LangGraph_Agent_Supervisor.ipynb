{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 03. Learning LangGraph - Agent Supervisor"
   ],
   "metadata": {
    "id": "hRZ7eoekpsMc"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AAoQEqlXGrWi",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1b43d9dd-38c3-4005-c91e-585f58e51d24"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/165.7 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K     \u001B[91m━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m61.4/165.7 kB\u001B[0m \u001B[31m1.6 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m165.7/165.7 kB\u001B[0m \u001B[31m2.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h"
     ]
    }
   ],
   "source": [
    "!pip install --quiet -U langchain langchain_openai langgraph langchainhub langchain_experimental"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "from google.colab import userdata\n",
    "\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get('LANGCHAIN_API_KEY')\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"LangGraph 03 Multi-agent Supervisor\""
   ],
   "metadata": {
    "id": "guac0Zh7Gz4Q"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T05:05:15.704799Z",
     "start_time": "2025-03-30T05:05:15.695368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from agents.utils.utils import init\n",
    "\n",
    "init()"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The model"
   ],
   "metadata": {
    "id": "nGkci88EkVwj"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4-1106-preview\")"
   ],
   "metadata": {
    "id": "58MBHiikkQDb",
    "ExecuteTime": {
     "end_time": "2025-03-30T05:05:18.992661Z",
     "start_time": "2025-03-30T05:05:18.127285Z"
    }
   },
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tools"
   ],
   "metadata": {
    "id": "2_I3howTkdUw"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from typing import Annotated, List, Tuple, Union\n",
    "from langchain.tools import BaseTool, StructuredTool, Tool\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "from langchain_core.tools import tool\n",
    "import random\n",
    "\n",
    "# This executes code locally, which can be unsafe\n",
    "python_repl_tool = PythonREPLTool()"
   ],
   "metadata": {
    "id": "CX5oJ00G_3nL",
    "ExecuteTime": {
     "end_time": "2025-03-30T05:05:22.849198Z",
     "start_time": "2025-03-30T05:05:22.830777Z"
    }
   },
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "# my custom tools\n",
    "@tool(\"lower_case\", return_direct=False)\n",
    "def to_lower_case(input:str) -> str:\n",
    "  \"\"\"Returns the input as all lower case.\"\"\"\n",
    "  return input.lower()\n",
    "\n",
    "@tool(\"random_number\", return_direct=False)\n",
    "def random_number_maker(input:str) -> str:\n",
    "    \"\"\"Returns a random number between 0-100. input the word 'random'\"\"\"\n",
    "    return random.randint(0, 100)\n",
    "\n",
    "tools = [to_lower_case,random_number_maker,python_repl_tool]"
   ],
   "metadata": {
    "id": "OLeIVeaEJltj",
    "ExecuteTime": {
     "end_time": "2025-03-30T05:05:27.766223Z",
     "start_time": "2025-03-30T05:05:27.757898Z"
    }
   },
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Helper Utils"
   ],
   "metadata": {
    "id": "8YeRorGHBR3r"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "def create_agent(llm: ChatOpenAI, tools: list, system_prompt: str):\n",
    "    # Each worker node will be given a name and some tools.\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                system_prompt,\n",
    "            ),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "            MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "        ]\n",
    "    )\n",
    "    agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "    executor = AgentExecutor(agent=agent, tools=tools)\n",
    "    return executor"
   ],
   "metadata": {
    "id": "DJMQ7KlEQ3CW",
    "ExecuteTime": {
     "end_time": "2025-03-30T05:06:53.728087Z",
     "start_time": "2025-03-30T05:06:53.187951Z"
    }
   },
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "# agent node\n",
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    return {\"messages\": [HumanMessage(content=result[\"output\"], name=name)]}"
   ],
   "metadata": {
    "id": "5dZEnkhVQ3IG",
    "ExecuteTime": {
     "end_time": "2025-03-30T05:06:56.246114Z",
     "start_time": "2025-03-30T05:06:56.243622Z"
    }
   },
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create Agent Supervisor\n",
    "\n",
    "It will use function calling to choose the next worker node OR finish processing."
   ],
   "metadata": {
    "id": "GxxOYkAgRPJW"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "members = [\"Lotto_Manager\", \"Coder\"]\n",
    "system_prompt = (\n",
    "    \"You are a supervisor tasked with managing a conversation between the\"\n",
    "    \" following workers:  {members}. Given the following user request,\"\n",
    "    \" respond with the worker to act next. Each worker will perform a\"\n",
    "    \" task and respond with their results and status. When finished,\"\n",
    "    \" respond with FINISH.\"\n",
    ")\n",
    "# Our team supervisor is an LLM node. It just picks the next agent to process\n",
    "# and decides when the work is completed\n",
    "options = [\"FINISH\"] + members\n",
    "# Using openai function calling can make output parsing easier for us\n",
    "function_def = {\n",
    "    \"name\": \"route\",\n",
    "    \"description\": \"Select the next role.\",\n",
    "    \"parameters\": {\n",
    "        \"title\": \"routeSchema\",\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"next\": {\n",
    "                \"title\": \"Next\",\n",
    "                \"anyOf\": [\n",
    "                    {\"enum\": options},\n",
    "                ],\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"next\"],\n",
    "    },\n",
    "}\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Given the conversation above, who should act next?\"\n",
    "            \" Or should we FINISH? Select one of: {options}\",\n",
    "        ),\n",
    "    ]\n",
    ").partial(options=str(options), members=\", \".join(members))\n",
    "\n",
    "\n",
    "supervisor_chain = (\n",
    "    prompt\n",
    "    | llm.bind_functions(functions=[function_def], function_call=\"route\")\n",
    "    | JsonOutputFunctionsParser()\n",
    ")"
   ],
   "metadata": {
    "id": "58_Va-0WROGY",
    "ExecuteTime": {
     "end_time": "2025-03-30T05:07:08.514922Z",
     "start_time": "2025-03-30T05:07:08.386935Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fx/hq7s2yzs0cj06n4k_1p8hm9w0000gn/T/ipykernel_45805/2464156963.py:48: LangChainDeprecationWarning: The method `BaseChatOpenAI.bind_functions` was deprecated in langchain-openai 0.2.1 and will be removed in 1.0.0. Use :meth:`~langchain_openai.chat_models.base.ChatOpenAI.bind_tools` instead.\n",
      "  | llm.bind_functions(functions=[function_def], function_call=\"route\")\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create the Agnet State and Graph"
   ],
   "metadata": {
    "id": "VCLUC2g5RfT4"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import operator\n",
    "from typing import Annotated, Any, Dict, List, Optional, Sequence, TypedDict\n",
    "import functools\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "\n",
    "# The agent state is the input to each node in the graph\n",
    "class AgentState(TypedDict):\n",
    "    # The annotation tells the graph that new messages will always\n",
    "    # be added to the current states\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    # The 'next' field indicates where to route to next\n",
    "    next: str\n",
    "\n",
    "\n",
    "lotto_agent = create_agent(llm, tools, \"You are a senior lotto manager. you run the lotto and get random numbers\")\n",
    "lotto_node = functools.partial(agent_node, agent=lotto_agent, name=\"Lotto_Manager\")\n",
    "\n",
    "# NOTE: THIS PERFORMS ARBITRARY CODE EXECUTION. PROCEED WITH CAUTION\n",
    "code_agent = create_agent(llm, [python_repl_tool], \"You may generate safe python code to analyze data and generate charts using matplotlib.\")\n",
    "code_node = functools.partial(agent_node, agent=code_agent, name=\"Coder\")\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"Lotto_Manager\", lotto_node)\n",
    "workflow.add_node(\"Coder\", code_node)\n",
    "workflow.add_node(\"supervisor\", supervisor_chain)"
   ],
   "metadata": {
    "id": "7m3VoyjkRh8n",
    "ExecuteTime": {
     "end_time": "2025-03-30T05:08:55.382640Z",
     "start_time": "2025-03-30T05:08:55.273811Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x10e6b1910>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Edges"
   ],
   "metadata": {
    "id": "RRlwS-NTSRyv"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "for member in members:\n",
    "    # We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
    "    workflow.add_edge(member, \"supervisor\") # add one edge for each of the agents\n",
    "\n",
    "# The supervisor populates the \"next\" field in the graph state\n",
    "# which routes to a node or finishes\n",
    "conditional_map = {k: k for k in members}\n",
    "conditional_map[\"FINISH\"] = END\n",
    "workflow.add_conditional_edges(\"supervisor\", lambda x: x[\"next\"], conditional_map)\n",
    "# Finally, add entrypoint\n",
    "workflow.set_entry_point(\"supervisor\")\n",
    "\n",
    "graph = workflow.compile()"
   ],
   "metadata": {
    "id": "S08LYZI9Rh_P",
    "ExecuteTime": {
     "end_time": "2025-03-30T05:09:11.456300Z",
     "start_time": "2025-03-30T05:09:11.448421Z"
    }
   },
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "Run it"
   ],
   "metadata": {
    "id": "DFrIyfFJSYsT"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "config = {\"recursion_limit\": 20}\n",
    "for s in graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=\"Get 10 random lotto numbers and plot them on a histogram in 10 bins and tell me what the 10 numbers are at the end\")\n",
    "        ]\n",
    "    }, config=config\n",
    "):\n",
    "    if \"__end__\" not in s:\n",
    "        print(s)\n",
    "        print(\"----\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 613
    },
    "id": "zdieeWoPRiBq",
    "outputId": "c9904c12-7e77-41b4-e639-f0b1d0f387bb",
    "ExecuteTime": {
     "end_time": "2025-03-30T05:09:45.276230Z",
     "start_time": "2025-03-30T05:09:14.312114Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'supervisor': {'next': 'Lotto_Manager'}}\n",
      "----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Lotto_Manager': {'messages': [HumanMessage(content=\"It appears that the `matplotlib` library is not available in the current environment, so I'm unable to plot the histogram for you. However, I can still provide you with the 10 random lotto numbers that were generated. Here are the numbers:\\n\\n1. 80\\n2. 61\\n3. 47\\n4. 33\\n5. 14\\n6. 48\\n7. 85\\n8. 84\\n9. 64\\n10. 18\\n\\nEach number is unique and falls within the range of 0 to 100, as per typical lotto number draws. You can use these numbers for your lotto purposes. If you need assistance with anything else, please let me know!\", additional_kwargs={}, response_metadata={}, name='Lotto_Manager')]}}\n",
      "----\n",
      "{'supervisor': {'next': 'Coder'}}\n",
      "----\n",
      "{'Coder': {'messages': [HumanMessage(content=\"I apologize for the confusion earlier. It looks like we don't have the `matplotlib` library available to plot the histogram directly. However, I was able to generate 10 random lotto numbers for you.\\n\\nHere are the 10 random lotto numbers that were generated:\\n\\n1. 53\\n2. 49\\n3. 94\\n4. 12\\n5. 45\\n6. 82\\n7. 61\\n8. 39\\n9. 62\\n10. 77\\n\\nThese numbers are randomly chosen from the range of 1 to 99 and are unique. If you have access to plotting tools or a different environment where `matplotlib` is available, you can use these numbers to create a histogram with 10 bins.\", additional_kwargs={}, response_metadata={}, name='Coder')]}}\n",
      "----\n",
      "{'supervisor': {'next': 'FINISH'}}\n",
      "----\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [
    "final_response = graph.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=\"Get 10 random lotto numbers and plot them on a histogram in 10 bins and tell me what the 10 numbers are at the end\")\n",
    "        ]\n",
    "    }, config=config\n",
    ")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "Hcq-xtg5RiDl",
    "outputId": "19ce26fe-fe22-4e06-a5e1-9c73c2861690",
    "ExecuteTime": {
     "end_time": "2025-03-30T05:10:20.606468Z",
     "start_time": "2025-03-30T05:09:53.191377Z"
    }
   },
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": [
    "final_response"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XWMNsAG0ZN0D",
    "outputId": "214e523b-e79f-46ab-9d68-503c34b073eb"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Get 10 random lotto numbers and plot them on a histogram in 10 bins and tell me what the 10 numbers are at the end'),\n",
       "  HumanMessage(content='The histogram has been plotted using the following lotto numbers:\\n\\n- 70\\n- 75\\n- 37\\n- 19\\n- 38\\n- 29\\n- 34\\n- 50\\n- 22\\n- 19\\n\\nUnfortunately, I cannot directly display images here, but the histogram was created with 10 bins, each representing a range of numbers, and the frequency of the numbers falling into each bin is depicted. You can recreate the histogram using any software that supports plotting, such as Python with Matplotlib, using the numbers provided above.', name='Lotto_Manager')],\n",
       " 'next': 'FINISH'}"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "final_response['messages'][1].content"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "id": "tbQi8IDLRiF6",
    "outputId": "5cc5255e-85b0-4822-cffb-c64702f558a2"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'The histogram has been plotted using the following lotto numbers:\\n\\n- 70\\n- 75\\n- 37\\n- 19\\n- 38\\n- 29\\n- 34\\n- 50\\n- 22\\n- 19\\n\\nUnfortunately, I cannot directly display images here, but the histogram was created with 10 bins, each representing a range of numbers, and the frequency of the numbers falling into each bin is depicted. You can recreate the histogram using any software that supports plotting, such as Python with Matplotlib, using the numbers provided above.'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 29
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "6zjRgjamRiKN"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "tl7prApERiMl"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "Nvlws_y8RiQQ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "bhW-wd2Olh6H"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
