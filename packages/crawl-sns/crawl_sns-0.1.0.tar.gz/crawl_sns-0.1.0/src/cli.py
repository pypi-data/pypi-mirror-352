"""
@file cli.py
@description SNS í¬ë¡¤ë§ CLI ì¸í„°í˜ì´ìŠ¤

ì´ ëª¨ë“ˆì€ ì—¬ëŸ¬ SNS í”Œë«í¼ì˜ ê²Œì‹œê¸€ì„ í¬ë¡¤ë§í•˜ê¸° ìœ„í•œ ëª…ë ¹ì¤„ ì¸í„°í˜ì´ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
1. í”Œë«í¼ë³„ í¬ë¡¤ë§ ëª…ë ¹ì–´ (threads, linkedin, x, reddit)
2. í†µì¼ëœ í¬ë¡¤ë§ ì˜µì…˜ ì„¤ì • (ê²Œì‹œê¸€ ìˆ˜, ì €ì¥ ìœ„ì¹˜, ë””ë²„ê·¸ ëª¨ë“œ)
3. ì¼ê´€ëœ ê²°ê³¼ ì¶œë ¥ ë° ì €ì¥

í•µì‹¬ êµ¬í˜„ ë¡œì§:
- Typerë¥¼ ì‚¬ìš©í•œ ì§ê´€ì ì¸ CLI ì¸í„°í˜ì´ìŠ¤
- ë¡œê¹… ë°ì½”ë ˆì´í„°ë¥¼ í†µí•œ í†µì¼ëœ ì‘ì—… ì¶”ì 
- ëª¨ë“  í”Œë«í¼ì—ì„œ ë™ì¼í•œ ì¶œë ¥ í˜•ì‹ ì œê³µ

@dependencies
- typer: CLI í”„ë ˆì„ì›Œí¬
- asyncio: ë¹„ë™ê¸° ì²˜ë¦¬
- datetime: íŒŒì¼ëª… ìƒì„±ìš©
- pathlib: ë””ë ‰í† ë¦¬ ê´€ë¦¬
"""

import asyncio
import json
from datetime import datetime
from pathlib import Path
from typing import List, Optional

import typer

from .crawlers import LinkedInCrawler, RedditCrawler, ThreadsCrawler, XCrawler
from .exporters import SheetsExporter
from .models import Post
from .print import (
    log_crawl_operation,
    print_crawl_summary,
    print_no_posts_error,
    print_post_preview,
)

# === App Configuration ===
app = typer.Typer(
    name="crawl-sns",
    help="SNS í”Œë«í¼(Threads, LinkedIn, X, Reddit) í¬ë¡¤ë§ ë„êµ¬",
    add_completion=False,
    no_args_is_help=True,
    context_settings={"help_option_names": ["-h", "--help"]},
)

__version__ = "0.1.0"


# === Utility Functions ===
def save_posts_to_file(posts: List[Post], filepath: str) -> None:
    """ê²Œì‹œê¸€ ëª©ë¡ì„ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
    output_data = {
        "metadata": {
            "total_posts": len(posts),
            "crawled_at": datetime.now().isoformat(),
            "platform": posts[0].platform if posts else "unknown",
        },
        "posts": [post.model_dump() for post in posts],
    }

    with open(filepath, "w", encoding="utf-8") as f:
        json.dump(output_data, f, ensure_ascii=False, indent=2)


def generate_output_filename(platform: str, custom_output: Optional[str] = None) -> str:
    """ì¶œë ¥ íŒŒì¼ëª…ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    if custom_output:
        return custom_output

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    return f"data/{platform}_{timestamp}.json"


def ensure_data_directory() -> None:
    """data ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ê³  ìƒì„±í•©ë‹ˆë‹¤."""
    Path("data").mkdir(exist_ok=True)


def handle_sheets_export(posts: List[Post], platform: str) -> bool:
    """êµ¬ê¸€ ì‹œíŠ¸ ìµìŠ¤í¬íŠ¸ë¥¼ ì²˜ë¦¬í•˜ê³  ì„±ê³µ ì—¬ë¶€ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        exporter = SheetsExporter()
        return exporter.export_posts(posts, platform)
    except ValueError as e:
        typer.echo(f"âŒ êµ¬ê¸€ ì‹œíŠ¸ ì„¤ì • ì˜¤ë¥˜: {str(e)}")
        return False
    except Exception as e:
        typer.echo(f"âŒ êµ¬ê¸€ ì‹œíŠ¸ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return False


def process_crawl_results(
    posts: List[Post], platform: str, output: Optional[str], debug: bool, sheets: bool
) -> None:
    """í¬ë¡¤ë§ ê²°ê³¼ë¥¼ ì²˜ë¦¬í•˜ê³  ì €ì¥í•©ë‹ˆë‹¤."""
    if not posts:
        print_no_posts_error(platform, debug)
        raise typer.Exit(1)

    # JSON íŒŒì¼ ì €ì¥ (ê¸°ë³¸)
    ensure_data_directory()
    output_file = generate_output_filename(platform, output)
    save_posts_to_file(posts, output_file)

    # êµ¬ê¸€ ì‹œíŠ¸ ì €ì¥ (ì˜µì…˜)
    sheets_success = False
    if sheets:
        sheets_success = handle_sheets_export(posts, platform)

    # ê²°ê³¼ ì¶œë ¥
    print_crawl_summary(platform, len(posts), output_file, debug)
    if sheets:
        if sheets_success:
            typer.echo("   ğŸ“Š êµ¬ê¸€ ì‹œíŠ¸ ì €ì¥: âœ… ì„±ê³µ")
        else:
            typer.echo("   ğŸ“Š êµ¬ê¸€ ì‹œíŠ¸ ì €ì¥: âŒ ì‹¤íŒ¨ (JSON íŒŒì¼ì€ ì €ì¥ë¨)")

    print_post_preview(posts[0], platform)


# === Platform Crawling Commands ===
@app.command()
@log_crawl_operation("threads")
def threads(
    count: int = typer.Option(5, "--count", "-c", help="ìˆ˜ì§‘í•  ê²Œì‹œê¸€ ìˆ˜"),
    output: Optional[str] = typer.Option(
        None, "--output", "-o", help="ì¶œë ¥ íŒŒì¼ëª… (ê¸°ë³¸: ìë™ ìƒì„±)"
    ),
    debug: bool = typer.Option(
        False, "--debug", "-d", help="ë””ë²„ê·¸ ëª¨ë“œ í™œì„±í™” (ë¸Œë¼ìš°ì € í‘œì‹œ, ìƒì„¸ ë¡œê·¸, ìŠ¤í¬ë¦°ìƒ·)"
    ),
    sheets: bool = typer.Option(
        False, "--sheets", "-s", help="êµ¬ê¸€ ì‹œíŠ¸ì— ì €ì¥ (GOOGLE_WEBAPP_URL í™˜ê²½ë³€ìˆ˜ í•„ìš”)"
    ),
):
    """
    Threadsì—ì„œ ê²Œì‹œê¸€ì„ í¬ë¡¤ë§í•©ë‹ˆë‹¤.

    ì˜ˆì‹œ:
    crawl-sns threads --count 10
    crawl-sns threads -c 3 -o my_threads.json
    crawl-sns threads --debug  # ë””ë²„ê·¸ ëª¨ë“œë¡œ ì‹¤í–‰
    crawl-sns threads --sheets  # êµ¬ê¸€ ì‹œíŠ¸ì— ì €ì¥
    crawl-sns threads -c 5 -s  # 5ê°œ ê²Œì‹œê¸€ì„ êµ¬ê¸€ ì‹œíŠ¸ì— ì €ì¥
    """
    crawler = ThreadsCrawler(debug_mode=debug)
    posts = asyncio.run(crawler.crawl(count))
    process_crawl_results(posts, "threads", output, debug, sheets)


@app.command()
@log_crawl_operation("linkedin")
def linkedin(
    count: int = typer.Option(5, "--count", "-c", help="ìˆ˜ì§‘í•  ê²Œì‹œê¸€ ìˆ˜"),
    output: Optional[str] = typer.Option(
        None, "--output", "-o", help="ì¶œë ¥ íŒŒì¼ëª… (ê¸°ë³¸: ìë™ ìƒì„±)"
    ),
    debug: bool = typer.Option(
        False, "--debug", "-d", help="ë””ë²„ê·¸ ëª¨ë“œ í™œì„±í™” (ë¸Œë¼ìš°ì € í‘œì‹œ, ìƒì„¸ ë¡œê·¸)"
    ),
    sheets: bool = typer.Option(
        False, "--sheets", "-s", help="êµ¬ê¸€ ì‹œíŠ¸ì— ì €ì¥ (GOOGLE_WEBAPP_URL í™˜ê²½ë³€ìˆ˜ í•„ìš”)"
    ),
):
    """
    LinkedInì—ì„œ ê²Œì‹œê¸€ì„ í¬ë¡¤ë§í•©ë‹ˆë‹¤.

    ì˜ˆì‹œ:
    crawl-sns linkedin --count 10
    crawl-sns linkedin -c 3 -o my_linkedin.json
    crawl-sns linkedin --debug  # ë””ë²„ê·¸ ëª¨ë“œë¡œ ì‹¤í–‰
    crawl-sns linkedin --sheets  # êµ¬ê¸€ ì‹œíŠ¸ì— ì €ì¥
    crawl-sns linkedin -c 5 -s  # 5ê°œ ê²Œì‹œê¸€ì„ êµ¬ê¸€ ì‹œíŠ¸ì— ì €ì¥
    """
    crawler = LinkedInCrawler(debug_mode=debug)
    posts = asyncio.run(crawler.crawl(count))
    process_crawl_results(posts, "linkedin", output, debug, sheets)


@app.command()
@log_crawl_operation("x")
def x(
    count: int = typer.Option(10, "--count", "-c", help="ìˆ˜ì§‘í•  ê²Œì‹œê¸€ ìˆ˜"),
    output: Optional[str] = typer.Option(
        None, "--output", "-o", help="ì¶œë ¥ íŒŒì¼ëª… (ê¸°ë³¸: ìë™ ìƒì„±)"
    ),
    debug: bool = typer.Option(False, "--debug", "-d", help="ë””ë²„ê·¸ ëª¨ë“œ"),
    sheets: bool = typer.Option(
        False, "--sheets", "-s", help="êµ¬ê¸€ ì‹œíŠ¸ì— ì €ì¥ (GOOGLE_WEBAPP_URL í™˜ê²½ë³€ìˆ˜ í•„ìš”)"
    ),
):
    """
    X(Twitter)ì—ì„œ ê²Œì‹œê¸€ì„ í¬ë¡¤ë§í•©ë‹ˆë‹¤.

    ì˜ˆì‹œ:
    crawl-sns x --count 15
    crawl-sns x -c 5 -o my_tweets.json
    crawl-sns x --debug  # ë””ë²„ê·¸ ëª¨ë“œë¡œ ì‹¤í–‰
    crawl-sns x --sheets  # êµ¬ê¸€ ì‹œíŠ¸ì— ì €ì¥
    crawl-sns x -c 10 -s  # 10ê°œ ê²Œì‹œê¸€ì„ êµ¬ê¸€ ì‹œíŠ¸ì— ì €ì¥
    """
    crawler = XCrawler(debug_mode=debug)
    posts = asyncio.run(crawler.crawl(count))
    process_crawl_results(posts, "x", output, debug, sheets)


@app.command()
@log_crawl_operation("reddit")
def reddit(
    count: int = typer.Option(10, "--count", "-c", help="ìˆ˜ì§‘í•  ê²Œì‹œê¸€ ìˆ˜"),
    output: Optional[str] = typer.Option(
        None, "--output", "-o", help="ì¶œë ¥ íŒŒì¼ëª… (ê¸°ë³¸: ìë™ ìƒì„±)"
    ),
    debug: bool = typer.Option(False, "--debug", "-d", help="ë””ë²„ê·¸ ëª¨ë“œ"),
    sheets: bool = typer.Option(
        False, "--sheets", "-s", help="êµ¬ê¸€ ì‹œíŠ¸ì— ì €ì¥ (GOOGLE_WEBAPP_URL í™˜ê²½ë³€ìˆ˜ í•„ìš”)"
    ),
):
    """
    Redditì—ì„œ ê²Œì‹œê¸€ì„ í¬ë¡¤ë§í•©ë‹ˆë‹¤.

    ì˜ˆì‹œ:
    crawl-sns reddit --count 15
    crawl-sns reddit -c 5 -o my_reddit.json
    crawl-sns reddit --debug  # ë””ë²„ê·¸ ëª¨ë“œë¡œ ì‹¤í–‰
    crawl-sns reddit --sheets  # êµ¬ê¸€ ì‹œíŠ¸ì— ì €ì¥
    crawl-sns reddit -c 10 -s  # 10ê°œ ê²Œì‹œê¸€ì„ êµ¬ê¸€ ì‹œíŠ¸ì— ì €ì¥
    """
    crawler = RedditCrawler(debug_mode=debug)
    posts = asyncio.run(crawler.crawl(count))
    process_crawl_results(posts, "reddit", output, debug, sheets)


@app.command()
def version():
    """ë²„ì „ ì •ë³´ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤."""
    typer.echo(f"crawl-sns version {__version__}")


@app.command()
def status():
    """ë„êµ¬ ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤."""
    typer.echo("ğŸ”§ crawl-sns ìƒíƒœ í™•ì¸")
    typer.echo("âœ… ëª¨ë“  ì‹œìŠ¤í…œì´ ì •ìƒì ìœ¼ë¡œ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤.")


def main():
    """CLI ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì§„ì…ì ì…ë‹ˆë‹¤."""
    app()


if __name__ == "__main__":
    main()
