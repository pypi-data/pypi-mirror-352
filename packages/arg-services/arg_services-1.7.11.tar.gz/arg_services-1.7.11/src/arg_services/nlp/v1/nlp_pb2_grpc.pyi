"""
@generated by mypy-protobuf.  Do not edit manually!
isort:skip_file
Service for offloading computationally complex NLP tasks."""

import abc
import arg_services.nlp.v1.nlp_pb2
import collections.abc
import grpc
import grpc.aio
import typing

_T = typing.TypeVar("_T")

class _MaybeAsyncIterator(collections.abc.AsyncIterator[_T], collections.abc.Iterator[_T], metaclass=abc.ABCMeta): ...

class _ServicerContext(grpc.ServicerContext, grpc.aio.ServicerContext):  # type: ignore[misc, type-arg]
    ...

class NlpServiceStub:
    def __init__(self, channel: typing.Union[grpc.Channel, grpc.aio.Channel]) -> None: ...
    Vectors: grpc.UnaryUnaryMultiCallable[
        arg_services.nlp.v1.nlp_pb2.VectorsRequest,
        arg_services.nlp.v1.nlp_pb2.VectorsResponse,
    ]
    """Compute embeddings (i.e., vectors) for strings."""

    Similarities: grpc.UnaryUnaryMultiCallable[
        arg_services.nlp.v1.nlp_pb2.SimilaritiesRequest,
        arg_services.nlp.v1.nlp_pb2.SimilaritiesResponse,
    ]
    """Compute the similarity score between two strings."""

    DocBin: grpc.UnaryUnaryMultiCallable[
        arg_services.nlp.v1.nlp_pb2.DocBinRequest,
        arg_services.nlp.v1.nlp_pb2.DocBinResponse,
    ]
    """Process strings by spacy and return them as [binary data](https://spacy.io/api/docbin).
    Locally, spacy can restore this data **without** loading the underlying NLP models into the main memory.
    Allows one to retrieve all computed attributes (e.g., POS tags, sentences), but can only be used by Python programs.
    """

class NlpServiceAsyncStub:
    Vectors: grpc.aio.UnaryUnaryMultiCallable[
        arg_services.nlp.v1.nlp_pb2.VectorsRequest,
        arg_services.nlp.v1.nlp_pb2.VectorsResponse,
    ]
    """Compute embeddings (i.e., vectors) for strings."""

    Similarities: grpc.aio.UnaryUnaryMultiCallable[
        arg_services.nlp.v1.nlp_pb2.SimilaritiesRequest,
        arg_services.nlp.v1.nlp_pb2.SimilaritiesResponse,
    ]
    """Compute the similarity score between two strings."""

    DocBin: grpc.aio.UnaryUnaryMultiCallable[
        arg_services.nlp.v1.nlp_pb2.DocBinRequest,
        arg_services.nlp.v1.nlp_pb2.DocBinResponse,
    ]
    """Process strings by spacy and return them as [binary data](https://spacy.io/api/docbin).
    Locally, spacy can restore this data **without** loading the underlying NLP models into the main memory.
    Allows one to retrieve all computed attributes (e.g., POS tags, sentences), but can only be used by Python programs.
    """

class NlpServiceServicer(metaclass=abc.ABCMeta):
    @abc.abstractmethod
    def Vectors(
        self,
        request: arg_services.nlp.v1.nlp_pb2.VectorsRequest,
        context: _ServicerContext,
    ) -> typing.Union[arg_services.nlp.v1.nlp_pb2.VectorsResponse, collections.abc.Awaitable[arg_services.nlp.v1.nlp_pb2.VectorsResponse]]:
        """Compute embeddings (i.e., vectors) for strings."""

    @abc.abstractmethod
    def Similarities(
        self,
        request: arg_services.nlp.v1.nlp_pb2.SimilaritiesRequest,
        context: _ServicerContext,
    ) -> typing.Union[arg_services.nlp.v1.nlp_pb2.SimilaritiesResponse, collections.abc.Awaitable[arg_services.nlp.v1.nlp_pb2.SimilaritiesResponse]]:
        """Compute the similarity score between two strings."""

    @abc.abstractmethod
    def DocBin(
        self,
        request: arg_services.nlp.v1.nlp_pb2.DocBinRequest,
        context: _ServicerContext,
    ) -> typing.Union[arg_services.nlp.v1.nlp_pb2.DocBinResponse, collections.abc.Awaitable[arg_services.nlp.v1.nlp_pb2.DocBinResponse]]:
        """Process strings by spacy and return them as [binary data](https://spacy.io/api/docbin).
        Locally, spacy can restore this data **without** loading the underlying NLP models into the main memory.
        Allows one to retrieve all computed attributes (e.g., POS tags, sentences), but can only be used by Python programs.
        """

def add_NlpServiceServicer_to_server(servicer: NlpServiceServicer, server: typing.Union[grpc.Server, grpc.aio.Server]) -> None: ...
