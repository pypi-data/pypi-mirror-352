<picture>
  <img alt="" src="./static/logo-jtech.png"  width="full">
</picture>

<h1 align="center">Biblioteca Unificada de Cliente MCP</h1>

üåê Jtech-MCP-Executor √© a solu√ß√£o propriet√°ria da J-Tech para conectar **qualquer LLM a qualquer servidor MCP** e construir agentes personalizados que t√™m acesso a ferramentas.

üí° Permite que desenvolvedores da J-Tech conectem facilmente qualquer LLM a ferramentas como navega√ß√£o web, opera√ß√µes de arquivos, e muito mais.

# Recursos

## ‚ú® Recursos Principais

| Recurso | Descri√ß√£o |
|---------|-------------|
| üîÑ [**Facilidade de uso**](#in√≠cio-r√°pido) | Crie seu primeiro agente MCP com apenas 6 linhas de c√≥digo |
| ü§ñ [**Flexibilidade de LLM**](#instalando-provedores-langchain) | Funciona com qualquer LLM suportado pelo LangChain que tenha suporte a chamada de ferramentas (OpenAI, Anthropic, Groq, LLama etc.) |
| üîó [**Suporte HTTP**](#exemplo-de-conex√£o-http) | Conex√£o direta com servidores MCP rodando em portas HTTP espec√≠ficas |
| ‚öôÔ∏è [**Sele√ß√£o Din√¢mica de Servidor**](#sele√ß√£o-din√¢mica-de-servidor-gerenciador-de-servidor) | Os agentes podem escolher dinamicamente o servidor MCP mais apropriado para uma determinada tarefa dentre os dispon√≠veis |
| üß© [**Suporte Multi-Servidor**](#suporte-multi-servidor) | Use m√∫ltiplos servidores MCP simultaneamente em um √∫nico agente |
| üõ°Ô∏è [**Restri√ß√µes de Ferramentas**](#controle-de-acesso-a-ferramentas) | Restrinja ferramentas potencialmente perigosas como acesso ao sistema de arquivos ou √† rede |
| üîß [**Agentes Personalizados**](#construa-um-agente-personalizado) | Construa seus pr√≥prios agentes com qualquer framework usando o adaptador LangChain ou crie novos adaptadores |


# In√≠cio R√°pido

Para instala√ß√£o a partir do reposit√≥rio interno da J-Tech:

```bash
pip install jtech-mcp-executor --index-url=https://pypi.jtech.interno/simple/
```

Ou instale a partir do c√≥digo fonte:

```bash
git clone https://gitlab.com/veolia.com/brasil/jtech/jtech-generative-ai/poc/jtech-mcp-executor.git
cd jtech-mcp-executor
pip install -e .
```

### Instalando Provedores LangChain

jtech_mcp_executor trabalha com v√°rios provedores de LLM atrav√©s do LangChain. Voc√™ precisar√° instalar o pacote provedor LangChain apropriado para o LLM escolhido. Por exemplo:

```bash
# Para OpenAI
pip install langchain-openai

# Para Anthropic
pip install langchain-anthropic

# Para outros provedores, consulte a [documenta√ß√£o de modelos de chat LangChain](https://python.langchain.com/docs/integrations/chat/)
```

e adicione suas chaves API para o provedor que deseja usar ao seu arquivo `.env`.

```bash
OPENAI_API_KEY=
ANTHROPIC_API_KEY=
```

> **Importante**: Apenas modelos com recursos de chamadas de ferramentas podem ser usados com jtech_mcp_executor. Certifique-se de que seu modelo escolhido suporte chamadas de fun√ß√£o ou uso de ferramentas.

### Inicie seu agente:

```python
import asyncio
import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from jtech_mcp_executor import JtechMCPAgent, JtechMCPClient

async def main():
    # Carregar vari√°veis de ambiente
    load_dotenv()

    # Criar dicion√°rio de configura√ß√£o
    config = {
      "mcpServers": {
        "playwright": {
          "command": "npx",
          "args": ["@playwright/mcp@latest"],
          "env": {
            "DISPLAY": ":1"
          }
        }
      }
    }

    # Criar JtechMCPClient a partir do dicion√°rio de configura√ß√£o
    client = JtechMCPClient.from_dict(config)

    # Criar LLM
    llm = ChatOpenAI(model="gpt-4o")

    # Criar agente com o cliente
    agent = JtechMCPAgent(llm=llm, client=client, max_steps=30)

    # Executar a consulta
    result = await agent.run(
        "Encontre o melhor restaurante em S√£o Paulo",
    )
    print(f"\nResultado: {result}")

if __name__ == "__main__":
    asyncio.run(main())
```

Voc√™ tamb√©m pode adicionar a configura√ß√£o de servidores a partir de um arquivo de configura√ß√£o assim:

```python
client = JtechMCPClient.from_config_file(
        os.path.join("browser_mcp.json")
    )
```

Exemplo de arquivo de configura√ß√£o (`browser_mcp.json`):

```json
{
  "mcpServers": {
    "playwright": {
      "command": "npx",
      "args": ["@playwright/mcp@latest"],
      "env": {
        "DISPLAY": ":1"
      }
    }
  }
}
```

Para outras configura√ß√µes, modelos e mais, consulte a documenta√ß√£o.

## Sa√≠da de Agente em Streaming

JtechMCPExecutor suporta streaming ass√≠ncrono de sa√≠da do agente usando o m√©todo `astream` no `JtechMCPAgent`. Isso permite que voc√™ receba resultados incrementais, a√ß√µes de ferramentas e etapas intermedi√°rias conforme s√£o geradas pelo agente, permitindo feedback em tempo real e relat√≥rios de progresso.

### Como usar

Chame `agent.astream(query)` e itere sobre os resultados de forma ass√≠ncrona:

```python
async for chunk in agent.astream("Encontre o melhor restaurante em S√£o Paulo"):
    print(chunk["messages"], end="", flush=True)
```

Cada fragmento √© um dicion√°rio contendo chaves como `actions`, `steps`, `messages` e (no √∫ltimo fragmento) `output`. Isso permite construir interfaces de usu√°rio responsivas ou registrar o progresso do agente em tempo real.

#### Exemplo: Streaming na Pr√°tica

```python
import asyncio
import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from jtech_mcp_executor import JtechMCPAgent, JtechMCPClient

async def main():
    load_dotenv()
    client = JtechMCPClient.from_config_file("browser_mcp.json")
    llm = ChatOpenAI(model="gpt-4o")
    agent = JtechMCPAgent(llm=llm, client=client, max_steps=30)
    async for chunk in agent.astream("Procure trabalho na NVIDIA para engenheiro de aprendizado de m√°quina."):
        print(chunk["messages"], end="", flush=True)

if __name__ == "__main__":
    asyncio.run(main())
```

Esta interface de streaming √© ideal para aplica√ß√µes que requerem atualiza√ß√µes em tempo real, como chatbots, pain√©is ou notebooks interativos.

# Exemplos de Casos de Uso

## Navega√ß√£o Web com Playwright

```python
import asyncio
import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from jtech_mcp_executor import JtechMCPAgent, JtechMCPClient

async def main():
    # Carregar vari√°veis de ambiente
    load_dotenv()

    # Criar JtechMCPClient a partir do arquivo de configura√ß√£o
    client = JtechMCPClient.from_config_file(
        os.path.join(os.path.dirname(__file__), "browser_mcp.json")
    )

    # Criar LLM
    llm = ChatOpenAI(model="gpt-4o")
    # Modelos alternativos:
    # llm = ChatAnthropic(model="claude-3-5-sonnet-20240620")
    # llm = ChatGroq(model="llama3-8b-8192")

    # Criar agente com o cliente
    agent = JtechMCPAgent(llm=llm, client=client, max_steps=30)

    # Executar a consulta
    result = await agent.run(
        "Encontre o melhor restaurante em S√£o Paulo USANDO PESQUISA DO GOOGLE",
        max_steps=30,
    )
    print(f"\nResultado: {result}")

if __name__ == "__main__":
    asyncio.run(main())
```

## Pesquisa no Airbnb

```python
import asyncio
import os
from dotenv import load_dotenv
from langchain_anthropic import ChatAnthropic
from jtech_mcp_executor import JtechMCPAgent, JtechMCPClient

async def run_airbnb_example():
    # Carregar vari√°veis de ambiente
    load_dotenv()

    # Criar JtechMCPClient com configura√ß√£o do Airbnb
    client = JtechMCPClient.from_config_file(
        os.path.join(os.path.dirname(__file__), "airbnb_mcp.json")
    )

    # Criar LLM - voc√™ pode escolher entre diferentes modelos
    llm = ChatAnthropic(model="claude-3-5-sonnet-20240620")

    # Criar agente com o cliente
    agent = JtechMCPAgent(llm=llm, client=client, max_steps=30)

    try:
        # Executar uma consulta para buscar acomoda√ß√µes
        result = await agent.run(
            "Encontre um bom lugar para ficar em Florian√≥polis para 2 adultos "
            "por uma semana em agosto. Prefiro lugares com piscina e "
            "boas avalia√ß√µes. Mostre-me as 3 melhores op√ß√µes.",
            max_steps=30,
        )
        print(f"\nResultado: {result}")
    finally:
        # Garantir que os recursos sejam limpos adequadamente
        if client.sessions:
            await client.close_all_sessions()

if __name__ == "__main__":
    asyncio.run(run_airbnb_example())
```

Exemplo de arquivo de configura√ß√£o (`airbnb_mcp.json`):

```json
{
  "mcpServers": {
    "airbnb": {
      "command": "npx",
      "args": ["-y", "@openbnb/mcp-server-airbnb"]
    }
  }
}
```

## Cria√ß√£o 3D com Blender

```python
import asyncio
from dotenv import load_dotenv
from langchain_anthropic import ChatAnthropic
from jtech_mcp_executor import JtechMCPAgent, JtechMCPClient

async def run_blender_example():
    # Carregar vari√°veis de ambiente
    load_dotenv()

    # Criar JtechMCPClient com configura√ß√£o MCP do Blender
    config = {"mcpServers": {"blender": {"command": "uvx", "args": ["blender-mcp"]}}}
    client = JtechMCPClient.from_dict(config)

    # Criar LLM
    llm = ChatAnthropic(model="claude-3-5-sonnet-20240620")

    # Criar agente com o cliente
    agent = JtechMCPAgent(llm=llm, client=client, max_steps=30)

    try:
        # Executar a consulta
        result = await agent.run(
            "Crie um cubo infl√°vel com material macio e um plano como ch√£o.",
            max_steps=30,
        )
        print(f"\nResultado: {result}")
    finally:
        # Garantir que os recursos sejam limpos adequadamente
        if client.sessions:
            await client.close_all_sessions()

if __name__ == "__main__":
    asyncio.run(run_blender_example())
```

# Suporte a Arquivo de Configura√ß√£o

JtechMCPExecutor suporta inicializa√ß√£o a partir de arquivos de configura√ß√£o, facilitando o gerenciamento e a altern√¢ncia entre diferentes configura√ß√µes de servidores MCP:

```python
import asyncio
from jtech_mcp_executor import create_session_from_config

async def main():
    # Criar uma sess√£o MCP a partir de um arquivo de configura√ß√£o
    session = create_session_from_config("mcp-config.json")

    # Inicializar a sess√£o
    await session.initialize()

    # Usar a sess√£o...

    # Desconectar quando terminar
    await session.disconnect()

if __name__ == "__main__":
    asyncio.run(main())
```

## Exemplo de Conex√£o HTTP

JtechMCPExecutor suporta conex√µes HTTP, permitindo que voc√™ se conecte a servidores MCP rodando em portas HTTP espec√≠ficas. Este recurso √© particularmente √∫til para integra√ß√£o com servidores MCP baseados na web.

Aqui est√° um exemplo de como usar o recurso de conex√£o HTTP:

```python
import asyncio
import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from jtech_mcp_executor import JtechMCPAgent, JtechMCPClient

async def main():
    """Execute o exemplo usando um arquivo de configura√ß√£o."""
    # Carregar vari√°veis de ambiente
    load_dotenv()

    config = {
        "mcpServers": {
            "http": {
                "url": "http://localhost:8931/sse"
            }
        }
    }

    # Criar JtechMCPClient a partir do arquivo de configura√ß√£o
    client = JtechMCPClient.from_dict(config)

    # Criar LLM
    llm = ChatOpenAI(model="gpt-4o")

    # Criar agente com o cliente
    agent = JtechMCPAgent(llm=llm, client=client, max_steps=30)

    # Executar a consulta
    result = await agent.run(
        "Encontre o melhor restaurante em S√£o Paulo USANDO PESQUISA DO GOOGLE",
        max_steps=30,
    )
    print(f"\nResultado: {result}")

if __name__ == "__main__":
    # Executar o exemplo apropriado
    asyncio.run(main())
```

Este exemplo demonstra como se conectar a um servidor MCP rodando em uma porta HTTP espec√≠fica. Certifique-se de iniciar seu servidor MCP antes de executar este exemplo.

# Suporte Multi-Servidor

JtechMCPExecutor permite configurar e conectar-se a m√∫ltiplos servidores MCP simultaneamente usando o `JtechMCPClient`. Isso possibilita fluxos de trabalho complexos que requerem ferramentas de diferentes servidores, como navega√ß√£o web combinada com opera√ß√µes de arquivos ou modelagem 3D.

## Configura√ß√£o

Voc√™ pode configurar m√∫ltiplos servidores em seu arquivo de configura√ß√£o:

```json
{
  "mcpServers": {
    "airbnb": {
      "command": "npx",
      "args": ["-y", "@openbnb/mcp-server-airbnb", "--ignore-robots-txt"]
    },
    "playwright": {
      "command": "npx",
      "args": ["@playwright/mcp@latest"],
      "env": {
        "DISPLAY": ":1"
      }
    }
  }
}
```

## Uso

A classe `JtechMCPClient` fornece m√©todos para gerenciar conex√µes a m√∫ltiplos servidores. Ao criar um `JtechMCPAgent`, voc√™ pode fornecer um `JtechMCPClient` configurado com m√∫ltiplos servidores.

Por padr√£o, o agente ter√° acesso a ferramentas de todos os servidores configurados. Se voc√™ precisar direcionar um servidor espec√≠fico para uma tarefa particular, pode especificar o `server_name` ao chamar o m√©todo `agent.run()`.

```python
# Exemplo: Sele√ß√£o manual de um servidor para uma tarefa espec√≠fica
result = await agent.run(
    "Procure por listagens do Airbnb em Florian√≥polis",
    server_name="airbnb" # Use explicitamente o servidor airbnb
)

result_google = await agent.run(
    "Encontre restaurantes perto do primeiro resultado usando a Pesquisa do Google",
    server_name="playwright" # Use explicitamente o servidor playwright
)
```

## Sele√ß√£o Din√¢mica de Servidor (Gerenciador de Servidor)

Para maior efici√™ncia e para reduzir a potencial confus√£o do agente ao lidar com muitas ferramentas de diferentes servidores, voc√™ pode habilitar o Gerenciador de Servidor definindo `use_server_manager=True` durante a inicializa√ß√£o do `JtechMCPAgent`.

Quando habilitado, o agente seleciona inteligentemente o servidor MCP correto com base na ferramenta escolhida pelo LLM para uma etapa espec√≠fica. Isso minimiza conex√µes desnecess√°rias e garante que o agente use as ferramentas apropriadas para a tarefa.

```python
import asyncio
from jtech_mcp_executor import JtechMCPClient, JtechMCPAgent
from langchain_anthropic import ChatAnthropic

async def main():
    # Criar cliente com m√∫ltiplos servidores
    client = JtechMCPClient.from_config_file("multi_server_config.json")

    # Criar agente com o cliente
    agent = JtechMCPAgent(
        llm=ChatAnthropic(model="claude-3-5-sonnet-20240620"),
        client=client,
        use_server_manager=True  # Habilitar o Gerenciador de Servidor
    )

    try:
        # Executar uma consulta que usa ferramentas de m√∫ltiplos servidores
        result = await agent.run(
            "Procure por um bom lugar para ficar em Florian√≥polis no Airbnb, "
            "depois use o Google para encontrar restaurantes e atra√ß√µes pr√≥ximas."
        )
        print(result)
    finally:
        # Limpar todas as sess√µes
        await client.close_all_sessions()

if __name__ == "__main__":
    asyncio.run(main())
```

# Controle de Acesso a Ferramentas

JtechMCPExecutor permite que voc√™ restrinja quais ferramentas est√£o dispon√≠veis para o agente, proporcionando melhor seguran√ßa e controle sobre as capacidades do agente:

```python
import asyncio
from jtech_mcp_executor import JtechMCPAgent, JtechMCPClient
from langchain_openai import ChatOpenAI

async def main():
    # Criar cliente
    client = JtechMCPClient.from_config_file("config.json")

    # Criar agente com ferramentas restritas
    agent = JtechMCPAgent(
        llm=ChatOpenAI(model="gpt-4"),
        client=client,
        disallowed_tools=["file_system", "network"]  # Restringir ferramentas potencialmente perigosas
    )

    # Executar uma consulta com acesso a ferramentas restrito
    result = await agent.run(
        "Encontre o melhor restaurante em S√£o Paulo"
    )
    print(result)

    # Limpar
    await client.close_all_sessions()

if __name__ == "__main__":
    asyncio.run(main())
```

# Construa um Agente Personalizado:

Voc√™ tamb√©m pode construir seu pr√≥prio agente personalizado usando o adaptador LangChain:

```python
import asyncio
from langchain_openai import ChatOpenAI
from jtech_mcp_executor.client import JtechMCPClient
from jtech_mcp_executor.adapters.langchain_adapter import LangChainAdapter
from dotenv import load_dotenv

load_dotenv()


async def main():
    # Inicializar cliente MCP
    client = JtechMCPClient.from_config_file("examples/browser_mcp.json")
    llm = ChatOpenAI(model="gpt-4o")

    # Criar inst√¢ncia do adaptador
    adapter = LangChainAdapter()
    # Obter ferramentas LangChain com uma √∫nica linha
    tools = await adapter.create_tools(client)

    # Criar um agente LangChain personalizado
    llm_with_tools = llm.bind_tools(tools)
    result = await llm_with_tools.ainvoke("Quais ferramentas voc√™ tem dispon√≠veis?")
    print(result)


if __name__ == "__main__":
    asyncio.run(main())
```

# Depura√ß√£o

JtechMCPExecutor fornece um modo de depura√ß√£o integrado que aumenta a verbosidade dos logs e ajuda a diagnosticar problemas na implementa√ß√£o do seu agente.

## Habilitando o Modo de Depura√ß√£o

Existem duas maneiras principais de habilitar o modo de depura√ß√£o:

### 1. Vari√°vel de Ambiente (Recomendado para Execu√ß√µes Pontuais)

Execute seu script com a vari√°vel de ambiente `DEBUG` definida para o n√≠vel desejado:

```bash
# N√≠vel 1: Mostrar mensagens de n√≠vel INFO
DEBUG=1 python3.11 examples/browser_use.py

# N√≠vel 2: Mostrar mensagens de n√≠vel DEBUG (sa√≠da verbosa completa)
DEBUG=2 python3.11 examples/browser_use.py
```

Isso define o n√≠vel de depura√ß√£o apenas para a dura√ß√£o desse processo Python espec√≠fico.

Alternativamente, voc√™ pode definir a seguinte vari√°vel de ambiente para o n√≠vel de log desejado:

```bash
export MCP_USE_DEBUG=1 # ou 2
```

### 2. Definindo a Flag de Depura√ß√£o Programaticamente

Voc√™ pode definir a flag de depura√ß√£o global diretamente em seu c√≥digo:

```python
import jtech_mcp_executor

jtech_mcp_executor.set_debug(1)  # N√≠vel INFO
# ou
jtech_mcp_executor.set_debug(2)  # N√≠vel DEBUG (sa√≠da verbosa completa)
```

### 3. Verbosidade Espec√≠fica do Agente

Se voc√™ quiser ver apenas informa√ß√µes de depura√ß√£o do agente sem habilitar o log de depura√ß√£o completo, pode definir o par√¢metro `verbose` ao criar um JtechMCPAgent:

```python
# Criar agente com verbosidade aumentada
agent = JtechMCPAgent(
    llm=seu_llm,
    client=seu_cliente,
    verbose=True  # Mostra apenas mensagens de depura√ß√£o do agente
)
```

Isso √© √∫til quando voc√™ s√≥ precisa ver as etapas e o processo de tomada de decis√£o do agente sem todas as informa√ß√µes de depura√ß√£o de baixo n√≠vel de outros componentes.

# Desenvolvimento com Makefile

O projeto JTech MCP Executor inclui um Makefile para simplificar tarefas comuns de desenvolvimento. Isso facilita a configura√ß√£o do ambiente, execu√ß√£o de testes e cria√ß√£o de distribui√ß√µes do pacote.

## üõ†Ô∏è Comandos do Makefile

| Comando | Descri√ß√£o |
|---------|-----------|
| `make help` | Exibe informa√ß√µes sobre todos os comandos dispon√≠veis |
| `make venv` | Cria um ambiente virtual Python. Se j√° existir, pergunta se deseja recriar |
| `make install` | Instala o pacote sem depend√™ncias de desenvolvimento |
| `make install-dev` | Instala o pacote em modo edit√°vel com todas as depend√™ncias |
| `make test` | Executa os testes unit√°rios do projeto |
| `make lint` | Executa verifica√ß√µes de linting com Ruff |
| `make clean` | Remove arquivos tempor√°rios e diret√≥rios de build |
| `make build` | Constr√≥i o pacote para distribui√ß√£o, permitindo selecionar a vers√£o |
| `make publish` | Publica o pacote no PyPI |
| `make publish-test` | Publica o pacote no TestPyPI para testes |

## üöÄ Exemplos de Uso

### Configura√ß√£o do Ambiente de Desenvolvimento

```bash
# Criar ambiente virtual e instalar em modo desenvolvimento
make install-dev

# Ap√≥s a instala√ß√£o, ative o ambiente virtual
source .venv/bin/activate
```

### Testes e Linting

```bash
# Executar os testes
make test

# Verificar c√≥digo com o linter
make lint
```

### Construir e Publicar

```bash
# Limpar arquivos tempor√°rios e construir o pacote
make build
```

Ao executar `make build`, voc√™ ver√° um menu interativo que permite:
1. Incrementar n√∫mero de patch (para corre√ß√µes)
2. Incrementar n√∫mero minor (para novos recursos compat√≠veis)
3. Incrementar n√∫mero major (para mudan√ßas incompat√≠veis)
4. Inserir uma vers√£o personalizada
5. Manter a vers√£o atual

A vers√£o escolhida ser√° atualizada no arquivo `pyproject.toml` e o pacote ser√° constru√≠do com esta vers√£o.

```bash
# Publicar no PyPI (requer autentica√ß√£o)
make publish
```

## üìã Fluxo de Trabalho Recomendado

Para desenvolvimento:
1. `make install-dev` - Configure o ambiente
2. Fa√ßa suas altera√ß√µes no c√≥digo
3. `make test` - Certifique-se de que os testes passam
4. `make lint` - Verifique se o c√≥digo est√° em conformidade com os padr√µes

Para lan√ßamento:
1. `make build` - Construa o pacote e selecione a vers√£o adequada
2. `make publish-test` - Teste a publica√ß√£o no TestPyPI
3. `make publish` - Publique oficialmente no PyPI

> **Nota**: Para publicar no PyPI ou TestPyPI, voc√™ deve configurar seus tokens de autentica√ß√£o com o Poetry antes de executar `make publish` ou `make publish-test`. Use `poetry config pypi-token.pypi <seu-token>` para configurar o token do PyPI.

# Configura√ß√£o para Pacotes npm da J-Tech

Para utilizar servidores MCP como PostgreSQL, Airbnb e outros que dependem de pacotes do reposit√≥rio npm interno da J-Tech, √© necess√°rio configurar corretamente a autentica√ß√£o no npm. Sem essa configura√ß√£o, voc√™ poder√° encontrar erros como:

```
HttpErrorAuthUnknown: Unable to authenticate, need: BASIC realm="Sonatype Nexus Repository Manager"
```

## üîê Configurando o arquivo .npmrc

1. Crie ou edite um arquivo `.npmrc` na raiz do seu projeto:

```bash
# Crie o arquivo .npmrc se ele n√£o existir
touch .npmrc
```

2. Adicione as seguintes configura√ß√µes ao arquivo:

```properties
registry=https://registry.npmjs.org/
@modelcontextprotocol:registry=https://nexus.jtech.com.br/repository/npm-jtech/
//nexus.jtech.com.br/repository/npm-jtech/:_auth=${JTECH_NPM_AUTH}
//nexus.jtech.com.br/repository/npm-jtech/:always-auth=true
```

3. Configure a vari√°vel de ambiente `JTECH_NPM_AUTH` com suas credenciais em formato Base64:

```bash
# Gerar a string Base64 a partir de suas credenciais
echo -n "seu_usuario:sua_senha" | base64

# Exemplo do resultado: c2V1X3VzdWFyaW86c3VhX3Nlbmhh
```

4. Adicione a vari√°vel de ambiente ao seu ambiente:

```bash
# Temporariamente (para uma √∫nica sess√£o)
export JTECH_NPM_AUTH=sua_string_base64

# OU permanentemente (adicionando ao seu .bashrc ou .zshrc)
echo 'export JTECH_NPM_AUTH=sua_string_base64' >> ~/.bashrc
source ~/.bashrc
```

## üîÑ Configura√ß√£o Alternativa (sem vari√°vel de ambiente)

Se preferir n√£o usar vari√°veis de ambiente, voc√™ pode adicionar suas credenciais diretamente no arquivo `.npmrc`:

```properties
registry=https://registry.npmjs.org/
@modelcontextprotocol:registry=https://nexus.jtech.com.br/repository/npm-jtech/
//nexus.jtech.com.br/repository/npm-jtech/:_auth=c2V1X3VzdWFyaW86c3VhX3Nlbmhh
//nexus.jtech.com.br/repository/npm-jtech/:always-auth=true
```

## üöÄ Testando a Configura√ß√£o

Ap√≥s configurar o `.npmrc`, teste a autentica√ß√£o:

```bash
# Exemplo para testar o acesso ao servidor PostgreSQL
npx --yes @modelcontextprotocol/server-postgres --help
```

Se a configura√ß√£o estiver correta, o comando ser√° executado sem erros de autentica√ß√£o.

## üìã Exemplo de Configura√ß√£o para PostgreSQL

Para usar o servidor MCP PostgreSQL, crie um arquivo de configura√ß√£o como `postgres-mcp.json`:

```json
{
  "mcpServers": {
    "postgres": {
      "command": "npx",
      "args": [
        "--yes",
        "@modelcontextprotocol/server-postgres",
        "postgresql://usuario:senha@host:porta/base_de_dados"
      ]
    }
  }
}
```

> **Dica**: Para projetos de produ√ß√£o, considere usar vari√°veis de ambiente ou um gerenciador de segredos para as credenciais do banco de dados.

# Exemplo Completo: Consultas SQL com PostgreSQL e Cat√°logo de Metadados

O exemplo a seguir demonstra como usar o JTech MCP Executor com um banco de dados PostgreSQL, passando um contexto rico de metadados sobre as tabelas para melhorar a precis√£o das consultas SQL geradas.

## Arquivo de Configura√ß√£o

Primeiro, crie um arquivo de configura√ß√£o `postgres-mcp.json` para o servidor PostgreSQL:

```json
{
  "mcpServers": {
    "postgres": {
      "command": "npx",
      "args": [
        "--yes",
        "@modelcontextprotocol/server-postgres",
        "postgresql://usuario:senha@host:porta/base_de_dados"
      ]
    }
  }
}
```

## C√≥digo Exemplo

Aqui est√° um exemplo completo (`database.py`) que mostra como:
1. Configurar metadados de tabelas para fornecer contexto ao modelo
2. Conectar ao servidor MCP PostgreSQL
3. Executar uma consulta em linguagem natural com o contexto das tabelas

```python
import asyncio
import os
from typing import Dict, Any
from dotenv import load_dotenv
from jtech_mcp_executor import JtechMCPAgent, JtechMCPClient
from langchain_google_genai import ChatGoogleGenerativeAI

# Cat√°logo de metadados das tabelas
TABLE_CATALOG: Dict[str, Dict[str, Any]] = {
    "revenue_forecast": {
        "description": "Proje√ß√µes e dados hist√≥ricos de faturamento por cliente e per√≠odo",
        "keywords": ["faturamento", "receita", "proje√ß√£o", "previs√£o", "cliente", "res√≠duo"],
        "campos": [
            {"nome": "client_id", "tipo": "INT", "descricao": "Identificador √∫nico do cliente"},
            {"nome": "year", "tipo": "INT", "descricao": "Ano da proje√ß√£o ou dado hist√≥rico"},
            {"nome": "month", "tipo": "INT", "descricao": "M√™s da proje√ß√£o ou dado hist√≥rico (1-12)"},
            {"nome": "material_type", "tipo": "VARCHAR", "descricao": "Tipo de material (metais, pl√°sticos, etc)"},
            {"nome": "revenue", "tipo": "DECIMAL", "descricao": "Valor do faturamento em reais"}
        ]
    },
    "customer": {
        "description": "Dados cadastrais de clientes",
        "keywords": ["cliente", "contato", "cadastro", "empresa"],
        "campos": [
            {"nome": "client_id", "tipo": "INT", "descricao": "Identificador √∫nico do cliente"},
            {"nome": "name", "tipo": "VARCHAR", "descricao": "Nome da empresa cliente"},
            {"nome": "segment", "tipo": "VARCHAR", "descricao": "Segmento de atua√ß√£o do cliente"}
        ]
    }
    # Adicione outras tabelas conforme necess√°rio
}

async def postgres():
    # Carregar vari√°veis de ambiente
    load_dotenv()

    # Inicializar cliente com configura√ß√£o
    client = JtechMCPClient.from_config_file("./postgres-mcp.json")

    # Configurar modelo LLM
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.0-flash",
        temperature=0,
        max_tokens=None,
        timeout=None,
        max_retries=2,
    )

    # Criar agente com o cliente
    agent = JtechMCPAgent(llm=llm, client=client, max_steps=30)

    try:
        # Consulta em linguagem natural
        query = "Preciso saber qual o faturamento para os meses de janeiro at√© mar√ßo da tabela revenue_forecast somente para pl√°sticos, apresente o valor em Reais (R$)"
        
        result = await agent.run(query,max_steps=30)
        print(f"\nResultado: {result}")
    finally:
        # Garantir que os recursos sejam limpos adequadamente
        if client.sessions:
            await client.close_all_sessions()

if __name__ == "__main__":
    asyncio.run(postgres())
```

## Como Executar o Exemplo

1. Certifique-se de que voc√™ j√° configurou o `.npmrc` conforme explicado acima
2. Instale as depend√™ncias necess√°rias:
   ```bash
   pip install langchain-google-genai python-dotenv
   ```
3. Configure sua chave API do Google em um arquivo `.env`:
   ```
   GOOGLE_API_KEY=sua_chave_api_aqui
   ```
4. Ajuste as informa√ß√µes de conex√£o do PostgreSQL no arquivo `postgres-mcp.json`
5. Execute o script:
   ```bash
   python database.py
   ```

## Como Funciona

1. **Cat√°logo de Metadados**: Define estrutura, descri√ß√µes e palavras-chave para as tabelas
2. **Formata√ß√£o do Contexto**: Converte o cat√°logo em um texto estruturado para o LLM
3. **Execu√ß√£o da Consulta**: O agente usa o contexto para entender o esquema do banco e gerar SQL mais preciso

Este padr√£o √© especialmente √∫til quando:
- O esquema do banco de dados √© complexo
- Voc√™ deseja fornecer detalhes sem√¢nticos sobre o significado dos dados
- Precisa de consultas precisas que respeitem rela√ß√µes e tipos de dados espec√≠ficos

Voc√™ pode expandir o cat√°logo de metadados com informa√ß√µes adicionais como restri√ß√µes, relacionamentos entre tabelas, intervalos v√°lidos para campos, etc.
