{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the Dell AI SDK Walkthrough\n",
    "\n",
    "In this interactive guide, we'll explore the capabilities of the Dell AI SDK, helping you understand how to harness Dell's enterprise-grade AI infrastructure for your projects. By the end of this notebook, you'll have hands-on experience with:\n",
    "\n",
    "- Setting up and authenticating your Dell AI client\n",
    "- Discovering and exploring available AI models\n",
    "- Understanding Dell's AI hardware platforms\n",
    "- Generating deployment configurations for production environments\n",
    "\n",
    "Let's begin our journey into enterprise AI deployment!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Your Environment\n",
    "\n",
    "First, let's import the necessary libraries. The Dell AI SDK provides a simple client interface that handles all communication with Dell's AI infrastructure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dell_ai import DellAIClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Connecting to Dell AI\n",
    "\n",
    "Let's initialize our connection to Dell AI services. The client acts as your gateway to all Dell AI functionality.\n",
    "\n",
    "üí° **Authentication Tip:** The client will automatically try to use your Hugging Face token from the cache. If you haven't authenticated with Hugging Face before, you can pass your token directly as shown in the commented example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the client (uses HF token from cache if available)\n",
    "client = DellAIClient()\n",
    "\n",
    "# If you need to provide a token directly:\n",
    "# client = DellAIClient(token=\"your_huggingface_token\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Verifying Your Connection\n",
    "\n",
    "Before proceeding, let's make sure we're properly connected and authenticated with the Dell AI platform. This step is crucial as it verifies your access to Dell's enterprise AI services.\n",
    "\n",
    "Let's check your authentication status and retrieve your user information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's verify our connection and see your account details\n",
    "is_auth = client.is_authenticated()\n",
    "print(f\"‚úÖ Authentication status: {'Successful' if is_auth else 'Failed'}\")\n",
    "\n",
    "if is_auth:\n",
    "    user_info = client.get_user_info()\n",
    "    print(\"\\nüìã Your Hugging Face User Information:\")\n",
    "    for key, value in user_info.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "    print(\"\\nYou're all set to explore Dell's AI capabilities!\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Please check your authentication token and try again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploring Available AI Models\n",
    "\n",
    "Now that we're connected, let's discover the AI models available through Dell's platform. Dell AI provides access to a curated selection of high-performance models optimized for enterprise use cases.\n",
    "\n",
    "These models range from large language models (LLMs) to specialized AI models for various tasks, all optimized to run efficiently on Dell's hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's explore the available models\n",
    "models = client.list_models()\n",
    "print(f\"üìö Found {len(models)} models on the Dell AI Platform and Dell AI PCs\")\n",
    "\n",
    "# Display a few examples\n",
    "print(\"\\nSample of available models:\")\n",
    "for model in models[:5]:  # Show first 5 models\n",
    "    print(f\"  ‚Ä¢ {model}\")\n",
    "\n",
    "# Show more details about one model\n",
    "if models:\n",
    "    example_model = models[0]  # Let's look at the first model in detail\n",
    "    model_details = client.get_model(example_model)\n",
    "\n",
    "    print(f\"\\nüîç Spotlight on: {example_model}\")\n",
    "    print(f\"  Description: {model_details.description}\")\n",
    "    print(f\"  License: {model_details.license}\")\n",
    "    print(f\"  Is Multimodal: {model_details.is_multimodal}\")\n",
    "\n",
    "    print(\"\\nTip: To explore a different model, use: client.get_model('model_name')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Understanding Dell's AI Hardware Platforms\n",
    "\n",
    "One of Dell's key strengths is its range of optimized hardware platforms for AI workloads. These platforms are designed to deliver maximum performance for different types of AI models and use cases.\n",
    "\n",
    "Let's explore the available hardware platforms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discover Dell AI hardware platforms\n",
    "platforms = client.list_platforms()\n",
    "print(f\"üñ•Ô∏è Found {len(platforms)} AI-optimized hardware platforms\")\n",
    "\n",
    "# List all available platforms\n",
    "print(\"\\nAvailable platforms:\")\n",
    "for platform in platforms:\n",
    "    print(f\"  ‚Ä¢ {platform}\")\n",
    "\n",
    "# Deep dive into one platform\n",
    "if platforms:\n",
    "    example_platform = platforms[0]\n",
    "    platform_details = client.get_platform(example_platform)\n",
    "\n",
    "    print(f\"\\nüîç Platform Details: {platform_details.name}\")\n",
    "    print(f\"  Platform: {platform_details.platform}\")\n",
    "    print(\"  GPU Information:\")\n",
    "    print(f\"    - Vendor: {platform_details.vendor}\")\n",
    "    print(f\"    - Type: {platform_details.platform_type}\")\n",
    "    print(f\"    - Memory per GPU: {platform_details.gpuram}\")\n",
    "    print(f\"    - Total GPUs: {platform_details.totalgpucount}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model-Platform Compatibility\n",
    "\n",
    "Not all models can run efficiently on all hardware. Dell AI provides detailed compatibility information to help you choose the right hardware for your AI workloads.\n",
    "\n",
    "Let's check which platforms support our example model and what configurations are available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which platforms support our model\n",
    "model_id = \"deepseek-ai/deepseek-r1\"\n",
    "model_details = client.get_model(model_id)\n",
    "\n",
    "print(f\"üìä Platform Support for: {model_id}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if not model_details.configs_deploy:\n",
    "    print(\"‚ö†Ô∏è No deployment configurations available for this model.\")\n",
    "else:\n",
    "    print(\n",
    "        f\"This model can be deployed on {len(model_details.configs_deploy)} platform(s):\"\n",
    "    )\n",
    "\n",
    "    for platform_id, configs in model_details.configs_deploy.items():\n",
    "        print(f\"\\nüñ•Ô∏è {platform_id}\")\n",
    "\n",
    "        for idx, config in enumerate(configs, 1):\n",
    "            print(f\"  Configuration Option {idx}:\")\n",
    "\n",
    "            # Get all attributes dynamically including any extra fields\n",
    "            config_dict = config.model_dump()\n",
    "            for key, value in config_dict.items():\n",
    "                # Format the key to be more readable\n",
    "                formatted_key = key.replace(\"_\", \" \").title()\n",
    "                print(f\"    ‚Ä¢ {formatted_key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 List Compatible Platforms for Each Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    model_id = model  # Using our previous example model\n",
    "    print(model_id)\n",
    "    model_details = client.get_model(model_id)\n",
    "\n",
    "    print(\"=\" * 100)\n",
    "    print(f\"\\nüìä Platform Support for: {model_id}\")\n",
    "\n",
    "    if not model_details.configs_deploy:\n",
    "        print(\"‚ö†Ô∏è No deployment configurations available for this model.\")\n",
    "    else:\n",
    "        print(\n",
    "            f\"   This model can be deployed on {len(model_details.configs_deploy)} platform(s):\"\n",
    "        )\n",
    "\n",
    "        for platform_id, configs in model_details.configs_deploy.items():\n",
    "            print(f\"\\nüñ•Ô∏è {platform_id}\")\n",
    "\n",
    "            for idx, config in enumerate(configs, 0):\n",
    "                print(f\"  Configuration Option {idx+1}:\")\n",
    "\n",
    "                # Get all attributes dynamically including any extra fields\n",
    "                config_dict = config.model_dump()\n",
    "                for key, value in config_dict.items():\n",
    "                    # Format the key to be more readable\n",
    "                    formatted_key = key.replace(\"_\", \" \").title()\n",
    "                    print(f\"    ‚Ä¢ {formatted_key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 List Compatible Platforms for Specified Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which platforms support our model\n",
    "user_input = input(\"Enter model id:üëâ \")\n",
    "\n",
    "model_details = client.get_model(user_input)\n",
    "\n",
    "print(f\"üìä Platform Support for: {user_input}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if not model_details.configs_deploy:\n",
    "    print(\"‚ö†Ô∏è No deployment configurations available for this model.\")\n",
    "else:\n",
    "    print(\n",
    "        f\"This model can be deployed on {len(model_details.configs_deploy)} platform(s):\"\n",
    "    )\n",
    "\n",
    "    for platform_id, configs in model_details.configs_deploy.items():\n",
    "        print(f\"\\nüñ•Ô∏è {platform_id}\")\n",
    "\n",
    "        for idx, config in enumerate(configs, 1):\n",
    "            print(f\"  Configuration Option {idx}:\")\n",
    "\n",
    "            # Get all attributes dynamically including any extra fields\n",
    "            config_dict = config.model_dump()\n",
    "            for key, value in config_dict.items():\n",
    "                # Format the key to be more readable\n",
    "                formatted_key = key.replace(\"_\", \" \").title()\n",
    "                print(f\"    ‚Ä¢ {formatted_key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Generating Model Deployment Configurations\n",
    "\n",
    "Now let's see how to deploy your chosen AI model! Dell AI simplifies deployment by generating ready-to-use configuration snippets for Docker and Kubernetes.\n",
    "\n",
    "Let's generate deployment snippets for our example model on a compatible platform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate deployment snippets\n",
    "if model_details.configs_deploy:\n",
    "    model_id = model_details.repo_name\n",
    "\n",
    "    # Get the first platform ID from the available platforms\n",
    "    platform_ids = list(model_details.configs_deploy.keys())\n",
    "\n",
    "    if platform_ids:\n",
    "        platform_id = platform_ids[0]  # Take the first platform\n",
    "        config = model_details.configs_deploy[platform_id][\n",
    "            0\n",
    "        ]  # Take the first config of that platform\n",
    "\n",
    "        print(f\"üöÄ Preparing Deployment for {model_id}\")\n",
    "        print(f\"On Platform: {platform_id}\")\n",
    "        print(\"\\nDeployment Configuration:\")\n",
    "\n",
    "        # Display all config properties dynamically\n",
    "        config_dict = config.model_dump()\n",
    "        for key, value in config_dict.items():\n",
    "            # Format the key to be more readable\n",
    "            formatted_key = key.replace(\"_\", \" \").title()\n",
    "            print(f\"  ‚Ä¢ {formatted_key}: {value}\")\n",
    "\n",
    "    # Generate Docker deployment snippet\n",
    "    docker_snippet = client.get_deployment_snippet(\n",
    "        model_id=model_id,\n",
    "        platform_id=platform_id,\n",
    "        engine=\"docker\",\n",
    "        num_gpus=config.num_gpus,\n",
    "        num_replicas=1,\n",
    "    )\n",
    "\n",
    "    print(\"\\nüì¶ Docker Deployment Command:\")\n",
    "    print(\"Copy this command to deploy with Docker:\")\n",
    "    print(\"```bash\")\n",
    "    print(docker_snippet)\n",
    "    print(\"```\")\n",
    "\n",
    "    # Generate Kubernetes deployment snippet\n",
    "    k8s_snippet = client.get_deployment_snippet(\n",
    "        model_id=model_id,\n",
    "        platform_id=platform_id,\n",
    "        engine=\"kubernetes\",\n",
    "        num_gpus=config.num_gpus,\n",
    "        num_replicas=1,\n",
    "    )\n",
    "\n",
    "    print(\"\\n‚ò∏Ô∏è Kubernetes Deployment Manifest:\")\n",
    "    print(\"```yaml\")\n",
    "    print(k8s_snippet)\n",
    "    print(\"```\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No deployment configurations available. Try with a different model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Exploring the App Catalog\n",
    "\n",
    "In addition to models, the Dell Enterprise Hub includes an App Catalog that provides ready-to-deploy applications optimized for AI workloads. In this section, we'll explore how to:\n",
    "\n",
    "1. List available applications\n",
    "2. Get detailed information about applications\n",
    "3. Explore configuration options\n",
    "4. Generate deployment snippets\n",
    "\n",
    "Let's start by listing the available applications:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available applications in the catalog\n",
    "print(\"üìã Available Applications:\")\n",
    "apps = client.list_apps()\n",
    "for i, app in enumerate(apps, 1):\n",
    "    print(f\"  {i}. {app}\")\n",
    "\n",
    "if not apps:\n",
    "    print(\"No applications available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Exploring Application Details\n",
    "\n",
    "Once you've identified an application of interest, you can retrieve its detailed information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get details for an application (using first available app as an example)\n",
    "if apps:\n",
    "    app_id = apps[0].lower()  # Convert to lowercase for API compatibility\n",
    "\n",
    "    print(f\"\\nüîç Getting details for app: {app_id}\")\n",
    "    app_details = client.get_app(app_id)\n",
    "\n",
    "    print(f\"App: {app_details.name}\")\n",
    "    print(f\"Description: {app_details.description[:100]}...\")\n",
    "    print(f\"License: {app_details.license}\")\n",
    "    print(f\"Documentation: {app_details.docs}\")\n",
    "\n",
    "    # Display tags and recommended models\n",
    "    print(f\"\\nTags: {', '.join(app_details.tags)}\")\n",
    "    print(f\"Recommended Models: {', '.join(app_details.recommendedModels[:2])}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Understanding Configuration Options\n",
    "\n",
    "Each application has specific configuration options organized by component. \n",
    "\n",
    "**Note:** for a full list of configurable values, please refer to the [Dell Enterprise Hub Helm Chart repo](https://github.com/huggingface/dell-helm-chart).\n",
    "\n",
    "Let's explore these options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore configuration options\n",
    "if \"app_details\" in locals():\n",
    "    print(\"\\n‚öôÔ∏è Available Configuration Options:\")\n",
    "    config_options = []\n",
    "\n",
    "    for i, component in enumerate(app_details.components, 1):\n",
    "        print(f\"\\nComponent {i}: {component.name} (Required: {component.required})\")\n",
    "        print(f\"Description: {component.description}\")\n",
    "\n",
    "        if component.config:\n",
    "            print(\"\\nConfiguration Parameters:\")\n",
    "            for param in component.config:\n",
    "                print(f\"  ‚Ä¢ {param.name}: {param.description[:100]}\")\n",
    "                print(f\"    Type: {param.type}, Required: {param.required or False}\")\n",
    "                if param.default is not None:\n",
    "                    print(f\"    Default Value: {param.default}\")\n",
    "                print(f\"    Helm Path: {param.helmPath}\")\n",
    "\n",
    "                # Store config information for later use\n",
    "                config_options.append(\n",
    "                    {\n",
    "                        \"component\": component.name,\n",
    "                        \"param\": param,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "        if component.secrets:\n",
    "            print(\"\\nSecrets:\")\n",
    "            for secret in component.secrets:\n",
    "                print(f\"  ‚Ä¢ {secret.name}: {secret.description[:100]}\")\n",
    "                print(f\"    Type: {secret.type}, Required: {secret.required or False}\")\n",
    "                print(f\"    Helm Path: {secret.helmPath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Creating a Deployment Configuration\n",
    "\n",
    "Based on the available options, we can create a custom configuration for our application deployment.\n",
    "In this example, we'll create a basic configuration using \"example\" parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a configuration based on available options\n",
    "if \"app_details\" in locals() and app_details.components:\n",
    "    print(\"\\nüîß Creating Deployment Configuration\")\n",
    "\n",
    "    config = []\n",
    "\n",
    "    # Create configuration using example values from parameters\n",
    "    for opt in config_options:\n",
    "        param = opt[\"param\"]\n",
    "        # Use example value if available, otherwise use default or a type-appropriate value\n",
    "        if hasattr(param, \"example\") and param.example is not None:\n",
    "            value = param.example\n",
    "        else:\n",
    "            continue  # Skip if we can't determine a good value\n",
    "\n",
    "        config.append({\"helmPath\": param.helmPath, \"type\": param.type, \"value\": value})\n",
    "\n",
    "    # Display the final configuration\n",
    "    print(\"\\nüìù Example Configuration:\")\n",
    "    for i, cfg in enumerate(config, 1):\n",
    "        print(f\"  {i}. {cfg['helmPath']} = {cfg['value']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 Generating Application Deployment Snippets\n",
    "\n",
    "With our configuration defined, we can now generate a deployment snippet.\n",
    "This will produce a Helm command you can run to deploy the application:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the deployment snippet\n",
    "if \"config\" in locals() and config:\n",
    "    print(\"\\nüöÄ Generating deployment snippet...\")\n",
    "    try:\n",
    "        snippet = client.get_app_snippet(app_id, config)\n",
    "\n",
    "        print(\"\\nüì¶ Helm Deployment Command:\")\n",
    "        print(\"```bash\")\n",
    "        print(snippet)\n",
    "        print(\"```\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error generating snippet: {e}\")\n",
    "else:\n",
    "    print(\"No valid configuration available to generate a snippet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: To run this command:**\n",
    "1. Make sure you have Helm installed (https://helm.sh/docs/intro/install/)\n",
    "2. Add the Dell Enterprise Hub chart repository:\n",
    "   ```\n",
    "   $ helm repo add deh https://huggingface.github.io/dell-helm-chart\n",
    "   $ helm repo update\n",
    "   ```\n",
    "3. Ensure your Kubernetes cluster is properly configured\n",
    "4. Run the command above to deploy OpenWebUI\n",
    "5. For detailed usage instructions, visit:\n",
    "   - OpenWebUI docs: https://docs.openwebui.com/\n",
    "   - Dell Enterprise Hub Helm charts: https://github.com/huggingface/dell-helm-chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Congratulations! You've successfully completed the Dell AI SDK walkthrough. You now have the knowledge to:\n",
    "\n",
    "1. **Connect** to Dell's enterprise AI platform\n",
    "2. **Explore** available AI models, hardware platforms, and apps\n",
    "3. **Check** compatibility between models and platforms\n",
    "4. **Generate** deployment configurations for your chosen model or application\n",
    "\n",
    "### Where to go from here:\n",
    "\n",
    "- Try deploying one of these models or applications on your Dell hardware\n",
    "- Explore additional models and their capabilities\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
