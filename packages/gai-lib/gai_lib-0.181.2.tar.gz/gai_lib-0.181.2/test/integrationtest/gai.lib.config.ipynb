{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Gai Config"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "a) Get Gai Config\n",
                "\n",
                "<div style=\"background: #949494; padding: 10px; color:black\">\n",
                "    gai_config = config_helper.get_gai_config()\n",
                "</div>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "{\n",
                        "  \"version\": \"1.0\",\n",
                        "  \"gai_url\": \"http://localhost:12033\",\n",
                        "  \"logging\": {\n",
                        "    \"level\": \"INFO\",\n",
                        "    \"format\": \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n",
                        "    \"datefmt\": \"%Y-%m-%d %H:%M:%S\",\n",
                        "    \"filename\": \"\",\n",
                        "    \"filemode\": \"a\",\n",
                        "    \"stream\": \"stdout\",\n",
                        "    \"loggers\": {\n",
                        "      \"gai.ttt\": \"DEBUG\",\n",
                        "      \"gai.common.http_utils\": \"DEBUG\"\n",
                        "    }\n",
                        "  },\n",
                        "  \"clients\": {\n",
                        "    \"ttt\": {\n",
                        "      \"client_type\": \"gai\",\n",
                        "      \"type\": \"ttt\",\n",
                        "      \"engine\": null,\n",
                        "      \"model\": null,\n",
                        "      \"name\": null,\n",
                        "      \"url\": \"http://gai-ttt-svr:12031/gen/v1/chat/completions\",\n",
                        "      \"env\": null,\n",
                        "      \"extra\": null,\n",
                        "      \"hyperparameters\": {}\n",
                        "    },\n",
                        "    \"dolphin3.0_llama3.1:4.25bpw:exl2\": {\n",
                        "      \"client_type\": \"gai\",\n",
                        "      \"type\": \"ttt\",\n",
                        "      \"engine\": null,\n",
                        "      \"model\": null,\n",
                        "      \"name\": null,\n",
                        "      \"url\": \"http://gai-ttt-svr:12031/gen/v1/chat/completions\",\n",
                        "      \"env\": null,\n",
                        "      \"extra\": null,\n",
                        "      \"hyperparameters\": {}\n",
                        "    },\n",
                        "    \"tool-web\": {\n",
                        "      \"client_type\": \"gai\",\n",
                        "      \"type\": \"tool\",\n",
                        "      \"engine\": null,\n",
                        "      \"model\": null,\n",
                        "      \"name\": null,\n",
                        "      \"url\": \"http://gai-tools-web-svr:12036/tools/web/v1\",\n",
                        "      \"env\": null,\n",
                        "      \"extra\": null,\n",
                        "      \"hyperparameters\": {}\n",
                        "    },\n",
                        "    \"gpt-4o\": {\n",
                        "      \"client_type\": \"openai\",\n",
                        "      \"type\": \"ttt\",\n",
                        "      \"engine\": null,\n",
                        "      \"model\": null,\n",
                        "      \"name\": null,\n",
                        "      \"url\": null,\n",
                        "      \"env\": null,\n",
                        "      \"extra\": null,\n",
                        "      \"hyperparameters\": {}\n",
                        "    },\n",
                        "    \"mcp-web\": {\n",
                        "      \"client_type\": \"gai\",\n",
                        "      \"type\": \"mcp\",\n",
                        "      \"engine\": null,\n",
                        "      \"model\": null,\n",
                        "      \"name\": null,\n",
                        "      \"url\": \"file://../../src/gai/mcp/web/mcp_server/mcp_server.py\",\n",
                        "      \"env\": null,\n",
                        "      \"extra\": null,\n",
                        "      \"hyperparameters\": {}\n",
                        "    }\n",
                        "  },\n",
                        "  \"generators\": {},\n",
                        "  \"tools\": {}\n",
                        "}\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "import json\n",
                "from gai.lib.tests import get_local_datadir\n",
                "file_path =  os.path.join(get_local_datadir(),\"gai.yml\")\n",
                "\n",
                "from gai.lib.config import config_helper\n",
                "root = config_helper.get_gai_config(file_path=file_path)\n",
                "print(root.model_dump_json(indent=2))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 2. Client Config\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "a) Get Client Config\n",
                "\n",
                "<div style=\"background: #949494; padding: 10px; color:black\">\n",
                "    client_config = config_helper.get_client_config(name=\"dolphin\")\n",
                "</div>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "client_type='gai' type='ttt' engine=None model=None name=None url='http://gai-ttt-svr:12031/gen/v1/chat/completions' env=None extra=None hyperparameters={}\n",
                        "client_type='openai' type='ttt' engine=None model=None name=None url=None env=None extra=None hyperparameters={}\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "from gai.lib.tests import get_local_datadir\n",
                "from gai.lib.config import config_helper\n",
                "\n",
                "file_path =  os.path.join(get_local_datadir(),\"gai.yml\")\n",
                "\n",
                "client_config = config_helper.get_client_config(name=\"ttt\",file_path=file_path)\n",
                "print(client_config)\n",
                "\n",
                "import os\n",
                "from gai.lib.tests import get_local_datadir\n",
                "from gai.lib.config import config_helper\n",
                "file_path =  os.path.join(get_local_datadir(),\"gai.yml\")\n",
                "\n",
                "client_config = config_helper.get_client_config(name=\"gpt-4o\",file_path=file_path)\n",
                "print(client_config)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "b) Get from Dict\n",
                "\n",
                "<div style=\"background: #949494; padding: 10px; color:black\">\n",
                "    client_config = config_helper.get_client_config(client_config={\n",
                "        \"type\": \"ttt\",\n",
                "        \"client_type\":\"gai\",\n",
                "        \"url\":\"http://gai-ttt-svr:12031/gen/v1/chat/completions\"\n",
                "    })\n",
                "</div>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "client_type='gai' type='ttt' engine='exllamav2' model='dolphin' name='dolphin' url='http://gai-ttt-svr:12031/gen/v1/chat/completions' env=None extra=None hyperparameters={}\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "from gai.lib.tests import get_local_datadir\n",
                "from gai.lib.config import config_helper\n",
                "file_path =  os.path.join(get_local_datadir(),\"gai.yml\")\n",
                "\n",
                "client_config = config_helper.get_client_config(client_config={\n",
                "    \"type\":\"ttt\",\n",
                "    \"engine\":\"exllamav2\",\n",
                "    \"model\":\"dolphin\",\n",
                "    \"name\":\"dolphin\",\n",
                "    \"client_type\":\"gai\",\n",
                "    \"url\":\"http://gai-ttt-svr:12031/gen/v1/chat/completions\"\n",
                "})\n",
                "\n",
                "print(client_config)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 3. Generator Config\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "a) Prepare Test Data (./tmp/gai.yml)\n",
                "\n",
                "Copy from ./data/generator_config/gai.yml into ./tmp/gai.yml"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "gai.yml:\n",
                        " {}\n",
                        "generator_config/gai.yml:\n",
                        " {'ttt': GaiGeneratorConfig(type='ttt', engine='exllamav2', model='dolphin3.0_llama3.1:4.25bpw', name='dolphin3.0_llama3.1:4.25bpw:exl2', hyperparameters={'temperature': 0.85, 'top_p': 0.8, 'top_k': 50, 'max_tokens': 1000, 'tool_choice': 'auto', 'max_retries': 5, 'stop': ['<|im_end|>', '</s>', '[/INST]']}, extra={'model_path': 'models/Dolphin3.0-Llama3.1-8B-4_25bpw-exl2', 'max_seq_len': 8192, 'prompt_format': 'llama', 'no_flash_attn': True, 'seed': None, 'decode_special_tokens': False}, module=ModuleConfig(name='gai.chat.server.gai_exllamav2', class_='GaiExLlamav2'), source=HuggingfaceDownloadConfig(type='huggingface', repo_id='bartowski/Dolphin3.0-Llama3.1-8B-exl2', revision='896301e945342d032ef0b3a81b57f0d5a8bac6fe', file=None)), 'dolphin3.0_llama3.1:4.25bpw:exl2': GaiGeneratorConfig(type='ttt', engine='exllamav2', model='dolphin3.0_llama3.1:4.25bpw', name='dolphin3.0_llama3.1:4.25bpw:exl2', hyperparameters={'temperature': 0.85, 'top_p': 0.8, 'top_k': 50, 'max_tokens': 1000, 'tool_choice': 'auto', 'max_retries': 5, 'stop': ['<|im_end|>', '</s>', '[/INST]']}, extra={'model_path': 'models/Dolphin3.0-Llama3.1-8B-4_25bpw-exl2', 'max_seq_len': 8192, 'prompt_format': 'llama', 'no_flash_attn': True, 'seed': None, 'decode_special_tokens': False}, module=ModuleConfig(name='gai.chat.server.gai_exllamav2', class_='GaiExLlamav2'), source=HuggingfaceDownloadConfig(type='huggingface', repo_id='bartowski/Dolphin3.0-Llama3.1-8B-exl2', revision='896301e945342d032ef0b3a81b57f0d5a8bac6fe', file=None))}\n"
                    ]
                }
            ],
            "source": [
                "# Reset ./tmp/gai.yml\n",
                "\n",
                "import os\n",
                "from gai.lib.tests import make_local_tmp,get_local_datadir\n",
                "data_path = get_local_datadir()\n",
                "app_path=make_local_tmp()\n",
                "\n",
                "source_gai_config_path = os.path.join(data_path,\"gai.yml\")\n",
                "gai_config_path = os.path.join(app_path,\"gai.yml\")\n",
                "\n",
                "import shutil\n",
                "shutil.copyfile(source_gai_config_path,gai_config_path)\n",
                "\n",
                "## \"./tmp/gai.yml\" should have no generators\n",
                "\n",
                "from gai.lib.config import GaiGeneratorConfig\n",
                "from gai.lib.config import config_helper\n",
                "gai_generators = config_helper.list_generator_configs(file_path=gai_config_path)\n",
                "print(\"gai.yml:\\n\", gai_generators)\n",
                "assert len(gai_generators) == 0\n",
                "\n",
                "## \"./data/generators_config/gai.yml\" should have 2 generators\n",
                "\n",
                "from gai.lib.tests import get_local_datadir\n",
                "from gai.lib.config import GaiGeneratorConfig\n",
                "\n",
                "data_path = get_local_datadir()\n",
                "server_config_path = os.path.join(data_path,\"generator_config\",\"gai.yml\")\n",
                "\n",
                "server_generators = config_helper.list_generator_configs(file_path=server_config_path)\n",
                "print(\"generator_config/gai.yml:\\n\", server_generators)\n",
                "assert len(server_generators) == 2\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "b) Update Gai Config (./tmp/gai.yml)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "gai.yml:\n",
                        " {'ttt': GaiGeneratorConfig(type='ttt', engine='exllamav2', model='dolphin3.0_llama3.1:4.25bpw', name='dolphin3.0_llama3.1:4.25bpw:exl2', hyperparameters={'temperature': 0.85, 'top_p': 0.8, 'top_k': 50, 'max_tokens': 1000, 'tool_choice': 'auto', 'max_retries': 5, 'stop': ['<|im_end|>', '</s>', '[/INST]']}, extra={'model_path': 'models/Dolphin3.0-Llama3.1-8B-4_25bpw-exl2', 'max_seq_len': 8192, 'prompt_format': 'llama', 'no_flash_attn': True, 'seed': None, 'decode_special_tokens': False}, module=ModuleConfig(name='gai.chat.server.gai_exllamav2', class_='GaiExLlamav2'), source=HuggingfaceDownloadConfig(type='huggingface', repo_id='bartowski/Dolphin3.0-Llama3.1-8B-exl2', revision='896301e945342d032ef0b3a81b57f0d5a8bac6fe', file=None)), 'dolphin3.0_llama3.1:4.25bpw:exl2': GaiGeneratorConfig(type='ttt', engine='exllamav2', model='dolphin3.0_llama3.1:4.25bpw', name='dolphin3.0_llama3.1:4.25bpw:exl2', hyperparameters={'temperature': 0.85, 'top_p': 0.8, 'top_k': 50, 'max_tokens': 1000, 'tool_choice': 'auto', 'max_retries': 5, 'stop': ['<|im_end|>', '</s>', '[/INST]']}, extra={'model_path': 'models/Dolphin3.0-Llama3.1-8B-4_25bpw-exl2', 'max_seq_len': 8192, 'prompt_format': 'llama', 'no_flash_attn': True, 'seed': None, 'decode_special_tokens': False}, module=ModuleConfig(name='gai.chat.server.gai_exllamav2', class_='GaiExLlamav2'), source=HuggingfaceDownloadConfig(type='huggingface', repo_id='bartowski/Dolphin3.0-Llama3.1-8B-exl2', revision='896301e945342d032ef0b3a81b57f0d5a8bac6fe', file=None))}\n"
                    ]
                }
            ],
            "source": [
                "config_helper.update_gai_config(\"generators\", builtin_config_path=server_config_path,global_config_path=gai_config_path)\n",
                "gai_generators = config_helper.list_generator_configs(file_path=gai_config_path)\n",
                "assert len(gai_generators) == 2\n",
                "print(\"gai.yml:\\n\", gai_generators)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "c) Get from Dict"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "type='ttt' engine='exllamav2' model='dolphin' name='dolphin3.0_llama3.1:4.25bpw:exl2' hyperparameters={} extra=None module=ModuleConfig(name='gai.ttt.exllamav2.gai_exllamav2', class_='GaiExllamav2') source=None\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "from  gai.lib.config import config_helper\n",
                "here = os.getcwd()\n",
                "file_path =  os.path.abspath(os.path.join(here,\"..\",\"..\",\"..\",\"lib\",\"src\",\"gai\",\"scripts\",\"data\",\"gai.yml\"))\n",
                "\n",
                "generator_config = config_helper.get_generator_config(generator_config={\n",
                "    \"type\":\"ttt\",\n",
                "    \"engine\":\"exllamav2\",\n",
                "    \"model\":\"dolphin\",\n",
                "    \"name\":\"dolphin3.0_llama3.1:4.25bpw:exl2\",\n",
                "    \"module\": {\n",
                "        \"name\":\"gai.ttt.exllamav2.gai_exllamav2\",\n",
                "        \"class\":\"GaiExllamav2\"\n",
                "    }\n",
                "})\n",
                "\n",
                "print(generator_config)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Get from Name"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "type='ttt' engine='exllamav2' model='dolphin3.0_llama3.1:4.25bpw' name='dolphin3.0_llama3.1:4.25bpw:exl2' hyperparameters={'temperature': 0.85, 'top_p': 0.8, 'top_k': 50, 'max_tokens': 1000, 'tool_choice': 'auto', 'max_retries': 5, 'stop': ['<|im_end|>', '</s>', '[/INST]']} extra={'model_path': 'models/Dolphin3.0-Llama3.1-8B-4_25bpw-exl2', 'max_seq_len': 8192, 'prompt_format': 'llama', 'no_flash_attn': True, 'seed': None, 'decode_special_tokens': False} module=ModuleConfig(name='gai.chat.server.gai_exllamav2', class_='GaiExLlamav2') source=HuggingfaceDownloadConfig(type='huggingface', repo_id='bartowski/Dolphin3.0-Llama3.1-8B-exl2', revision='896301e945342d032ef0b3a81b57f0d5a8bac6fe', file=None)\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "from gai.lib.tests import get_local_datadir\n",
                "from gai.lib.config import config_helper\n",
                "file_path =  os.path.join(get_local_datadir(),\"generator_config\",\"gai.yml\")\n",
                "\n",
                "generator_config = config_helper.get_generator_config(name=\"dolphin3.0_llama3.1:4.25bpw:exl2\",file_path=file_path)\n",
                "print(generator_config)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "d) Get from Ref\n",
                "\n",
                "Note: This generator config is an alias. The objective is to prove that the alias is resolved correctly.\n",
                "\n",
                "```yaml\n",
                "    ttt:\n",
                "        ref: dolphin3.0_llama3.1:4.25bpw:exl2\n",
                "\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "type='ttt' engine='exllamav2' model='dolphin3.0_llama3.1:4.25bpw' name='dolphin3.0_llama3.1:4.25bpw:exl2' hyperparameters={'temperature': 0.85, 'top_p': 0.8, 'top_k': 50, 'max_tokens': 1000, 'tool_choice': 'auto', 'max_retries': 5, 'stop': ['<|im_end|>', '</s>', '[/INST]']} extra={'model_path': 'models/Dolphin3.0-Llama3.1-8B-4_25bpw-exl2', 'max_seq_len': 8192, 'prompt_format': 'llama', 'no_flash_attn': True, 'seed': None, 'decode_special_tokens': False} module=ModuleConfig(name='gai.chat.server.gai_exllamav2', class_='GaiExLlamav2') source=HuggingfaceDownloadConfig(type='huggingface', repo_id='bartowski/Dolphin3.0-Llama3.1-8B-exl2', revision='896301e945342d032ef0b3a81b57f0d5a8bac6fe', file=None)\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "from gai.lib.tests import get_local_datadir\n",
                "from gai.lib.config import config_helper\n",
                "file_path =  os.path.join(get_local_datadir(),\"generator_config\",\"gai.yml\")\n",
                "\n",
                "generator_config = config_helper.get_generator_config(name=\"ttt\",file_path=file_path)\n",
                "print(generator_config)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 4. Download Config"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "type='huggingface' repo_id='bartowski/Dolphin3.0-Llama3.1-8B-exl2' revision='896301e945342d032ef0b3a81b57f0d5a8bac6fe' file=None\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "import json\n",
                "from gai.lib.config import config_helper\n",
                "from gai.lib.config.download_config import HuggingfaceDownloadConfig\n",
                "from gai.lib.tests import get_local_datadir\n",
                "file_path =  os.path.join(get_local_datadir(),\"generator_config\",\"gai.yml\")\n",
                "\n",
                "download_config = config_helper.get_download_config(name_or_config=\"dolphin3.0_llama3.1:4.25bpw:exl2\",file_path=file_path)\n",
                "print(download_config)\n",
                "assert isinstance(download_config, HuggingfaceDownloadConfig)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 5. Tool Config\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "a) Get tool config"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "type='tool' name='web' extra={'scraper': {'headless': True, 'scraper_type': 'playwright', 'no_cache': False, 'max_content_length': 250000, 'max_links': 100, 'max_depth': 1, 'max_retries': 3}}\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "from gai.lib.tests import get_local_datadir\n",
                "data_dir = get_local_datadir()\n",
                "source_config_path=os.path.join(data_dir,\"tool_config\",\"gai.yml\")\n",
                "from gai.lib.config import config_helper\n",
                "config=config_helper.get_tool_config(name=\"web\",file_path=source_config_path)\n",
                "print(config)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "a) Prepare Test Data (./tmp/gai.yml)\n",
                "\n",
                "Copy from ./data/tool_config/gai.yml into ./tmp/gai.yml"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "gai.yml:\n",
                        " {}\n",
                        "tool_config/gai.yml:\n",
                        " {'web': GaiToolConfig(type='rag', name='web', extra={'scraper': {'headless': True, 'scraper_type': 'playwright', 'no_cache': False, 'max_content_length': 250000, 'max_links': 100, 'max_depth': 1, 'max_retries': 3}})}\n"
                    ]
                }
            ],
            "source": [
                "# Reset ./tmp/gai.yml\n",
                "\n",
                "import os\n",
                "from gai.lib.tests import make_local_tmp,get_local_datadir\n",
                "data_path = get_local_datadir()\n",
                "app_path=make_local_tmp()\n",
                "\n",
                "source_gai_config_path = os.path.join(data_path,\"gai.yml\")\n",
                "gai_config_path = os.path.join(app_path,\"gai.yml\")\n",
                "\n",
                "import shutil\n",
                "shutil.copyfile(source_gai_config_path,gai_config_path)\n",
                "\n",
                "## \"./tmp/gai.yml\" should have no generators\n",
                "\n",
                "from gai.lib.config import GaiGeneratorConfig\n",
                "from gai.lib.config import config_helper\n",
                "gai_tools = config_helper.list_tool_configs(file_path=gai_config_path)\n",
                "print(\"gai.yml:\\n\", gai_tools)\n",
                "assert len(gai_tools) == 0\n",
                "\n",
                "## \"./data/tools_config/gai.yml\" should have 2 generators\n",
                "\n",
                "from gai.lib.tests import get_local_datadir\n",
                "from gai.lib.config import GaiGeneratorConfig\n",
                "\n",
                "data_path = get_local_datadir()\n",
                "server_config_path = os.path.join(data_path,\"tool_config\",\"gai.yml\")\n",
                "\n",
                "server_tools = config_helper.list_tool_configs(file_path=server_config_path)\n",
                "print(\"tool_config/gai.yml:\\n\", server_tools)\n",
                "assert len(server_tools) == 1\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "b) Update Gai Config (./tmp/gai.yml)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "gai.yml:\n",
                        " {'web': GaiToolConfig(type='rag', name='web', extra={'scraper': {'headless': True, 'scraper_type': 'playwright', 'no_cache': False, 'max_content_length': 250000, 'max_links': 100, 'max_depth': 1, 'max_retries': 3}})}\n"
                    ]
                }
            ],
            "source": [
                "config_helper.update_gai_config(\"tools\", builtin_config_path=server_config_path,global_config_path=gai_config_path)\n",
                "gai_tools = config_helper.list_tool_configs(file_path=gai_config_path)\n",
                "assert len(gai_tools) == 1\n",
                "print(\"gai.yml:\\n\", gai_tools)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "c) Get from Dict"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "{'type': 'tool', 'name': 'web', 'extra': {'scraper': {'headless': True, 'timeout': 60, 'max_content_length': 1000000}}}\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "from  gai.lib.config import config_helper\n",
                "tool_config = config_helper.get_tool_config(tool_config={\n",
                "    \"type\":\"tool\",\n",
                "    \"name\":\"web\",\n",
                "    \"extra\": {\n",
                "        \"scraper\":{\n",
                "            \"headless\":True,\n",
                "            \"timeout\":60,\n",
                "            \"max_content_length\":1000000,\n",
                "        }\n",
                "    }\n",
                "})\n",
                "\n",
                "print(tool_config)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 5. MCP Config\n",
                "\n",
                "MCP config is a special type of client config.\n",
                "\n",
                "Example:\n",
                "\n",
                "```yaml\n",
                "mcp-web:\n",
                "    type: mcp\n",
                "    client_type: gai\n",
                "    url: file://../../src/gai/mcp/web/mcp_server/mcp_server.py\n",
                "```\n",
                "\n",
                "In thie case, the url represents the file path of the mcp_server.py file relative to **MCP Client**.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "mcp_server_path= file://../../src/gai/mcp/web/mcp_server/mcp_server.py\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "from gai.lib.tests import get_local_datadir\n",
                "from gai.lib.config import config_helper\n",
                "file_path =  os.path.join(get_local_datadir(),\"gai.yml\")\n",
                "\n",
                "mcp_config = config_helper.get_client_config(name=\"mcp-web\",file_path=file_path)\n",
                "print(\"mcp_server_path=\",mcp_config.url)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.17"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
