import logging
import os
from pathlib import Path
from typing import Optional
from urllib.parse import urlparse

import typer
from rich.console import Console

from pyhub import init
from pyhub.config import DEFAULT_ENV_PATH, DEFAULT_TOML_PATH
from pyhub.llm.types import EmbeddingDimensionsEnum, LLMEmbeddingModelEnum

# Create pgvector subcommand group
app = typer.Typer(
    name="pgvector",
    help="PostgreSQL pgvector ê´€ë ¨ ëª…ë ¹ì–´",
    invoke_without_command=True,
)
console = Console()


@app.callback()
def pgvector_callback(ctx: typer.Context):
    """PostgreSQL pgvector ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬ë¥¼ ìœ„í•œ ì„œë¸Œì»¤ë§¨ë“œì…ë‹ˆë‹¤."""
    if ctx.invoked_subcommand is None:
        # ì„œë¸Œì»¤ë§¨ë“œê°€ ì—†ìœ¼ë©´ help ì¶œë ¥
        console.print(ctx.get_help())
        raise typer.Exit()


def get_database_url(
    database_url: Optional[str] = None,
    database_alias: Optional[str] = None,
) -> str:
    """ë°ì´í„°ë² ì´ìŠ¤ URLì„ ê²°ì •í•©ë‹ˆë‹¤.

    ìš°ì„ ìˆœìœ„:
    1. ì§ì ‘ ì§€ì •ëœ database_url
    2. Django ì„¤ì •ì˜ database_alias
    3. í™˜ê²½ë³€ìˆ˜ (PGVECTOR_DATABASE_URL, VECTOR_DATABASE_URL, DATABASE_URL)
    """
    # 1. ì§ì ‘ ì§€ì •ëœ URL
    if database_url:
        return database_url

    # 2. Django ì„¤ì •ì—ì„œ ë³„ì¹­ìœ¼ë¡œ ì°¾ê¸°
    if database_alias:
        from django.conf import settings

        if database_alias in settings.DATABASES:
            db_config = settings.DATABASES[database_alias]
            if "postgresql" not in db_config.get("ENGINE", ""):
                raise typer.BadParameter(f"Database alias '{database_alias}' is not a PostgreSQL database")
            # Django ì„¤ì •ì„ URLë¡œ ë³€í™˜
            return build_database_url_from_config(db_config)
        else:
            raise typer.BadParameter(f"Database alias '{database_alias}' not found")

    # 3. í™˜ê²½ë³€ìˆ˜ì—ì„œ ì°¾ê¸°
    for env_var in ["PGVECTOR_DATABASE_URL", "VECTOR_DATABASE_URL", "DATABASE_URL"]:
        if url := os.environ.get(env_var):
            if url.startswith("postgresql://") or url.startswith("postgres://"):
                return url

    # 4. Django ì„¤ì •ì—ì„œ PostgreSQL DB ì°¾ê¸°
    try:
        from django.conf import settings

        for alias, config in settings.DATABASES.items():
            if "postgresql" in config.get("ENGINE", ""):
                console.print(f"[dim]Using Django database '{alias}'[/dim]")
                return build_database_url_from_config(config)
    except:
        pass

    raise typer.BadParameter(
        "PostgreSQL database URL not found. " "Please specify --database-url or set DATABASE_URL environment variable"
    )


def build_database_url_from_config(config: dict) -> str:
    """Django ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •ì„ URLë¡œ ë³€í™˜"""
    user = config.get("USER", "")
    password = config.get("PASSWORD", "")
    host = config.get("HOST", "localhost")
    port = config.get("PORT", "5432")
    dbname = config.get("NAME", "")

    auth = f"{user}:{password}@" if user else ""
    return f"postgresql://{auth}{host}:{port}/{dbname}"


@app.command()
def check(
    database_url: Optional[str] = typer.Option(
        None, "--database-url", "-e", help="PostgreSQL ì—°ê²° URL", envvar="DATABASE_URL"
    ),
    database_alias: str = typer.Option("default", "--database", "-d", help="Django ë°ì´í„°ë² ì´ìŠ¤ ë³„ì¹­"),
    toml_path: Optional[Path] = typer.Option(
        DEFAULT_TOML_PATH,
        "--toml-file",
        help="toml ì„¤ì • íŒŒì¼ ê²½ë¡œ",
    ),
    env_path: Optional[Path] = typer.Option(
        DEFAULT_ENV_PATH,
        "--env-file",
        help="í™˜ê²½ ë³€ìˆ˜ íŒŒì¼(.env) ê²½ë¡œ",
    ),
):
    """pgvector í™•ì¥ì´ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤."""

    init(toml_path=toml_path, env_path=env_path)

    try:
        import psycopg2
    except ImportError:
        console.print("[red]âŒ psycopg2 íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.[/red]")
        console.print("[dim]ì„¤ì¹˜: pip install psycopg2-binary[/dim]")
        raise typer.Exit(code=1)

    db_url = get_database_url(database_url, database_alias)

    try:
        # URL íŒŒì‹±
        parsed = urlparse(db_url)
        console.print(f"[dim]Connecting to {parsed.hostname}:{parsed.port}/{parsed.path[1:]}...[/dim]")

        conn = psycopg2.connect(db_url)
        cursor = conn.cursor()

        # pgvector í™•ì¥ í™•ì¸
        cursor.execute("SELECT installed_version FROM pg_available_extensions WHERE name = 'vector'")
        result = cursor.fetchone()

        if result and result[0]:
            console.print(f"[green]âœ“ pgvector {result[0]} is installed[/green]")

            # ë²¡í„° í…Œì´ë¸” ìˆ˜ í™•ì¸
            cursor.execute(
                """
                SELECT COUNT(*) 
                FROM information_schema.columns 
                WHERE data_type = 'USER-DEFINED' 
                AND udt_name = 'vector'
            """
            )
            vector_columns = cursor.fetchone()[0]
            console.print(f"[dim]  Vector columns found: {vector_columns}[/dim]")

        else:
            console.print("[yellow]âš ï¸  pgvector extension is not installed[/yellow]")
            console.print("[dim]  Run: CREATE EXTENSION vector;[/dim]")
            raise typer.Exit(code=1)

        cursor.close()
        conn.close()

    except psycopg2.Error as e:
        console.print(f"[red]âŒ Database connection failed: {e}[/red]")
        raise typer.Exit(code=1)


@app.command(name="install-extension")
def install_extension(
    database_url: Optional[str] = typer.Option(
        None, "--database-url", "-e", help="PostgreSQL ì—°ê²° URL", envvar="DATABASE_URL"
    ),
    database_alias: str = typer.Option("default", "--database", "-d", help="Django ë°ì´í„°ë² ì´ìŠ¤ ë³„ì¹­"),
    toml_path: Optional[Path] = typer.Option(
        DEFAULT_TOML_PATH,
        "--toml-file",
        help="toml ì„¤ì • íŒŒì¼ ê²½ë¡œ",
    ),
    env_path: Optional[Path] = typer.Option(
        DEFAULT_ENV_PATH,
        "--env-file",
        help="í™˜ê²½ ë³€ìˆ˜ íŒŒì¼(.env) ê²½ë¡œ",
    ),
):
    """pgvector í™•ì¥ì„ ì„¤ì¹˜í•©ë‹ˆë‹¤ (CREATE EXTENSION vector)."""

    init(toml_path=toml_path, env_path=env_path)

    try:
        import psycopg2
    except ImportError:
        console.print("[red]âŒ psycopg2 íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.[/red]")
        raise typer.Exit(code=1)

    db_url = get_database_url(database_url, database_alias)

    try:
        conn = psycopg2.connect(db_url)
        cursor = conn.cursor()

        # í™•ì¥ ì„¤ì¹˜
        cursor.execute("CREATE EXTENSION IF NOT EXISTS vector")
        conn.commit()

        # ë²„ì „ í™•ì¸
        cursor.execute("SELECT extversion FROM pg_extension WHERE extname = 'vector'")
        version = cursor.fetchone()[0]

        console.print(f"[green]âœ“ pgvector {version} extension installed successfully[/green]")

        cursor.close()
        conn.close()

    except psycopg2.Error as e:
        console.print(f"[red]âŒ Failed to install extension: {e}[/red]")
        if "permission denied" in str(e).lower():
            console.print("[dim]  You may need superuser privileges[/dim]")
        raise typer.Exit(code=1)


@app.command(name="create-table")
def create_table(
    table_name: str = typer.Argument(..., help="ìƒì„±í•  í…Œì´ë¸” ì´ë¦„"),
    database_url: Optional[str] = typer.Option(
        None, "--database-url", "-e", help="PostgreSQL ì—°ê²° URL", envvar="DATABASE_URL"
    ),
    database_alias: str = typer.Option("default", "--database", "-d", help="Django ë°ì´í„°ë² ì´ìŠ¤ ë³„ì¹­"),
    dimensions: EmbeddingDimensionsEnum = typer.Option(
        EmbeddingDimensionsEnum.D_1536, "--dimensions", help="ë²¡í„° ì°¨ì›"
    ),
    index_type: str = typer.Option("hnsw", "--index-type", help="ì¸ë±ìŠ¤ íƒ€ì… (hnsw, ivfflat)"),
    distance_metric: str = typer.Option("cosine", "--distance-metric", help="ê±°ë¦¬ ë©”íŠ¸ë¦­ (cosine, l2, inner_product)"),
    toml_path: Optional[Path] = typer.Option(
        DEFAULT_TOML_PATH,
        "--toml-file",
        help="toml ì„¤ì • íŒŒì¼ ê²½ë¡œ",
    ),
    env_path: Optional[Path] = typer.Option(
        DEFAULT_ENV_PATH,
        "--env-file",
        help="í™˜ê²½ ë³€ìˆ˜ íŒŒì¼(.env) ê²½ë¡œ",
    ),
    is_verbose: bool = typer.Option(False, "--verbose"),
):
    """PostgreSQLì— pgvector í…Œì´ë¸”ì„ ìƒì„±í•©ë‹ˆë‹¤."""

    log_level = logging.DEBUG if is_verbose else logging.INFO
    init(debug=True, log_level=log_level, toml_path=toml_path, env_path=env_path)

    try:
        import psycopg2
    except ImportError:
        console.print("[red]âŒ psycopg2 íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.[/red]")
        raise typer.Exit(code=1)

    db_url = get_database_url(database_url, database_alias)

    # ê±°ë¦¬ í•¨ìˆ˜ ë§¤í•‘
    distance_ops = {"cosine": "vector_cosine_ops", "l2": "vector_l2_ops", "inner_product": "vector_ip_ops"}

    if distance_metric not in distance_ops:
        console.print(f"[red]âŒ Invalid distance metric: {distance_metric}[/red]")
        raise typer.Exit(code=1)

    try:
        conn = psycopg2.connect(db_url)
        cursor = conn.cursor()

        # í…Œì´ë¸” ìƒì„±
        create_sql = f"""
        CREATE TABLE IF NOT EXISTS {table_name} (
            id SERIAL PRIMARY KEY,
            page_content TEXT NOT NULL,
            metadata JSONB,
            embedding vector({dimensions.value})
        )
        """

        cursor.execute(create_sql)

        # ì¸ë±ìŠ¤ ìƒì„±
        if index_type == "hnsw":
            index_sql = f"""
            CREATE INDEX IF NOT EXISTS {table_name}_embedding_idx 
            ON {table_name} 
            USING hnsw (embedding {distance_ops[distance_metric]})
            """
        else:  # ivfflat
            index_sql = f"""
            CREATE INDEX IF NOT EXISTS {table_name}_embedding_idx 
            ON {table_name} 
            USING ivfflat (embedding {distance_ops[distance_metric]})
            WITH (lists = 100)
            """

        cursor.execute(index_sql)
        conn.commit()

        # ë°ì´í„°ë² ì´ìŠ¤ ì •ë³´
        parsed = urlparse(db_url)
        console.print(f"[green]âœ“ '{table_name}' í…Œì´ë¸”ì„ ì„±ê³µì ìœ¼ë¡œ ìƒì„±í–ˆìŠµë‹ˆë‹¤.[/green]")
        console.print(f"[dim]ë°ì´í„°ë² ì´ìŠ¤: {parsed.hostname}:{parsed.port}/{parsed.path[1:]}[/dim]")
        console.print(f"[dim]ì¸ë±ìŠ¤ íƒ€ì…: {index_type} ({distance_metric})[/dim]")

        cursor.close()
        conn.close()

    except psycopg2.Error as e:
        if "already exists" in str(e):
            console.print(f"[red]âŒ í…Œì´ë¸” ìƒì„± ì‹¤íŒ¨: '{table_name}' í…Œì´ë¸”ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.[/red]")
            parsed = urlparse(db_url)
            console.print(f"[dim]ë°ì´í„°ë² ì´ìŠ¤: {parsed.hostname}:{parsed.port}/{parsed.path[1:]}[/dim]")
        else:
            console.print(f"[red]âŒ Error creating table: {e}[/red]")
        raise typer.Exit(code=1)


@app.command(name="import-jsonl")
def import_jsonl(
    jsonl_path: Path = typer.Argument(..., help="ì„í¬íŠ¸í•  JSONL íŒŒì¼"),
    database_url: Optional[str] = typer.Option(
        None, "--database-url", "-e", help="PostgreSQL ì—°ê²° URL", envvar="DATABASE_URL"
    ),
    database_alias: str = typer.Option("default", "--database", "-d", help="Django ë°ì´í„°ë² ì´ìŠ¤ ë³„ì¹­"),
    table_name: str = typer.Option(..., "--table", "-t", help="ëŒ€ìƒ í…Œì´ë¸” ì´ë¦„"),
    batch_size: int = typer.Option(1000, "--batch-size", help="ë°°ì¹˜ í¬ê¸°"),
    clear: bool = typer.Option(False, "--clear", "-c", help="ê¸°ì¡´ ë°ì´í„° ì‚­ì œ"),
    toml_path: Optional[Path] = typer.Option(
        DEFAULT_TOML_PATH,
        "--toml-file",
        help="toml ì„¤ì • íŒŒì¼ ê²½ë¡œ",
    ),
    env_path: Optional[Path] = typer.Option(
        DEFAULT_ENV_PATH,
        "--env-file",
        help="í™˜ê²½ ë³€ìˆ˜ íŒŒì¼(.env) ê²½ë¡œ",
    ),
    is_verbose: bool = typer.Option(False, "--verbose"),
):
    """JSONL íŒŒì¼ì„ PostgreSQL pgvector í…Œì´ë¸”ë¡œ ì„í¬íŠ¸í•©ë‹ˆë‹¤."""

    if not jsonl_path.exists():
        console.print(f"[red]âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {jsonl_path}[/red]")
        raise typer.Exit(code=1)

    log_level = logging.DEBUG if is_verbose else logging.INFO
    init(debug=True, log_level=log_level, toml_path=toml_path, env_path=env_path)

    try:
        import json

        import psycopg2
        import psycopg2.extras
    except ImportError:
        console.print("[red]âŒ psycopg2 íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.[/red]")
        raise typer.Exit(code=1)

    db_url = get_database_url(database_url, database_alias)

    try:
        conn = psycopg2.connect(db_url)
        cursor = conn.cursor()

        # í…Œì´ë¸” ì¡´ì¬ í™•ì¸
        cursor.execute("SELECT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_name = %s)", (table_name,))
        if not cursor.fetchone()[0]:
            console.print(f"[red]âŒ í…Œì´ë¸” '{table_name}'ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.[/red]")
            console.print(f"[dim]ë¨¼ì € 'pyhub.rag pgvector create-table {table_name}' ëª…ë ¹ì„ ì‹¤í–‰í•˜ì„¸ìš”.[/dim]")
            raise typer.Exit(code=1)

        # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ
        if clear:
            cursor.execute(f"TRUNCATE TABLE {table_name}")
            console.print("[yellow]ê¸°ì¡´ ë°ì´í„°ë¥¼ ì‚­ì œí–ˆìŠµë‹ˆë‹¤.[/yellow]")

        # JSONL íŒŒì¼ ì½ê¸° ë° ì„í¬íŠ¸
        total = 0
        batch = []

        with jsonl_path.open("r", encoding="utf-8") as f:
            for line in f:
                data = json.loads(line.strip())

                # ë°ì´í„° ê²€ì¦
                if "page_content" not in data or "embedding" not in data:
                    console.print(f"[yellow]âš ï¸  Invalid data format at line {total + 1}[/yellow]")
                    continue

                batch.append((data["page_content"], json.dumps(data.get("metadata", {})), data["embedding"]))

                # ë°°ì¹˜ ì²˜ë¦¬
                if len(batch) >= batch_size:
                    psycopg2.extras.execute_batch(
                        cursor,
                        f"""
                        INSERT INTO {table_name} (page_content, metadata, embedding)
                        VALUES (%s, %s::jsonb, %s::vector)
                        """,
                        batch,
                    )
                    total += len(batch)
                    console.print(f"[dim]Imported {total} records...[/dim]")
                    batch = []

        # ë‚¨ì€ ë°ì´í„° ì²˜ë¦¬
        if batch:
            psycopg2.extras.execute_batch(
                cursor,
                f"""
                INSERT INTO {table_name} (page_content, metadata, embedding)
                VALUES (%s, %s::jsonb, %s::vector)
                """,
                batch,
            )
            total += len(batch)

        conn.commit()

        parsed = urlparse(db_url)
        console.print(f"[green]âœ“ {total}ê°œì˜ ë ˆì½”ë“œë¥¼ ì„±ê³µì ìœ¼ë¡œ ì„í¬íŠ¸í–ˆìŠµë‹ˆë‹¤.[/green]")
        console.print(f"[dim]í…Œì´ë¸”: {table_name}[/dim]")
        console.print(f"[dim]ë°ì´í„°ë² ì´ìŠ¤: {parsed.hostname}:{parsed.port}/{parsed.path[1:]}[/dim]")

        cursor.close()
        conn.close()

    except psycopg2.Error as e:
        console.print(f"[red]âŒ Import failed: {e}[/red]")
        raise typer.Exit(code=1)


@app.command(name="similarity-search")
def similarity_search(
    ctx: typer.Context,
    query: str = typer.Argument(None, help="ê²€ìƒ‰í•  í…ìŠ¤íŠ¸"),
    database_url: Optional[str] = typer.Option(
        None, "--database-url", "-e", help="PostgreSQL ì—°ê²° URL", envvar="DATABASE_URL"
    ),
    database_alias: str = typer.Option("default", "--database", "-d", help="Django ë°ì´í„°ë² ì´ìŠ¤ ë³„ì¹­"),
    table_name: str = typer.Option(..., "--table", "-t", help="ê²€ìƒ‰í•  í…Œì´ë¸”"),
    embedding_model: LLMEmbeddingModelEnum = typer.Option(
        LLMEmbeddingModelEnum.TEXT_EMBEDDING_3_SMALL, "--model", "-m", help="ì„ë² ë”© ëª¨ë¸"
    ),
    limit: int = typer.Option(10, "--limit", "-l", help="ê²°ê³¼ ê°œìˆ˜"),
    threshold: Optional[float] = typer.Option(None, "--threshold", help="ìœ ì‚¬ë„ ì„ê³„ê°’ (0-1)"),
    distance_metric: str = typer.Option("cosine", "--distance-metric", help="ê±°ë¦¬ ë©”íŠ¸ë¦­ (cosine, l2, inner_product)"),
    no_metadata: bool = typer.Option(False, "--no-metadata", help="ë©”íƒ€ë°ì´í„° ìˆ¨ê¹€"),
    toml_path: Optional[Path] = typer.Option(
        DEFAULT_TOML_PATH,
        "--toml-file",
        help="toml ì„¤ì • íŒŒì¼ ê²½ë¡œ",
    ),
    env_path: Optional[Path] = typer.Option(
        DEFAULT_ENV_PATH,
        "--env-file",
        help="í™˜ê²½ ë³€ìˆ˜ íŒŒì¼(.env) ê²½ë¡œ",
    ),
    is_verbose: bool = typer.Option(False, "--verbose"),
):
    """PostgreSQL pgvectorì—ì„œ ìœ ì‚¬ë„ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""

    # queryê°€ ì—†ìœ¼ë©´ help ì¶œë ¥
    if query is None:
        console.print(ctx.get_help())
        raise typer.Exit()

    log_level = logging.DEBUG if is_verbose else logging.INFO
    init(debug=True, log_level=log_level, toml_path=toml_path, env_path=env_path)

    try:
        import json

        import psycopg2

        from pyhub.llm import LLM
    except ImportError as e:
        console.print(f"[red]âŒ Required package not found: {e}[/red]")
        raise typer.Exit(code=1)

    db_url = get_database_url(database_url, database_alias)

    # ê±°ë¦¬ í•¨ìˆ˜ ë§¤í•‘
    distance_funcs = {"cosine": "<=>", "l2": "<->", "inner_product": "<#>"}

    if distance_metric not in distance_funcs:
        console.print(f"[red]âŒ Invalid distance metric: {distance_metric}[/red]")
        raise typer.Exit(code=1)

    try:
        # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
        console.print("[dim]Generating embedding for query...[/dim]")
        llm = LLM.create(model=embedding_model)
        query_embedding = llm.embed(query)

        # ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰
        conn = psycopg2.connect(db_url)
        cursor = conn.cursor()

        # ìœ ì‚¬ë„ ê²€ìƒ‰ ì¿¼ë¦¬
        search_sql = f"""
        SELECT 
            page_content,
            metadata,
            1 - (embedding {distance_funcs[distance_metric]} %s::vector) as similarity
        FROM {table_name}
        WHERE 1 = 1
        """

        params = [query_embedding]

        # ì„ê³„ê°’ ì¡°ê±´ ì¶”ê°€
        if threshold is not None:
            search_sql += f" AND 1 - (embedding {distance_funcs[distance_metric]} %s::vector) >= %s"
            params.append(query_embedding)
            params.append(threshold)

        search_sql += f"""
        ORDER BY embedding {distance_funcs[distance_metric]} %s::vector
        LIMIT %s
        """
        params.extend([query_embedding, limit])

        cursor.execute(search_sql, params)
        results = cursor.fetchall()

        if not results:
            console.print("[yellow]ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.[/yellow]")
        else:
            console.print(f"\n[green]ê²€ìƒ‰ ê²°ê³¼ ({len(results)}ê°œ):[/green]\n")

            for i, (content, metadata, similarity) in enumerate(results):
                console.print(f"[bold]#{i+1} (ìœ ì‚¬ë„: {similarity:.4f})[/bold]")

                if not no_metadata and metadata:
                    console.print(f"[dim]metadata: {json.dumps(metadata, ensure_ascii=False)}[/dim]")

                console.print(content.strip())

                if i < len(results) - 1:
                    console.print("\n" + "-" * 50 + "\n")

        cursor.close()
        conn.close()

    except Exception as e:
        console.print(f"[red]âŒ Search failed: {e}[/red]")
        raise typer.Exit(code=1)


@app.command()
def stats(
    table_name: str = typer.Argument(..., help="í†µê³„ë¥¼ í™•ì¸í•  í…Œì´ë¸”"),
    database_url: Optional[str] = typer.Option(
        None, "--database-url", "-e", help="PostgreSQL ì—°ê²° URL", envvar="DATABASE_URL"
    ),
    database_alias: str = typer.Option("default", "--database", "-d", help="Django ë°ì´í„°ë² ì´ìŠ¤ ë³„ì¹­"),
    toml_path: Optional[Path] = typer.Option(
        DEFAULT_TOML_PATH,
        "--toml-file",
        help="toml ì„¤ì • íŒŒì¼ ê²½ë¡œ",
    ),
    env_path: Optional[Path] = typer.Option(
        DEFAULT_ENV_PATH,
        "--env-file",
        help="í™˜ê²½ ë³€ìˆ˜ íŒŒì¼(.env) ê²½ë¡œ",
    ),
):
    """í…Œì´ë¸”ì˜ ë²¡í„° í†µê³„ë¥¼ í™•ì¸í•©ë‹ˆë‹¤."""

    init(toml_path=toml_path, env_path=env_path)

    try:
        import psycopg2
    except ImportError:
        console.print("[red]âŒ psycopg2 íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.[/red]")
        raise typer.Exit(code=1)

    db_url = get_database_url(database_url, database_alias)

    try:
        conn = psycopg2.connect(db_url)
        cursor = conn.cursor()

        # í…Œì´ë¸” ì •ë³´
        cursor.execute(f"SELECT COUNT(*) FROM {table_name}")
        total_rows = cursor.fetchone()[0]

        # ë²¡í„° ì°¨ì›
        cursor.execute(
            f"""
            SELECT 
                dimension(embedding) as dim
            FROM {table_name}
            LIMIT 1
        """
        )
        result = cursor.fetchone()
        dimensions = result[0] if result else 0

        # ì¸ë±ìŠ¤ ì •ë³´
        cursor.execute(
            """
            SELECT 
                indexname,
                indexdef
            FROM pg_indexes
            WHERE tablename = %s
            AND indexdef LIKE '%embedding%'
        """,
            (table_name,),
        )
        indexes = cursor.fetchall()

        # í…Œì´ë¸” í¬ê¸°
        cursor.execute(
            """
            SELECT 
                pg_size_pretty(pg_total_relation_size(%s::regclass))
        """,
            (table_name,),
        )
        table_size = cursor.fetchone()[0]

        # ì¶œë ¥
        console.print(f"\n[bold]ğŸ“Š Table Statistics: {table_name}[/bold]\n")
        console.print(f"Total rows: {total_rows:,}")
        console.print(f"Vector dimensions: {dimensions}")
        console.print(f"Table size: {table_size}")

        if indexes:
            console.print("\n[bold]Indexes:[/bold]")
            for idx_name, idx_def in indexes:
                console.print(f"  â€¢ {idx_name}")
                if "hnsw" in idx_def:
                    console.print("    [dim]Type: HNSW[/dim]")
                elif "ivfflat" in idx_def:
                    console.print("    [dim]Type: IVFFlat[/dim]")

        cursor.close()
        conn.close()

    except psycopg2.Error as e:
        console.print(f"[red]âŒ Error: {e}[/red]")
        raise typer.Exit(code=1)
