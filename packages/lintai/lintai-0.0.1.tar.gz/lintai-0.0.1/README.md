# Lintai

**Lintai** is an experimental **AI-aware static-analysis tool** that spots _LLM-specific_ security bugs (prompt-injection, insecure output handling, data-leakage â€¦) **before** code ships.

| Why Lintai?                                                                              | What it does                                                                                                                         |
| ---------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------ |
| Traditional SAST canâ€™t â€œseeâ€ how you build prompts, stream completions or store vectors. | Lintai walks your AST, tags every AI sink (OpenAI, Anthropic, LangChain, â€¦), follows wrapper chains, then asks an LLM to judge risk. |

> **Requires Python â‰¥ 3.10**

---

## âœ¨ Key features

- **Two analysis commands**
  - `lintai ai-inventory <src-code-path>` â€“ list every AI call and its caller chain
  - `lintai scan <src-code-path>` â€“ run all detectors, emit JSON (with _llm_usage_ summary)
- **LLM budget guard-rails** â€“ hard caps on requests / tokens / cost (`LINTAI_MAX_LLM_*`)
- Modular detector registry (`entry_points`)
- OWASP LLM Top-10 & MITRE ATT&CK baked in
- DSL for custom rules
- CI-friendly JSON output (SARIF soon)

### âš ï¸ UI Notice

A React/Cytoscape UI is under active development â€“ not shipped in this cut.

---

## ğŸš€ Quick start

### 1 Â· Install

```bash
pip install lintai                    # core only
pip install "lintai[openai]"          # + OpenAI detectors
# or  "lintai[anthropic]"  "lintai[gemini]"  "lintai[cohere]"
pip install "lintai[ui]"              # FastAPI server extras
```

### 2 Â· Enable LLM detectors (optional but highly recommended)

```bash
# .env  (minimal)
LINTAI_LLM_PROVIDER=openai                # azure / anthropic / gemini / cohere / dummy
LLM_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxx    # API key for above provider

# provider-specific knobs
LLM_MODEL_NAME=gpt-4.1-mini
LLM_ENDPOINT_URL=https://api.openai.com/v1/
LLM_API_VERSION=2025-01-01-preview         # Required for Azure

# hard budget caps
LINTAI_MAX_LLM_TOKENS=50000
LINTAI_MAX_LLM_COST_USD=10
LINTAI_MAX_LLM_REQUESTS=500
```

Lintai auto-loads `.env`; the UI writes the same file, so CLI & browser stay in sync.

### 3 Â· Run

```bash
lintai ai-inventory src/ --ai-call-depth 4
lintai scan src/
```

### 4 Â· Launch REST server (Optional, React UI coming soon)

```bash
lintai ui                     # REST docs at http://localhost:8501/api/docs
```

---

## ğŸ”¬ How LLM detectors work

LLM-powered rules collect the **full source** of functions that call AI frameworks, plus their caller chain, and ask an external LLM to classify OWASP risks.

Budget checks run _before_ the call; actual usage is recorded afterwards.

---

## ğŸ”§ Common flags

| Flag              | Description                              |
| ----------------- | ---------------------------------------- |
| `-l DEBUG`        | Verbose logging                          |
| `--ruleset <dir>` | Load custom YAML/JSON rules              |
| `--output <file>` | Write full JSON report instead of stdout |

---

## ğŸ§ª Sample `scan` output

```json
{
  "llm_usage": {
    "tokens_used": 3544,
    "usd_used": 0.11,
    "requests": 6,
    "limits": { "tokens": 50000, "usd": 10, "requests": 500 }
  },
  "findings": [
    {
      "owasp_id": "LLM01",
      "severity": "blocker",
      "location": "services/chat.py:57",
      "message": "User-tainted f-string used in prompt",
      "fix": "Wrap variable in escape_braces()"
    }
  ]
}
```

---

## ğŸ“¦ Directory layout

lintai/
â”œâ”€â”€ cli.py Typer entry-point
â”œâ”€â”€ engine/ AST walker & AI-call analysis
â”œâ”€â”€ detectors/ Static & LLM-backed rules
â”œâ”€â”€ dsl/ Custom rule loader
â”œâ”€â”€ llm/ Provider clients & token-budget manager
â”œâ”€â”€ components/ Maps common AI frameworks â†’ canonical types
â”œâ”€â”€ core/ Finding & report model
â”œâ”€â”€ ui/ FastAPI backend (+ React UI coming soon)
â””â”€â”€ tests/ Unit / integration tests

examples/ Sample code with insecure AI usage

## ğŸŒ REST API cheat-sheet

| Method & path            | Body / Params        | Purpose                             |
| ------------------------ | -------------------- | ----------------------------------- |
| `GET  /api/health`       | â€“                    | Liveness probe                      |
| `GET  /api/config`       | â€“                    | Read current config                 |
| `POST /api/config`       | `ConfigModel` JSON   | Update settings (path, depth â€¦)     |
| `GET /POST /api/env`     | `EnvPayload` JSON    | Read / update non-secret .env       |
| `POST /api/secrets`      | `SecretPayload` JSON | Store API key (write-only)          |
| `POST /api/scan`         | multipart files      | Run detectors on uploaded code      |
| `POST /api/inventory`    | `path=<dir>`         | Inventory run on server-side folder |
| `GET  /api/runs`         | â€“                    | List all runs + status              |
| `GET  /api/results/{id}` | â€“                    | Fetch scan / inventory report       |

Auto-generated OpenAPI docs live at **`/api/docs`**.

---

## ğŸ“º Roadmap

- React JS UI support
- SARIF + GitHub Actions template
- Additional AI frameworks recognition and categorization
- Lintai VS Code extension
- Live taint-tracking

---

## ğŸ¤ Contributing

1. **Star** the repo â­
2. `git checkout -b feat/my-fix`
3. `pytest -q` (all green)
4. Open a PR â€“ or a draft PR early
5. See `CONTRIBUTING.md`

Created by **Harsh Parandekar** â€” [LinkedIn](https://linkedin.com/in/hparandekar)
Licensed under **Apache 2.0**
