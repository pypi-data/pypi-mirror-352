#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
Analizador de grupos funcionales con IA (Anthropic Claude).

Este mÃ³dulo implementa anÃ¡lisis inteligente de grupos funcionales usando
la API de Anthropic para generar anÃ¡lisis detallados de cada archivo
dentro de los grupos detectados.
"""

import os
import json
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional, Any, Tuple
import time

from src.utils.logger import get_logger
from src.integrations.anthropic_advanced import AdvancedAnthropicClient
from src.analyzers.project_progress_tracker import ProjectProgressTracker
from src.analyzers.dependency_graph import DependencyGraph
from src.utils.config import ConfigManager
from src.ui.cli import CLI
from src.utils.token_counter import AnthropicTokenCounter

# Configurar logger
logger = get_logger()


class AIGroupAnalyzer:
    """Analizador de grupos funcionales con IA."""
    
    def __init__(self, config: Optional[ConfigManager] = None):
        """
        Inicializar el analizador de grupos con IA.
        
        Args:
            config: ConfiguraciÃ³n opcional
        """
        self.config = config or ConfigManager()
        self.ai_client = AdvancedAnthropicClient(config=self.config)
        self.cli = CLI()
        self.token_counter = AnthropicTokenCounter()
        
        # ConfiguraciÃ³n de anÃ¡lisis
        self.batch_size = self.config.get("ai_analysis.batch_size", 5)
        self.max_file_size = self.config.get("ai_analysis.max_file_size", 50000)  # 50KB max por archivo
        self.analysis_delay = self.config.get("ai_analysis.delay", 2)  # 2 segundos entre requests
        
    def analyze_group(self, project_path: str, group_name: str) -> Dict[str, Any]:
        """
        Analizar un grupo funcional especÃ­fico con IA.
        
        Args:
            project_path: Ruta al proyecto
            group_name: Nombre del grupo a analizar
            
        Returns:
            Diccionario con los resultados del anÃ¡lisis
        """
        try:
            # Verificar acceso premium - si no estÃ¡ disponible, usar anÃ¡lisis bÃ¡sico
            has_premium_access = self.ai_client.verify_premium_access()
            if not has_premium_access:
                logger.info(f"Acceso premium no disponible, usando anÃ¡lisis bÃ¡sico para grupo '{group_name}'")
                return self._analyze_group_fallback(project_path, group_name)
            
            # Obtener grupos funcionales del proyecto
            groups = self._get_functional_groups(project_path)
            
            if not groups:
                return {
                    "success": False,
                    "error": "No se encontraron grupos funcionales en el proyecto",
                    "group_name": group_name
                }
            
            # Buscar el grupo especÃ­fico
            target_group = None
            for group in groups:
                if group.get('name', '').lower() == group_name.lower():
                    target_group = group
                    break
                # TambiÃ©n buscar por coincidencia parcial
                if group_name.lower() in group.get('name', '').lower():
                    target_group = group
                    break
            
            if not target_group:
                available_groups = [g.get('name', 'Sin nombre') for g in groups]
                return {
                    "success": False,
                    "error": f"Grupo '{group_name}' no encontrado. Grupos disponibles: {', '.join(available_groups)}",
                    "group_name": group_name,
                    "available_groups": available_groups
                }
            
            # Mostrar informaciÃ³n del grupo
            self.cli.print_info(f"\nðŸ¤– Analizando grupo: {target_group['name']}")
            self.cli.print_info(f"ðŸ“ Archivos en el grupo: {target_group['size']}")
            
            # Analizar archivos del grupo
            analysis_results = self._analyze_group_files(project_path, target_group)
            
            # Generar reporte de anÃ¡lisis
            report_path = self._generate_analysis_report(project_path, target_group, analysis_results)
            
            return {
                "success": True,
                "group_name": target_group['name'],
                "files_analyzed": len(analysis_results),
                "report_path": report_path,
                "analysis_results": analysis_results
            }
            
        except Exception as e:
            logger.error(f"Error al analizar grupo '{group_name}': {e}")
            return {
                "success": False,
                "error": f"Error durante el anÃ¡lisis: {str(e)}",
                "group_name": group_name
            }
    
    def _get_functional_groups(self, project_path: str) -> List[Dict[str, Any]]:
        """
        Obtener grupos funcionales del proyecto.
        
        Args:
            project_path: Ruta al proyecto
            
        Returns:
            Lista de grupos funcionales
        """
        try:
            # Intentar usar anÃ¡lisis de dependencias primero
            from src.analyzers.dependency_graph import get_dependency_graph
            dep_analyzer = get_dependency_graph()
            dep_result = dep_analyzer.build_dependency_graph(project_path)
            
            # Usar los grupos del dependency analyzer si estÃ¡n disponibles
            if dep_result.get('functionality_groups') and len(dep_result['functionality_groups']) > 0:
                return dep_result['functionality_groups']
            
            # Fallback: crear grupos basados en estructura de directorios del proyecto
            return self._create_directory_based_groups(project_path)
            
        except Exception as e:
            logger.error(f"Error al obtener grupos funcionales: {e}")
            return []
    
    def _create_directory_based_groups(self, project_path: str) -> List[Dict[str, Any]]:
        """
        Crear grupos funcionales basados en la estructura de directorios del proyecto.
        
        Args:
            project_path: Ruta al proyecto
            
        Returns:
            Lista de grupos funcionales basados en directorios
        """
        import os
        from pathlib import Path
        
        groups = []
        project_root = Path(project_path).resolve()
        
        # Definir directorios importantes y sus descripciones
        important_dirs = {
            'src/analyzers': 'ðŸ” Analizadores',
            'src/commands': 'âš¡ Comandos CLI',
            'src/core': 'ðŸŽ¯ NÃºcleo del Sistema',
            'src/generators': 'ðŸ—ï¸ Generadores',
            'src/integrations': 'ðŸ”— Integraciones',
            'src/ui': 'ðŸŽ¨ Interfaz de Usuario',
            'src/utils': 'ðŸ› ï¸ Utilidades',
            'tests': 'ðŸ§ª Tests',
            'docs': 'ðŸ“š DocumentaciÃ³n',
            'vscode-extension': 'ðŸ”Œ ExtensiÃ³n VSCode'
        }
        
        for dir_path, display_name in important_dirs.items():
            full_dir_path = project_root / dir_path
            if full_dir_path.exists() and full_dir_path.is_dir():
                # Recopilar archivos de cÃ³digo en el directorio
                files = []
                for ext in ['.py', '.js', '.ts', '.md', '.json']:
                    pattern = f"**/*{ext}"
                    for file_path in full_dir_path.glob(pattern):
                        if file_path.is_file() and not any(ignore in str(file_path) for ignore in ['__pycache__', '.pyc', 'node_modules']):
                            rel_path = file_path.relative_to(project_root)
                            files.append({'path': str(rel_path)})
                
                if files:  # Solo incluir directorios con archivos
                    groups.append({
                        'name': display_name,
                        'type': 'directory',
                        'size': len(files),
                        'files': files,
                        'total_importance': len(files) * 3,
                        'directory_path': dir_path
                    })
        
        # Si no se encontraron grupos, crear uno genÃ©rico con archivos principales
        if not groups:
            main_files = []
            for ext in ['.py', '.js', '.ts']:
                pattern = f"src/**/*{ext}"
                for file_path in project_root.glob(pattern):
                    if file_path.is_file() and not any(ignore in str(file_path) for ignore in ['__pycache__', '.pyc']):
                        rel_path = file_path.relative_to(project_root)
                        main_files.append({'path': str(rel_path)})
            
            if main_files:
                groups.append({
                    'name': 'ðŸ“ CÃ³digo Fuente',
                    'type': 'directory',
                    'size': len(main_files),
                    'files': main_files,
                    'total_importance': len(main_files) * 2,
                    'directory_path': 'src'
                })
        
        return groups
    
    def _analyze_group_files(self, project_path: str, group: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        Analizar todos los archivos de un grupo.
        
        Args:
            project_path: Ruta al proyecto
            group: Grupo a analizar
            
        Returns:
            Lista con anÃ¡lisis de cada archivo
        """
        from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TaskProgressColumn, TimeElapsedColumn
        
        files = group.get('files', [])
        analysis_results = []
        
        # Filtrar archivos vÃ¡lidos para anÃ¡lisis
        valid_files = self._filter_analyzable_files(project_path, files)
        
        if not valid_files:
            logger.warning("No hay archivos vÃ¡lidos para analizar en el grupo")
            return []
        
        total_files = len(valid_files)
        
        # Crear progreso con Rich
        from rich.console import Console
        console = Console()
        
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            BarColumn(),
            TaskProgressColumn(),
            TimeElapsedColumn(),
            console=console
        ) as progress:
            
            # Task para progreso general
            main_task = progress.add_task(f"ðŸ“Š Analizando {total_files} archivos", total=total_files)
            
            # Task para lotes
            total_batches = (len(valid_files) + self.batch_size - 1) // self.batch_size
            batch_task = progress.add_task("ðŸ”„ Procesando lotes", total=total_batches)
            
            # Procesar archivos en lotes
            for i in range(0, len(valid_files), self.batch_size):
                batch = valid_files[i:i + self.batch_size]
                batch_num = (i // self.batch_size) + 1
                
                progress.update(batch_task, description=f"ðŸ”„ Lote {batch_num}/{total_batches} ({len(batch)} archivos)")
                
                # Analizar archivos del lote
                for file_info in batch:
                    try:
                        # Actualizar descripciÃ³n con archivo actual
                        file_path = file_info.get('path', 'unknown')
                        progress.update(main_task, description=f"ðŸ“„ Analizando: {os.path.basename(file_path)}")
                        
                        file_analysis = self._analyze_single_file(project_path, file_info)
                        if file_analysis:
                            analysis_results.append(file_analysis)
                        
                        # Actualizar progreso
                        progress.update(main_task, advance=1)
                        
                    except Exception as e:
                        logger.error(f"Error al analizar archivo {file_info.get('path', '')}: {e}")
                        progress.update(main_task, advance=1)
                        continue
                
                # Actualizar progreso de lotes
                progress.update(batch_task, advance=1)
                
                # Delay entre lotes para evitar rate limiting
                if i + self.batch_size < len(valid_files):
                    delay_task = progress.add_task(f"â³ Esperando {self.analysis_delay}s", total=self.analysis_delay)
                    for _ in range(self.analysis_delay):
                        time.sleep(1)
                        progress.update(delay_task, advance=1)
                    progress.remove_task(delay_task)
        
        self.cli.print_success(f"âœ… AnÃ¡lisis completado: {len(analysis_results)} archivos procesados")
        return analysis_results
    
    def _filter_analyzable_files(self, project_path: str, files: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        Filtrar archivos que pueden ser analizados.
        
        Args:
            project_path: Ruta al proyecto
            files: Lista de archivos
            
        Returns:
            Lista de archivos vÃ¡lidos para anÃ¡lisis
        """
        valid_files = []
        
        for file_info in files:
            file_path = file_info.get('path', '')
            
            if not file_path:
                continue
            
            full_path = os.path.join(project_path, file_path)
            
            # Verificar que el archivo existe
            if not os.path.exists(full_path):
                continue
            
            # Verificar que no es un directorio
            if os.path.isdir(full_path):
                continue
            
            # Verificar tamaÃ±o del archivo
            try:
                file_size = os.path.getsize(full_path)
                if file_size > self.max_file_size:
                    logger.debug(f"Archivo {file_path} muy grande ({file_size} bytes), omitiendo")
                    continue
                
                if file_size == 0:
                    logger.debug(f"Archivo {file_path} vacÃ­o, omitiendo")
                    continue
            except OSError:
                continue
            
            # Verificar que es un archivo de texto
            if self._is_text_file(full_path):
                valid_files.append(file_info)
        
        return valid_files
    
    def _is_text_file(self, file_path: str) -> bool:
        """
        Verificar si un archivo es de texto y puede ser analizado.
        
        Args:
            file_path: Ruta al archivo
            
        Returns:
            True si es un archivo de texto vÃ¡lido
        """
        # Extensiones de archivos de cÃ³digo comunes
        text_extensions = {
            '.py', '.js', '.ts', '.jsx', '.tsx', '.java', '.cpp', '.c', '.h', '.hpp',
            '.cs', '.php', '.rb', '.go', '.rs', '.swift', '.kt', '.scala', '.clj',
            '.html', '.css', '.scss', '.sass', '.less', '.xml', '.json', '.yaml',
            '.yml', '.toml', '.ini', '.cfg', '.conf', '.md', '.txt', '.sql',
            '.sh', '.bash', '.zsh', '.fish', '.ps1', '.bat', '.cmd'
        }
        
        file_ext = os.path.splitext(file_path)[1].lower()
        
        if file_ext in text_extensions:
            return True
        
        # Verificar si es archivo de texto por contenido (primera muestra)
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                sample = f.read(1024)  # Leer primeros 1KB
                # Si contiene principalmente caracteres imprimibles, considerarlo texto
                printable_chars = sum(1 for c in sample if c.isprintable() or c.isspace())
                return (printable_chars / len(sample)) > 0.7 if sample else False
        except:
            return False
    
    def _analyze_single_file(self, project_path: str, file_info: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        Analizar un archivo individual con IA.
        
        Args:
            project_path: Ruta al proyecto
            file_info: InformaciÃ³n del archivo
            
        Returns:
            AnÃ¡lisis del archivo o None si falla
        """
        file_path = file_info.get('path', '')
        full_path = os.path.join(project_path, file_path)
        
        try:
            # Leer contenido del archivo
            with open(full_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
            
            if not content.strip():
                return None
            
            # Determinar lenguaje del archivo
            language = self._detect_file_language(file_path)
            
            # Crear prompt para anÃ¡lisis
            analysis_prompt = self._create_analysis_prompt(file_path, content, language)
            
            # Debug: log para verificar que se estÃ¡ llamando a la API
            logger.info(f"Analizando archivo {file_path} con IA (tamaÃ±o: {len(content)} chars)")
            
            # Solicitar anÃ¡lisis a Claude usando el mÃ©todo explain_code con prompt personalizado
            # Combine the analysis prompt with the code content for a comprehensive analysis
            combined_prompt = f"""Analiza este archivo {language} que forma parte de un grupo funcional:

Archivo: {file_path}

Por favor proporciona un anÃ¡lisis estructurado que incluya:

1. **Funcionalidad Principal**: Â¿QuÃ© hace este archivo?
2. **Responsabilidades**: Principales responsabilidades y propÃ³sito  
3. **Dependencias**: QuÃ© librerÃ­as, mÃ³dulos o archivos importa/usa
4. **Calidad del CÃ³digo**: EvaluaciÃ³n de la calidad (1-10) con justificaciÃ³n
5. **Complejidad**: Nivel de complejidad (Baja/Media/Alta) y por quÃ©
6. **Mantenibilidad**: QuÃ© tan fÃ¡cil es mantener este cÃ³digo
7. **Posibles Mejoras**: Sugerencias especÃ­ficas para mejorar

MantÃ©n el anÃ¡lisis conciso pero informativo.

CÃ“DIGO A ANALIZAR:
{content}"""
            
            result = self.ai_client.explain_code(combined_prompt, language, "standard", {
                "purpose": "file_analysis",
                "file_path": file_path
            })
            
            # Debug: log de la respuesta
            logger.info(f"Respuesta IA para {file_path}: success={result.get('success', False)}")
            
            if not result.get('success', False):
                logger.error(f"Error en anÃ¡lisis IA para {file_path}: {result.get('error', 'Unknown error')}")
                return None
            
            # Procesar y estructurar respuesta
            ai_content = result.get('explanation', result.get('content', result.get('message', '')))
            logger.info(f"Contenido AI recibido para {file_path}: {len(ai_content)} chars")
            
            analysis_data = self._parse_ai_analysis(file_path, ai_content, content)
            
            return analysis_data
            
        except Exception as e:
            logger.error(f"Error al analizar archivo {file_path}: {e}")
            return None
    
    def _detect_file_language(self, file_path: str) -> str:
        """
        Detectar el lenguaje de programaciÃ³n de un archivo.
        
        Args:
            file_path: Ruta al archivo
            
        Returns:
            Lenguaje detectado
        """
        ext = os.path.splitext(file_path)[1].lower()
        
        language_map = {
            '.py': 'python',
            '.js': 'javascript', 
            '.ts': 'typescript',
            '.jsx': 'javascript',
            '.tsx': 'typescript',
            '.java': 'java',
            '.cpp': 'cpp',
            '.c': 'c',
            '.h': 'c',
            '.hpp': 'cpp',
            '.cs': 'csharp',
            '.php': 'php',
            '.rb': 'ruby',
            '.go': 'go',
            '.rs': 'rust',
            '.swift': 'swift',
            '.kt': 'kotlin',
            '.scala': 'scala',
            '.html': 'html',
            '.css': 'css',
            '.scss': 'scss',
            '.json': 'json',
            '.yaml': 'yaml',
            '.yml': 'yaml',
            '.xml': 'xml',
            '.sql': 'sql',
            '.sh': 'bash',
            '.bash': 'bash',
            '.md': 'markdown'
        }
        
        return language_map.get(ext, 'text')
    
    def _create_analysis_prompt(self, file_path: str, content: str, language: str) -> str:
        """
        Crear prompt especÃ­fico para anÃ¡lisis de grupo funcional.
        
        Args:
            file_path: Ruta al archivo
            content: Contenido del archivo
            language: Lenguaje del archivo
            
        Returns:
            Prompt optimizado para el anÃ¡lisis
        """
        return f"""Analiza este archivo {language} que forma parte de un grupo funcional:

Archivo: {file_path}

Por favor proporciona un anÃ¡lisis estructurado que incluya EXACTAMENTE estos campos:

1. **Funcionalidad EspecÃ­fica**: Describe en UNA lÃ­nea concisa quÃ© hace especÃ­ficamente este archivo (mÃ¡ximo 60 caracteres)
2. **Dependencias Internas**: Lista SOLO los archivos internos del proyecto que este archivo importa o usa (separa con comas)
3. **Dependencias Externas**: Lista SOLO las librerÃ­as externas que importa (separa con comas, mÃ¡ximo 3)
4. **Complejidad**: Clasifica como "Baja", "Media" o "Alta" basÃ¡ndote en:
   - NÃºmero de funciones/clases
   - LÃ³gica de negocio
   - Manejo de errores
   - Interacciones con otros sistemas
5. **Responsabilidades Principales**: Enumera las 3 responsabilidades principales
6. **Mejoras Recomendadas**: Sugiere mejoras especÃ­ficas para este archivo

Ejemplo de formato de respuesta:
**Funcionalidad EspecÃ­fica**: Gestiona autenticaciÃ³n de usuarios y tokens JWT
**Dependencias Internas**: auth_utils.py, models/user.py
**Dependencias Externas**: jwt, bcrypt, hashlib
**Complejidad**: Alta
**Responsabilidades Principales**: 
- Validar credenciales de usuario
- Generar y validar tokens JWT
- Gestionar sesiones de usuario
**Mejoras Recomendadas**:
- Separar lÃ³gica de tokens en clase independiente
- Agregar tests unitarios para cada funciÃ³n
- Mejorar manejo de errores especÃ­ficos

MantÃ©n cada secciÃ³n concisa y especÃ­fica."""
    
    def _parse_ai_analysis(self, file_path: str, ai_response: str, original_content: str) -> Dict[str, Any]:
        """
        Parsear y estructurar la respuesta de IA.
        
        Args:
            file_path: Ruta al archivo
            ai_response: Respuesta de Claude
            original_content: Contenido original del archivo
            
        Returns:
            AnÃ¡lisis estructurado
        """
        # Calcular mÃ©tricas bÃ¡sicas del archivo
        lines_count = len(original_content.splitlines())
        char_count = len(original_content)
        
        # Extraer informaciÃ³n especÃ­fica usando el nuevo formato
        functionality = self._extract_section(ai_response, "Funcionalidad EspecÃ­fica")
        internal_deps = self._extract_section(ai_response, "Dependencias Internas")
        external_deps = self._extract_section(ai_response, "Dependencias Externas")
        complexity = self._extract_section(ai_response, "Complejidad")
        responsibilities = self._extract_section(ai_response, "Responsabilidades Principales")
        improvements = self._extract_section(ai_response, "Mejoras Recomendadas")
        
        # Procesar dependencias
        internal_dependencies = self._parse_dependencies_list(internal_deps)
        external_dependencies = self._parse_dependencies_list(external_deps)
        
        return {
            'file_path': file_path,
            'file_name': os.path.basename(file_path),
            'analysis': {
                'functionality': functionality,
                'internal_dependencies': internal_dependencies,
                'external_dependencies': external_dependencies,
                'complexity': complexity,
                'responsibilities': responsibilities,
                'improvements': improvements
            },
            'metrics': {
                'lines_of_code': lines_count,
                'character_count': char_count,
                'file_size_kb': round(char_count / 1024, 2)
            },
            'analysis_timestamp': datetime.now().isoformat(),
            'full_ai_response': ai_response
        }
    
    def _parse_dependencies_list(self, deps_text: str) -> List[str]:
        """
        Parsear lista de dependencias desde texto.
        
        Args:
            deps_text: Texto con dependencias separadas por comas
            
        Returns:
            Lista de dependencias limpias
        """
        if not deps_text or deps_text.strip() == "-" or "no" in deps_text.lower():
            return []
        
        # Limpiar y separar dependencias
        deps = [dep.strip() for dep in deps_text.split(',')]
        return [dep for dep in deps if dep and len(dep) > 1]
    
    def _extract_section(self, text: str, *section_names: str) -> str:
        """
        Extraer una secciÃ³n especÃ­fica del anÃ¡lisis de IA.
        
        Args:
            text: Texto completo
            section_names: Nombres posibles de la secciÃ³n
            
        Returns:
            Contenido de la secciÃ³n
        """
        import re
        
        for section_name in section_names:
            # Buscar patrones como "**SecciÃ³n:**" o "1. **SecciÃ³n**:"
            patterns = [
                rf'\*\*{re.escape(section_name)}[^*]*\*\*[:\s]*([^*\n]*(?:\n(?!\d+\.|[*#]).*)*)',
                rf'\d+\.\s*\*\*{re.escape(section_name)}[^*]*\*\*[:\s]*([^*\n]*(?:\n(?!\d+\.|[*#]).*)*)',
                rf'{re.escape(section_name)}[:\s]*([^\n]*(?:\n(?!\d+\.|[*#]).*)*)'
            ]
            
            for pattern in patterns:
                match = re.search(pattern, text, re.IGNORECASE | re.MULTILINE)
                if match:
                    content = match.group(1).strip()
                    if content:
                        return content
        
        return "No especificado"
    
    def _extract_quality_score(self, quality_text: str) -> Optional[int]:
        """
        Extraer puntuaciÃ³n numÃ©rica de calidad del texto.
        
        Args:
            quality_text: Texto con informaciÃ³n de calidad
            
        Returns:
            PuntuaciÃ³n de 1-10 o None
        """
        import re
        
        # Buscar patrones como "8/10", "7 de 10", "puntuaciÃ³n: 6"
        patterns = [
            r'(\d+)/10',
            r'(\d+)\s*de\s*10',
            r'puntuaciÃ³n[:\s]*(\d+)',
            r'score[:\s]*(\d+)',
            r'rating[:\s]*(\d+)',
            r'calidad[:\s]*(\d+)'
        ]
        
        for pattern in patterns:
            match = re.search(pattern, quality_text, re.IGNORECASE)
            if match:
                score = int(match.group(1))
                if 1 <= score <= 10:
                    return score
        
        return None
    
    def _generate_analysis_report(self, project_path: str, group: Dict[str, Any], analysis_results: List[Dict[str, Any]]) -> str:
        """
        Generar reporte markdown del anÃ¡lisis del grupo.
        
        Args:
            project_path: Ruta al proyecto
            group: InformaciÃ³n del grupo
            analysis_results: Resultados del anÃ¡lisis
            
        Returns:
            Ruta al archivo de reporte generado
        """
        # Crear directorio de salida
        output_dir = os.path.join(project_path, "project-output", "analyses", "functionality_groups")
        os.makedirs(output_dir, exist_ok=True)
        
        # Crear nombre de archivo seguro (sin timestamp para seguir el formato exacto requerido)
        safe_group_name = "".join(c for c in group['name'] if c.isalnum() or c in (' ', '-', '_')).strip()
        safe_group_name = safe_group_name.replace(' ', '_')
        
        report_filename = f"{safe_group_name}.md"
        report_path = os.path.join(output_dir, report_filename)
        
        # Generar contenido del reporte con formato especÃ­fico requerido
        content = self._create_structured_report_content(group, analysis_results, project_path)
        
        # Escribir reporte
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        self.cli.print_success(f"ðŸ“„ Reporte generado: {report_path}")
        return report_path
    
    def _create_report_content(self, group: Dict[str, Any], analysis_results: List[Dict[str, Any]], project_path: str) -> str:
        """
        Crear el contenido markdown del reporte.
        
        Args:
            group: InformaciÃ³n del grupo
            analysis_results: Resultados del anÃ¡lisis
            project_path: Ruta al proyecto
            
        Returns:
            Contenido markdown del reporte
        """
        project_name = os.path.basename(project_path)
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        content = [
            f"# ðŸ¤– AnÃ¡lisis IA de Grupo Funcional: {group['name']}",
            "",
            f"**Proyecto:** {project_name}  ",
            f"**Fecha de AnÃ¡lisis:** {timestamp}  ",
            f"**Tipo de Grupo:** {group.get('type', 'Unknown')}  ",
            f"**Archivos Analizados:** {len(analysis_results)}  ",
            "",
            "---",
            "",
            "## ðŸ“Š Resumen del Grupo",
            "",
            f"- **Nombre del Grupo:** {group['name']}",
            f"- **Tipo:** {group.get('type', 'Unknown')}",
            f"- **Total de Archivos:** {group.get('size', 0)}",
            f"- **Archivos Procesados:** {len(analysis_results)}",
            f"- **Importancia Total:** {group.get('total_importance', 0):.1f}",
            "",
        ]
        
        # Agregar tabla resumen simplificada
        if analysis_results:
            content.extend([
                "## ðŸ“‹ Resumen de AnÃ¡lisis",
                "",
                "| Archivo | Funcionalidad | Mejoras Sugeridas |",
                "|---------|---------------|-------------------|"
            ])
            
            for result in analysis_results:
                file_name = result['file_name']
                functionality = self._truncate_text(result['analysis']['functionality'], 60)
                improvements = self._truncate_text(result['analysis']['suggested_improvements'], 60)
                
                content.append(
                    f"| `{file_name}` | {functionality} | {improvements} |"
                )
            
            content.extend(["", "---", ""])
        
        # AnÃ¡lisis detallado por archivo - Solo informaciÃ³n Ãºtil
        content.extend([
            "## ðŸ” AnÃ¡lisis Detallado por Archivo",
            ""
        ])
        
        for i, result in enumerate(analysis_results, 1):
            analysis = result['analysis']
            
            content.extend([
                f"### {i}. ðŸ“„ `{result['file_path']}`",
                "",
                f"**ðŸŽ¯ Funcionalidad Principal:**",
                f"{analysis['functionality']}",
                "",
                f"**ðŸ”— Dependencias:**",
                f"{analysis['dependencies']}",
                "",
                f"**ðŸ’¡ Sugerencias de Mejora:**",
                f"{analysis['suggested_improvements']}",
                "",
                "---",
                ""
            ])
        
        # Footer
        content.extend([
            "",
            f"*Reporte generado por Project Prompt - AnÃ¡lisis IA con Anthropic Claude*",
            f"*Timestamp: {timestamp}*"
        ])
        
        return "\n".join(content)
    
    def _create_structured_report_content(self, group: Dict[str, Any], analysis_results: List[Dict[str, Any]], project_path: str) -> str:
        """
        Crear el contenido markdown del reporte con formato estructurado especÃ­fico.
        
        Args:
            group: InformaciÃ³n del grupo
            analysis_results: Resultados del anÃ¡lisis
            project_path: Ruta al proyecto
            
        Returns:
            Contenido markdown del reporte con formato especÃ­fico
        """
        from datetime import datetime
        import os
        
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        content = [
            f"# AnÃ¡lisis del Grupo: {group['name']}",
            f"Fecha: {timestamp}",
            f"Archivos analizados: {len(analysis_results)}",
            "",
            "## Resumen del Grupo",
            "",
            self._generate_group_summary(group, analysis_results),
            "",
            "## AnÃ¡lisis Detallado por Archivo",
            "",
            "| Archivo | Funcionalidad EspecÃ­fica | Dependencias Internas | Dependencias Externas | Complejidad |",
            "|---------|--------------------------|----------------------|----------------------|-------------|"
        ]
        
        # Generar tabla con formato especÃ­fico requerido
        for result in analysis_results:
            file_name = result['file_name']
            functionality = self._extract_specific_functionality(result['analysis'])
            internal_deps = self._extract_internal_dependencies(result['analysis'])
            external_deps = self._extract_external_dependencies(result['analysis'])
            complexity = self._extract_complexity_level(result['analysis'])
            
            content.append(
                f"| {file_name} | {functionality} | {internal_deps} | {external_deps} | {complexity} |"
            )
        
        content.extend([
            "",
            "## Conexiones y Dependencias",
            "",
            self._generate_dependency_diagram(analysis_results),
            "",
            "## Recomendaciones",
            "",
            self._generate_group_recommendations(analysis_results)
        ])
        
        return "\n".join(content)
    
    def _generate_group_summary(self, group: Dict[str, Any], analysis_results: List[Dict[str, Any]]) -> str:
        """Generar resumen general del grupo."""
        functionalities = []
        for result in analysis_results:
            functionality = self._extract_specific_functionality(result['analysis'])
            if functionality and functionality != "Sin especificar":
                functionalities.append(functionality)
        
        if functionalities:
            main_purpose = f"Este grupo se encarga principalmente de: {', '.join(functionalities[:3])}."
        else:
            main_purpose = f"Grupo funcional '{group['name']}' que contiene {len(analysis_results)} archivos."
        
        return main_purpose
    
    def _extract_specific_functionality(self, analysis: Dict[str, Any]) -> str:
        """Extraer funcionalidad especÃ­fica del anÃ¡lisis."""
        if isinstance(analysis, dict):
            functionality = analysis.get('functionality', '')
            if isinstance(functionality, str) and len(functionality) > 50:
                # Truncar funcionalidad si es muy larga
                return functionality[:47] + "..."
            return functionality or "Sin especificar"
        return "Sin especificar"
    
    def _extract_internal_dependencies(self, analysis: Dict[str, Any]) -> str:
        """Extraer dependencias internas del anÃ¡lisis."""
        if isinstance(analysis, dict):
            deps = analysis.get('internal_dependencies', [])
            if isinstance(deps, list) and deps:
                return ", ".join(deps[:3])  # MÃ¡ximo 3 dependencias
            elif isinstance(deps, str):
                return deps
        return "-"
    
    def _extract_external_dependencies(self, analysis: Dict[str, Any]) -> str:
        """Extraer dependencias externas del anÃ¡lisis."""
        if isinstance(analysis, dict):
            deps = analysis.get('external_dependencies', [])
            if isinstance(deps, list) and deps:
                return ", ".join(deps[:3])  # MÃ¡ximo 3 dependencias
            elif isinstance(deps, str):
                return deps
        return "-"
    
    def _extract_complexity_level(self, analysis: Dict[str, Any]) -> str:
        """Extraer nivel de complejidad del anÃ¡lisis."""
        if isinstance(analysis, dict):
            complexity = analysis.get('complexity', '')
            if complexity:
                return complexity
            # Intentar inferir complejidad por palabras clave
            text = str(analysis)
            if 'alta' in text.lower() or 'complex' in text.lower():
                return "Alta"
            elif 'media' in text.lower() or 'medium' in text.lower():
                return "Media"
            elif 'baja' in text.lower() or 'low' in text.lower():
                return "Baja"
        return "Media"
    
    def _generate_dependency_diagram(self, analysis_results: List[Dict[str, Any]]) -> str:
        """Generar diagrama textual de dependencias."""
        lines = []
        for result in analysis_results:
            file_name = result['file_name']
            internal_deps = self._extract_internal_dependencies(result['analysis'])
            if internal_deps and internal_deps != "-":
                lines.append(f"- `{file_name}` â†’ {internal_deps}")
        
        if lines:
            return "\n".join(lines)
        else:
            return "No se detectaron dependencias internas complejas entre los archivos del grupo."
    
    def _generate_group_recommendations(self, analysis_results: List[Dict[str, Any]]) -> str:
        """Generar recomendaciones basadas en el anÃ¡lisis."""
        recommendations = []
        
        # Analizar patrones comunes
        high_complexity_files = []
        files_with_many_deps = []
        
        for result in analysis_results:
            complexity = self._extract_complexity_level(result['analysis'])
            if complexity == "Alta":
                high_complexity_files.append(result['file_name'])
                
            internal_deps = self._extract_internal_dependencies(result['analysis'])
            if internal_deps and len(internal_deps.split(',')) > 2:
                files_with_many_deps.append(result['file_name'])
        
        if high_complexity_files:
            recommendations.append(f"- **RefactorizaciÃ³n de complejidad**: Los archivos {', '.join(high_complexity_files)} presentan alta complejidad y podrÃ­an beneficiarse de modularizaciÃ³n.")
        
        if files_with_many_deps:
            recommendations.append(f"- **ReducciÃ³n de dependencias**: Considerar simplificar las dependencias en {', '.join(files_with_many_deps)} para mejorar la mantenibilidad.")
        
        if len(analysis_results) > 5:
            recommendations.append("- **OrganizaciÃ³n**: El grupo contiene muchos archivos. Considerar subdividir en grupos mÃ¡s pequeÃ±os para mejor organizaciÃ³n.")
        
        recommendations.append("- **DocumentaciÃ³n**: Agregar documentaciÃ³n especÃ­fica sobre las responsabilidades y interfaces de cada archivo.")
        recommendations.append("- **Testing**: Implementar tests unitarios especÃ­ficos para cada funcionalidad identificada.")
        
        return "\n".join(recommendations)
    
    def _create_detailed_report_content(self, group: Dict[str, Any], analysis_results: List[Dict[str, Any]], project_path: str) -> str:
        """
        Crear un reporte detallado con anÃ¡lisis avanzado.
        
        Args:
            group: InformaciÃ³n del grupo
            analysis_results: Resultados del anÃ¡lisis
            project_path: Ruta al proyecto
            
        Returns:
            Contenido del reporte detallado
        """
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        content = []
        
        # Para cada archivo
        for result in analysis_results:
            analysis = result['analysis']
            
            # Extraer dependencias
            deps = self._parse_dependencies_from_analysis(analysis)
            if deps:
                for dep in deps:
                    content.append(f"- {dep}")
            else:
                content.append("- Ninguna dependencia crÃ­tica identificada")
            
            content.extend([
                "",
                f"**Puntos de Mejora:**",
            ])
            
            # Extraer mejoras sugeridas
            improvements = self._parse_improvements_from_analysis(analysis)
            if improvements:
                for improvement in improvements:
                    content.append(f"- {improvement}")
            else:
                content.append("- No se identificaron mejoras especÃ­ficas")
            
            content.extend([
                "",
                f"**Nivel de Complejidad:** {self._assess_complexity(analysis)}",
                f"**Prioridad de Refactoring:** {self._assess_refactoring_priority(analysis)}",
                "",
                "---",
                ""
            ])
        
        # SecciÃ³n de dependencias del grupo
        content.extend([
            "## Dependencias del Grupo",
            "",
            "### Dependencias Internas",
        ])
        
        internal_deps = self._identify_internal_dependencies(analysis_results)
        if internal_deps:
            for dep in internal_deps:
                content.append(f"- {dep}")
        else:
            content.append("- No se identificaron dependencias internas crÃ­ticas")
        
        content.extend([
            "",
            "### Dependencias Externas",
        ])
        
        external_deps = self._identify_external_dependencies(analysis_results)
        if external_deps:
            for dep in external_deps:
                content.append(f"- {dep}")
        else:
            content.append("- No se identificaron dependencias externas crÃ­ticas")
        
        # Recomendaciones finales
        content.extend([
            "",
            "## Recomendaciones Generales",
            "",
            "### Mejoras de Arquitectura",
        ])
        
        arch_recommendations = self._generate_architecture_recommendations(group, analysis_results)
        for rec in arch_recommendations:
            content.append(f"- {rec}")
        
        content.extend([
            "",
            "### Mejoras de CÃ³digo",
        ])
        
        code_recommendations = self._generate_code_recommendations(analysis_results)
        for rec in code_recommendations:
            content.append(f"- {rec}")
        
        content.extend([
            "",
            "### PrÃ³ximos Pasos Sugeridos",
            "",
            "1. **Fase 1:** Implementar mejoras de calidad de cÃ³digo identificadas",
            "2. **Fase 2:** Refactorizar componentes con alta complejidad",
            "3. **Fase 3:** Optimizar dependencias y arquitectura",
            "4. **Fase 4:** Implementar patrones de diseÃ±o recomendados",
            "",
            "---",
            "",
            f"*Reporte generado el {timestamp} por ProjectPrompt AI Analyzer*"
        ])
        
        return "\n".join(content)
    
    def _extract_main_functionality(self, analysis: dict) -> str:
        """Extraer la funcionalidad principal de un anÃ¡lisis."""
        functionality = analysis.get('functionality', '')
        if len(functionality) > 60:
            return functionality[:57] + "..."
        return functionality or "No especificada"
    
    def _extract_dependencies(self, analysis: dict) -> str:
        """Extraer dependencias clave del anÃ¡lisis."""
        # Buscar menciones de imports, requires, etc.
        text = str(analysis.get('technical_details', '')) + str(analysis.get('functionality', ''))
        deps = []
        
        # Patrones comunes de dependencias
        import_patterns = ['import ', 'from ', 'require(', 'include ', '#include']
        for pattern in import_patterns:
            if pattern in text.lower():
                deps.append("MÃºltiples")
                break
        
        if not deps:
            deps.append("MÃ­nimas")
            
        return ", ".join(deps[:3])  # MÃ¡ximo 3 dependencias mostradas
    
    def _extract_quality_score(self, analysis: dict) -> str:
        """Extraer puntuaciÃ³n de calidad del anÃ¡lisis."""
        # Buscar puntuaciones numÃ©ricas en el anÃ¡lisis
        text = str(analysis)
        scores = []
        
        # Buscar patrones de puntuaciÃ³n
        import re
        score_patterns = [
            r'(\d+)/10',
            r'score[:\s]*(\d+)',
            r'quality[:\s]*(\d+)',
            r'rating[:\s]*(\d+)'
        ]
        
        for pattern in score_patterns:
            matches = re.findall(pattern, text.lower())
            if matches:
                scores.extend([int(m) for m in matches if m.isdigit()])
        
        if scores:
            avg_score = sum(scores) / len(scores)
            if avg_score >= 8:
                return f"Alta ({avg_score:.1f}/10)"
            elif avg_score >= 6:
                return f"Media ({avg_score:.1f}/10)"
            else:
                return f"Baja ({avg_score:.1f}/10)"
        
        # AnÃ¡lisis heurÃ­stico basado en palabras clave
        text_lower = text.lower()
        if any(word in text_lower for word in ['excellent', 'good', 'well', 'clean']):
            return "Alta"
        elif any(word in text_lower for word in ['improve', 'refactor', 'fix', 'issue']):
            return "Media"
        else:
            return "Por evaluar"
    
    def _extract_key_recommendations(self, analysis: dict) -> str:
        """Extraer recomendaciones clave del anÃ¡lisis."""
        improvements = analysis.get('suggested_improvements', '')
        if len(improvements) > 50:
            return improvements[:47] + "..."
        return improvements or "Ninguna"
    
    def _parse_dependencies_from_analysis(self, analysis: dict) -> List[str]:
        """Extraer lista de dependencias del anÃ¡lisis."""
        deps = []
        text = str(analysis.get('technical_details', '')) + str(analysis.get('functionality', ''))
        
        # Buscar menciones especÃ­ficas de librerÃ­as/mÃ³dulos
        common_deps = [
            'os', 'sys', 'json', 'datetime', 'pathlib', 'typing',
            'requests', 'numpy', 'pandas', 'flask', 'django',
            'fastapi', 'sqlalchemy', 'pytest', 'logging'
        ]
        
        for dep in common_deps:
            if dep in text.lower():
                deps.append(f"MÃ³dulo {dep}")
        
        # Si no se encontraron dependencias especÃ­ficas, agregar genÃ©ricas
        if not deps:
            if 'import' in text.lower():
                deps.append("Dependencias estÃ¡ndar de Python")
            else:
                deps.append("Sin dependencias externas identificadas")
        
        return deps[:5]  # MÃ¡ximo 5 dependencias
    
    def _parse_improvements_from_analysis(self, analysis: dict) -> List[str]:
        """Extraer lista de mejoras del anÃ¡lisis."""
        improvements_text = analysis.get('suggested_improvements', '')
        if not improvements_text:
            return []
        
        # Dividir por puntos o lÃ­neas
        improvements = []
        
        # Intentar dividir por nÃºmeros o bullets
        import re
        lines = re.split(r'[.\n]|\d+\.', improvements_text)
        
        for line in lines:
            line = line.strip()
            if len(line) > 10:  # Filtrar lÃ­neas muy cortas
                improvements.append(line[:80] + ("..." if len(line) > 80 else ""))
        
        return improvements[:4]  # MÃ¡ximo 4 mejoras
    
    def _assess_complexity(self, analysis: dict) -> str:
        """Evaluar el nivel de complejidad basado en el anÃ¡lisis."""
        text = str(analysis).lower()
        
        # Indicadores de alta complejidad
        high_complexity_indicators = [
            'complex', 'complicated', 'intricate', 'nested',
            'multiple inheritance', 'deep hierarchy', 'coupling'
        ]
        
        # Indicadores de baja complejidad
        low_complexity_indicators = [
            'simple', 'straightforward', 'basic', 'minimal',
            'clean', 'clear', 'direct'
        ]
        
        high_score = sum(1 for indicator in high_complexity_indicators if indicator in text)
        low_score = sum(1 for indicator in low_complexity_indicators if indicator in text)
        
        if high_score > low_score:
            return "Alta"
        elif low_score > high_score:
            return "Baja"
        else:
            return "Media"
    
    def _assess_refactoring_priority(self, analysis: dict) -> str:
        """Evaluar la prioridad de refactoring."""
        improvements = analysis.get('suggested_improvements', '').lower()
        
        # Indicadores de alta prioridad
        high_priority_words = [
            'critical', 'urgent', 'important', 'must', 'should',
            'refactor', 'rewrite', 'fix', 'issue', 'problem'
        ]
        
        priority_score = sum(1 for word in high_priority_words if word in improvements)
        
        if priority_score >= 3:
            return "Alta"
        elif priority_score >= 1:
            return "Media"
        else:
            return "Baja"
    
    def _identify_internal_dependencies(self, analysis_results: List[Dict[str, Any]]) -> List[str]:
        """Identificar dependencias internas entre archivos del grupo."""
        deps = []
        file_names = [result['file_name'] for result in analysis_results]
        
        for result in analysis_results:
            text = str(result['analysis'])
            for other_file in file_names:
                if other_file != result['file_name'] and other_file.replace('.py', '') in text:
                    deps.append(f"{result['file_name']} â†’ {other_file}")
        
        return list(set(deps))[:8]  # Eliminar duplicados y limitar
    
    def _identify_external_dependencies(self, analysis_results: List[Dict[str, Any]]) -> List[str]:
        """Identificar dependencias externas del grupo."""
        deps = set()
        
        for result in analysis_results:
            text = str(result['analysis']).lower()
            
            # LibrerÃ­as comunes
            external_libs = [
                'requests', 'numpy', 'pandas', 'flask', 'django',
                'fastapi', 'sqlalchemy', 'pytest', 'click', 'typer',
                'rich', 'anthropic', 'openai'
            ]
            
            for lib in external_libs:
                if lib in text:
                    deps.add(f"LibrerÃ­a {lib}")
        
        return list(deps)[:10]
    
    def _generate_architecture_recommendations(self, group: Dict[str, Any], analysis_results: List[Dict[str, Any]]) -> List[str]:
        """Generar recomendaciones de arquitectura."""
        recommendations = []
        
        # Basado en el nÃºmero de archivos
        if len(analysis_results) > 10:
            recommendations.append("Considerar dividir el grupo en subgrupos mÃ¡s pequeÃ±os")
        
        # Basado en dependencias
        internal_deps = self._identify_internal_dependencies(analysis_results)
        if len(internal_deps) > 5:
            recommendations.append("Reducir el acoplamiento entre mÃ³dulos")
        
        # Recomendaciones generales
        recommendations.extend([
            "Implementar patrones de diseÃ±o apropiados para el dominio",
            "Evaluar la separaciÃ³n de responsabilidades",
            "Considerar la aplicaciÃ³n de principios SOLID"
        ])
        
        return recommendations[:5]
    
    def _generate_code_recommendations(self, analysis_results: List[Dict[str, Any]]) -> List[str]:
        """Generar recomendaciones de cÃ³digo."""
        recommendations = []
        
        # Analizar patrones comunes en las mejoras sugeridas
        all_improvements = []
        for result in analysis_results:
            improvements = result['analysis'].get('suggested_improvements', '')
            all_improvements.append(improvements.lower())
        
        combined_text = ' '.join(all_improvements)
        
        # Recomendaciones basadas en patrones
        if 'documentation' in combined_text or 'comment' in combined_text:
            recommendations.append("Mejorar documentaciÃ³n y comentarios")
        
        if 'test' in combined_text:
            recommendations.append("Incrementar cobertura de pruebas")
        
        if 'error' in combined_text or 'exception' in combined_text:
            recommendations.append("Mejorar manejo de errores")
        
        if 'performance' in combined_text or 'optimization' in combined_text:
            recommendations.append("Optimizar rendimiento")
        
        # Recomendaciones generales
        recommendations.extend([
            "Aplicar estÃ¡ndares de codificaciÃ³n consistentes",
            "Implementar logging adecuado",
            "Validar entradas y salidas"
        ])
        
        return recommendations[:6]

    def _analyze_group_fallback(self, project_path: str, group_name: str) -> Dict[str, Any]:
        """
        AnÃ¡lisis bÃ¡sico sin IA cuando no hay acceso premium.
        
        Args:
            project_path: Ruta al proyecto
            group_name: Nombre del grupo a analizar
            
        Returns:
            AnÃ¡lisis bÃ¡sico del grupo
        """
        try:
            # Obtener grupos funcionales usando mÃ©todo bÃ¡sico
            groups = self._get_functional_groups_basic(project_path)
            
            if not groups:
                return {
                    "success": False,
                    "error": "No se encontraron grupos funcionales en el proyecto",
                    "group_name": group_name
                }
            
            # Buscar el grupo especÃ­fico
            target_group = None
            for group in groups:
                if group.get('name', '').lower() == group_name.lower():
                    target_group = group
                    break
                # TambiÃ©n buscar por coincidencia parcial
                if group_name.lower() in group.get('name', '').lower():
                    target_group = group
                    break
            
            if not target_group:
                available_groups = [g.get('name', 'Sin nombre') for g in groups]
                return {
                    "success": False,
                    "error": f"Grupo '{group_name}' no encontrado. Grupos disponibles: {', '.join(available_groups)}",
                    "group_name": group_name,
                    "available_groups": available_groups
                }
            
            # Mostrar informaciÃ³n del grupo
            self.cli.print_info(f"\nðŸ“Š Analizando grupo (modo bÃ¡sico): {target_group['name']}")
            self.cli.print_info(f"ðŸ“ Archivos en el grupo: {target_group['size']}")
            
            # AnÃ¡lisis bÃ¡sico de archivos del grupo
            analysis_results = self._analyze_group_files_basic(project_path, target_group)
            
            # Generar reporte de anÃ¡lisis bÃ¡sico
            report_path = self._generate_basic_analysis_report(project_path, target_group, analysis_results)
            
            return {
                "success": True,
                "group_name": target_group['name'],
                "files_analyzed": len(analysis_results),
                "report_path": report_path,
                "analysis_results": analysis_results,
                "analysis_type": "basic"
            }
            
        except Exception as e:
            logger.error(f"Error en anÃ¡lisis bÃ¡sico del grupo '{group_name}': {e}")
            return {
                "success": False,
                "error": f"Error en anÃ¡lisis bÃ¡sico: {str(e)}",
                "group_name": group_name
            }

    def _get_functional_groups_basic(self, project_path: str) -> List[Dict[str, Any]]:
        """
        Obtener grupos funcionales usando anÃ¡lisis bÃ¡sico de directorios.
        
        Args:
            project_path: Ruta al proyecto
            
        Returns:
            Lista de grupos funcionales bÃ¡sicos
        """
        return self._create_directory_based_groups(project_path)

    def _analyze_group_files_basic(self, project_path: str, group: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        AnÃ¡lisis bÃ¡sico de archivos sin IA.
        
        Args:
            project_path: Ruta al proyecto
            group: Grupo a analizar
            
        Returns:
            Lista con anÃ¡lisis bÃ¡sico de cada archivo
        """
        from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TaskProgressColumn, TimeElapsedColumn
        from rich.console import Console
        
        files = group.get('files', [])
        analysis_results = []
        
        # Filtrar archivos vÃ¡lidos para anÃ¡lisis
        valid_files = self._filter_analyzable_files(project_path, files)
        
        if not valid_files:
            logger.warning("No hay archivos vÃ¡lidos para analizar en el grupo")
            return []
        
        total_files = len(valid_files)
        console = Console()
        
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            BarColumn(),
            TaskProgressColumn(),
            TimeElapsedColumn(),
            console=console
        ) as progress:
            
            main_task = progress.add_task(f"ðŸ“Š AnÃ¡lisis bÃ¡sico de {total_files} archivos", total=total_files)
            
            for file_info in valid_files:
                try:
                    file_path = file_info.get('path', 'unknown')
                    progress.update(main_task, description=f"ðŸ“„ Analizando: {os.path.basename(file_path)}")
                    
                    file_analysis = self._analyze_single_file_basic(project_path, file_info)
                    if file_analysis:
                        analysis_results.append(file_analysis)
                    
                    progress.update(main_task, advance=1)
                    
                except Exception as e:
                    logger.error(f"Error en anÃ¡lisis bÃ¡sico del archivo {file_info.get('path', '')}: {e}")
                    progress.update(main_task, advance=1)
                    continue
        
        self.cli.print_success(f"âœ… AnÃ¡lisis bÃ¡sico completado: {len(analysis_results)} archivos procesados")
        return analysis_results

    def _analyze_single_file_basic(self, project_path: str, file_info: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        AnÃ¡lisis bÃ¡sico de un archivo individual sin IA.
        
        Args:
            project_path: Ruta al proyecto
            file_info: InformaciÃ³n del archivo
            
        Returns:
            AnÃ¡lisis bÃ¡sico del archivo o None si falla
        """
        file_path = file_info.get('path', '')
        full_path = os.path.join(project_path, file_path)
        
        try:
            # Leer contenido del archivo
            with open(full_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
            
            if not content.strip():
                return None
            
            # AnÃ¡lisis bÃ¡sico estÃ¡tico
            lines = content.split('\n')
            lines_count = len(lines)
            char_count = len(content)
            
            # Detectar lenguaje
            language = self._detect_file_language(file_path)
            
            # AnÃ¡lisis bÃ¡sico de funcionalidad
            functionality = self._detect_basic_functionality(file_path, content, language)
            
            # AnÃ¡lisis bÃ¡sico de dependencias
            dependencies = self._detect_basic_dependencies(content, language)
            
            # EvaluaciÃ³n bÃ¡sica de complejidad
            complexity = self._evaluate_basic_complexity(content, lines_count)
            
            # Generar anÃ¡lisis estructurado
            analysis_data = {
                'file_path': file_path,
                'file_name': os.path.basename(file_path),
                'analysis': {
                    'functionality': functionality,
                    'internal_dependencies': dependencies.get('internal', []),
                    'external_dependencies': dependencies.get('external', []),
                    'complexity': complexity,
                    'responsibilities': self._detect_basic_responsibilities(file_path, content, language),
                    'improvements': self._suggest_basic_improvements(content, language)
                },
                'metrics': {
                    'lines_of_code': lines_count,
                    'character_count': char_count,
                    'file_size_kb': round(char_count / 1024, 2)
                },
                'analysis_timestamp': datetime.now().isoformat(),
                'analysis_type': 'basic'
            }
            
            return analysis_data
            
        except Exception as e:
            logger.error(f"Error en anÃ¡lisis bÃ¡sico del archivo {file_path}: {e}")
            return None

    def _detect_basic_functionality(self, file_path: str, content: str, language: str) -> str:
        """Detectar funcionalidad bÃ¡sica del archivo basada en patrones."""
        if 'test' in file_path.lower():
            return "Archivo de pruebas"
        elif 'config' in file_path.lower():
            return "Archivo de configuraciÃ³n"
        elif language == 'python':
            if 'class ' in content:
                return "DefiniciÃ³n de clases Python"
            elif 'def ' in content:
                return "Funciones Python"
            elif 'import ' in content:
                return "MÃ³dulo Python"
        elif language == 'javascript':
            if 'function ' in content or '=>' in content:
                return "Funciones JavaScript"
            elif 'class ' in content:
                return "Clases JavaScript"
        
        return f"Archivo de cÃ³digo {language}"

    def _detect_basic_dependencies(self, content: str, language: str) -> Dict[str, List[str]]:
        """Detectar dependencias bÃ¡sicas del archivo."""
        import re
        
        dependencies = {'internal': [], 'external': []}
        
        if language == 'python':
            # Buscar imports
            import_patterns = [
                r'import\s+([a-zA-Z_][a-zA-Z0-9_]*)',
                r'from\s+([a-zA-Z_][a-zA-Z0-9_]*)\s+import'
            ]
            for pattern in import_patterns:
                matches = re.findall(pattern, content)
                dependencies['external'].extend(matches)
        
        elif language == 'javascript':
            # Buscar requires e imports
            import_patterns = [
                r'require\([\'"]([^\'"]+)[\'"]\)',
                r'import.*from\s+[\'"]([^\'"]+)[\'"]'
            ]
            for pattern in import_patterns:
                matches = re.findall(pattern, content)
                dependencies['external'].extend(matches)
        
        # Limpiar duplicados
        dependencies['external'] = list(set(dependencies['external']))
        
        return dependencies

    def _evaluate_basic_complexity(self, content: str, lines_count: int) -> str:
        """Evaluar complejidad bÃ¡sica del archivo."""
        if lines_count < 50:
            return "Baja"
        elif lines_count < 200:
            return "Media"
        else:
            return "Alta"

    def _detect_basic_responsibilities(self, file_path: str, content: str, language: str) -> str:
        """Detectar responsabilidades bÃ¡sicas del archivo."""
        filename = os.path.basename(file_path).lower()
        
        if 'main' in filename:
            return "Punto de entrada principal del sistema"
        elif 'test' in filename:
            return "Pruebas unitarias y validaciÃ³n de funcionalidad"
        elif 'config' in filename:
            return "GestiÃ³n de configuraciÃ³n del sistema"
        elif 'util' in filename:
            return "Funciones de utilidad y helpers"
        elif language == 'python' and 'class ' in content:
            return "ImplementaciÃ³n de clases y lÃ³gica de negocio"
        
        return "LÃ³gica de aplicaciÃ³n general"

    def _suggest_basic_improvements(self, content: str, language: str) -> str:
        """Sugerir mejoras bÃ¡sicas del archivo."""
        suggestions = []
        
        lines = content.split('\n')
        
        # Verificar documentaciÃ³n
        if language == 'python':
            if '"""' not in content and "'''" not in content:
                suggestions.append("Agregar docstrings para documentar funciones y clases")
        
        # Verificar longitud de lÃ­neas
        long_lines = [i for i, line in enumerate(lines) if len(line) > 100]
        if long_lines:
            suggestions.append("Reducir longitud de lÃ­neas muy largas para mejorar legibilidad")
        
        # Verificar funciones muy largas
        if language == 'python':
            function_lines = [i for i, line in enumerate(lines) if line.strip().startswith('def ')]
            for func_start in function_lines:
                func_end = func_start + 1
                while func_end < len(lines) and (lines[func_end].startswith('    ') or lines[func_end].strip() == ''):
                    func_end += 1
                if func_end - func_start > 30:
                    suggestions.append("Dividir funciones muy largas en funciones mÃ¡s pequeÃ±as")
                    break
        
        if not suggestions:
            suggestions.append("Mantener buenas prÃ¡cticas de codificaciÃ³n")
        
        return '; '.join(suggestions[:3])

    def _generate_basic_analysis_report(self, project_path: str, group: Dict[str, Any], analysis_results: List[Dict[str, Any]]) -> str:
        """
        Generar reporte de anÃ¡lisis bÃ¡sico.
        
        Args:
            project_path: Ruta al proyecto
            group: Grupo analizado
            analysis_results: Resultados del anÃ¡lisis
            
        Returns:
            Ruta al archivo de reporte generado
        """
        # Usar el mismo directorio que el anÃ¡lisis con IA
        project_name = os.path.basename(project_path)
        safe_group_name = "".join(c for c in group['name'] if c.isalnum() or c in (' ', '-', '_')).strip()
        safe_group_name = safe_group_name.replace(' ', '_')
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{safe_group_name}_basic_analysis_{timestamp}.md"
        
        # Crear directorio de salida
        output_dir = os.path.join(project_path, "project-output", "analyses", "functionality_groups")
        os.makedirs(output_dir, exist_ok=True)
        report_path = os.path.join(output_dir, filename)
        
        # Generar contenido del reporte
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(f"# AnÃ¡lisis BÃ¡sico del Grupo Funcional: {group['name']}\n\n")
            f.write(f"**Fecha de anÃ¡lisis:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"**Proyecto:** {project_name}\n")
            f.write(f"**Tipo de anÃ¡lisis:** BÃ¡sico (sin IA)\n")
            f.write(f"**Archivos analizados:** {len(analysis_results)}\n\n")
            
            f.write("## Resumen del Grupo\n\n")
            f.write(f"- **Nombre:** {group['name']}\n")
            f.write(f"- **Tipo:** {group.get('type', 'Desconocido')}\n")
            f.write(f"- **Total de archivos:** {group.get('size', 0)}\n")
            f.write(f"- **Archivos procesados:** {len(analysis_results)}\n\n")
            
            if analysis_results:
                f.write("## AnÃ¡lisis por Archivo\n\n")
                
                for i, result in enumerate(analysis_results, 1):
                    f.write(f"### {i}. {result['file_name']}\n\n")
                    f.write(f"**Ruta:** `{result['file_path']}`\n\n")
                    
                    analysis = result['analysis']
                    metrics = result['metrics']
                    
                    f.write(f"- **Funcionalidad:** {analysis['functionality']}\n")
                    f.write(f"- **Responsabilidades:** {analysis['responsibilities']}\n")
                    f.write(f"- **Complejidad:** {analysis['complexity']}\n")
                    f.write(f"- **LÃ­neas de cÃ³digo:** {metrics['lines_of_code']}\n")
                    f.write(f"- **TamaÃ±o:** {metrics['file_size_kb']} KB\n\n")
                    
                    if analysis['external_dependencies']:
                        f.write(f"**Dependencias externas:** {', '.join(analysis['external_dependencies'][:5])}\n")
                        if len(analysis['external_dependencies']) > 5:
                            f.write(f" (+{len(analysis['external_dependencies']) - 5} mÃ¡s)\n")
                        f.write("\n")
                    
                    f.write(f"**Mejoras sugeridas:** {analysis['improvements']}\n\n")
                    f.write("---\n\n")
                
                # Agregar resumen y recomendaciones
                f.write("## Resumen y Recomendaciones\n\n")
                f.write("### EstadÃ­sticas Generales\n\n")
                
                total_lines = sum(r['metrics']['lines_of_code'] for r in analysis_results)
                total_size = sum(r['metrics']['file_size_kb'] for r in analysis_results)
                
                f.write(f"- **Total de lÃ­neas:** {total_lines:,}\n")
                f.write(f"- **TamaÃ±o total:** {total_size:.2f} KB\n")
                f.write(f"- **Promedio de lÃ­neas por archivo:** {total_lines // len(analysis_results) if analysis_results else 0}\n\n")
                
                # AnÃ¡lisis de complejidad
                complexity_counts = {}
                for result in analysis_results:
                    complexity = result['analysis']['complexity']
                    complexity_counts[complexity] = complexity_counts.get(complexity, 0) + 1
                
                f.write("### DistribuciÃ³n de Complejidad\n\n")
                for complexity, count in complexity_counts.items():
                    f.write(f"- **{complexity}:** {count} archivos\n")
                f.write("\n")
                
                f.write("### Recomendaciones Generales\n\n")
                f.write("- Revisar archivos de alta complejidad para posibles refactorizaciones\n")
                f.write("- Mejorar documentaciÃ³n en archivos con pocas lÃ­neas de comentarios\n")
                f.write("- Considerar dividir archivos muy grandes en mÃ³dulos mÃ¡s pequeÃ±os\n")
                f.write("- Implementar pruebas unitarias si no las hay\n")
                f.write("- Validar y optimizar dependencias externas\n\n")
            else:
                f.write("## Sin Resultados\n\n")
                f.write("No se pudieron procesar archivos en este grupo.\n\n")
            
            f.write("---\n")
            f.write("*Reporte generado por ProjectPrompt (AnÃ¡lisis BÃ¡sico)*\n")
        
        return report_path

def get_ai_group_analyzer(config: Optional[ConfigManager] = None) -> AIGroupAnalyzer:
    """
    Obtener instancia singleton del analizador de grupos con IA.
    
    Args:
        config: ConfiguraciÃ³n opcional
        
    Returns:
        Instancia del analizador
    """
    if not hasattr(get_ai_group_analyzer, '_instance'):
        get_ai_group_analyzer._instance = AIGroupAnalyzer(config)
    return get_ai_group_analyzer._instance
