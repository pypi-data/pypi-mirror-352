#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
Analizador de grupos funcionales con IA (Anthropic Claude).

Este m√≥dulo implementa an√°lisis inteligente de grupos funcionales usando
la API de Anthropic para generar an√°lisis detallados de cada archivo
dentro de los grupos detectados.
"""

import os
import json
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional, Any, Tuple
import time

from src.utils.logger import get_logger
from src.integrations.anthropic_advanced import AdvancedAnthropicClient
from src.analyzers.project_progress_tracker import ProjectProgressTracker
from src.analyzers.dependency_graph import DependencyGraph
from src.utils.config import ConfigManager
from src.ui.cli import CLI
from src.utils.token_counter import AnthropicTokenCounter

# Configurar logger
logger = get_logger()


class AIGroupAnalyzer:
    """Analizador de grupos funcionales con IA."""
    
    def __init__(self, config: Optional[ConfigManager] = None):
        """
        Inicializar el analizador de grupos con IA.
        
        Args:
            config: Configuraci√≥n opcional
        """
        self.config = config or ConfigManager()
        self.ai_client = AdvancedAnthropicClient(config=self.config)
        self.cli = CLI()
        self.token_counter = AnthropicTokenCounter()
        
        # Configuraci√≥n de an√°lisis
        self.batch_size = self.config.get("ai_analysis.batch_size", 5)
        self.max_file_size = self.config.get("ai_analysis.max_file_size", 50000)  # 50KB max por archivo
        self.analysis_delay = self.config.get("ai_analysis.delay", 2)  # 2 segundos entre requests
        
    def analyze_group(self, project_path: str, group_name: str) -> Dict[str, Any]:
        """
        Analizar un grupo funcional espec√≠fico con IA.
        
        Args:
            project_path: Ruta al proyecto
            group_name: Nombre del grupo a analizar
            
        Returns:
            Diccionario con los resultados del an√°lisis
        """
        try:
            # Verificar acceso premium - si no est√° disponible, usar an√°lisis b√°sico
            has_premium_access = self.ai_client.verify_premium_access()
            if not has_premium_access:
                logger.info(f"Acceso premium no disponible, usando an√°lisis b√°sico para grupo '{group_name}'")
                return self._analyze_group_fallback(project_path, group_name)
            
            # Obtener grupos funcionales del proyecto
            groups = self._get_functional_groups(project_path)
            
            if not groups:
                return {
                    "success": False,
                    "error": "No se encontraron grupos funcionales en el proyecto",
                    "group_name": group_name
                }
            
            # Buscar el grupo espec√≠fico
            target_group = None
            for group in groups:
                if group.get('name', '').lower() == group_name.lower():
                    target_group = group
                    break
                # Tambi√©n buscar por coincidencia parcial
                if group_name.lower() in group.get('name', '').lower():
                    target_group = group
                    break
            
            if not target_group:
                available_groups = [g.get('name', 'Sin nombre') for g in groups]
                return {
                    "success": False,
                    "error": f"Grupo '{group_name}' no encontrado. Grupos disponibles: {', '.join(available_groups)}",
                    "group_name": group_name,
                    "available_groups": available_groups
                }
            
            # Mostrar informaci√≥n del grupo
            self.cli.print_info(f"\nü§ñ Analizando grupo: {target_group['name']}")
            self.cli.print_info(f"üìÅ Archivos en el grupo: {target_group['size']}")
            
            # Analizar archivos del grupo
            analysis_results = self._analyze_group_files(project_path, target_group)
            
            # Generar reporte de an√°lisis
            report_path = self._generate_analysis_report(project_path, target_group, analysis_results)
            
            return {
                "success": True,
                "group_name": target_group['name'],
                "files_analyzed": len(analysis_results),
                "report_path": report_path,
                "analysis_results": analysis_results
            }
            
        except Exception as e:
            logger.error(f"Error al analizar grupo '{group_name}': {e}")
            return {
                "success": False,
                "error": f"Error durante el an√°lisis: {str(e)}",
                "group_name": group_name
            }
    
    def _get_functional_groups(self, project_path: str) -> List[Dict[str, Any]]:
        """
        Obtener grupos funcionales del proyecto.
        
        Args:
            project_path: Ruta al proyecto
            
        Returns:
            Lista de grupos funcionales
        """
        try:
            # Intentar usar an√°lisis de dependencias primero
            from src.analyzers.dependency_graph import get_dependency_graph
            dep_analyzer = get_dependency_graph()
            dep_result = dep_analyzer.build_dependency_graph(project_path)
            
            # Usar los grupos del dependency analyzer si est√°n disponibles
            if dep_result.get('functionality_groups') and len(dep_result['functionality_groups']) > 0:
                return dep_result['functionality_groups']
            
            # Fallback: crear grupos basados en estructura de directorios del proyecto
            return self._create_directory_based_groups(project_path)
            
        except Exception as e:
            logger.error(f"Error al obtener grupos funcionales: {e}")
            return []
    
    def _create_directory_based_groups(self, project_path: str) -> List[Dict[str, Any]]:
        """
        Crear grupos funcionales basados en la estructura de directorios del proyecto.
        
        Args:
            project_path: Ruta al proyecto
            
        Returns:
            Lista de grupos funcionales basados en directorios
        """
        import os
        from pathlib import Path
        
        groups = []
        project_root = Path(project_path).resolve()
        
        # Definir directorios importantes y sus descripciones
        important_dirs = {
            'src/analyzers': 'üîç Analizadores',
            'src/commands': '‚ö° Comandos CLI',
            'src/core': 'üéØ N√∫cleo del Sistema',
            'src/generators': 'üèóÔ∏è Generadores',
            'src/integrations': 'üîó Integraciones',
            'src/ui': 'üé® Interfaz de Usuario',
            'src/utils': 'üõ†Ô∏è Utilidades',
            'tests': 'üß™ Tests',
            'docs': 'üìö Documentaci√≥n',
            'vscode-extension': 'üîå Extensi√≥n VSCode'
        }
        
        for dir_path, display_name in important_dirs.items():
            full_dir_path = project_root / dir_path
            if full_dir_path.exists() and full_dir_path.is_dir():
                # Recopilar archivos de c√≥digo en el directorio
                files = []
                for ext in ['.py', '.js', '.ts', '.md', '.json']:
                    pattern = f"**/*{ext}"
                    for file_path in full_dir_path.glob(pattern):
                        if file_path.is_file() and not any(ignore in str(file_path) for ignore in ['__pycache__', '.pyc', 'node_modules']):
                            rel_path = file_path.relative_to(project_root)
                            files.append({'path': str(rel_path)})
                
                if files:  # Solo incluir directorios con archivos
                    groups.append({
                        'name': display_name,
                        'type': 'directory',
                        'size': len(files),
                        'files': files,
                        'total_importance': len(files) * 3,
                        'directory_path': dir_path
                    })
        
        # Si no se encontraron grupos, crear uno gen√©rico con archivos principales
        if not groups:
            main_files = []
            for ext in ['.py', '.js', '.ts']:
                pattern = f"src/**/*{ext}"
                for file_path in project_root.glob(pattern):
                    if file_path.is_file() and not any(ignore in str(file_path) for ignore in ['__pycache__', '.pyc']):
                        rel_path = file_path.relative_to(project_root)
                        main_files.append({'path': str(rel_path)})
            
            if main_files:
                groups.append({
                    'name': 'üìÅ C√≥digo Fuente',
                    'type': 'directory',
                    'size': len(main_files),
                    'files': main_files,
                    'total_importance': len(main_files) * 2,
                    'directory_path': 'src'
                })
        
        return groups
    
    def _analyze_group_files(self, project_path: str, group: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        Analizar todos los archivos de un grupo.
        
        Args:
            project_path: Ruta al proyecto
            group: Grupo a analizar
            
        Returns:
            Lista con an√°lisis de cada archivo
        """
        from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TaskProgressColumn, TimeElapsedColumn
        
        files = group.get('files', [])
        analysis_results = []
        
        # Filtrar archivos v√°lidos para an√°lisis
        valid_files = self._filter_analyzable_files(project_path, files)
        
        if not valid_files:
            logger.warning("No hay archivos v√°lidos para analizar en el grupo")
            return []
        
        total_files = len(valid_files)
        
        # Crear progreso con Rich
        from rich.console import Console
        console = Console()
        
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            BarColumn(),
            TaskProgressColumn(),
            TimeElapsedColumn(),
            console=console
        ) as progress:
            
            # Task para progreso general
            main_task = progress.add_task(f"üìä Analizando {total_files} archivos", total=total_files)
            
            # Task para lotes
            total_batches = (len(valid_files) + self.batch_size - 1) // self.batch_size
            batch_task = progress.add_task("üîÑ Procesando lotes", total=total_batches)
            
            # Procesar archivos en lotes
            for i in range(0, len(valid_files), self.batch_size):
                batch = valid_files[i:i + self.batch_size]
                batch_num = (i // self.batch_size) + 1
                
                progress.update(batch_task, description=f"üîÑ Lote {batch_num}/{total_batches} ({len(batch)} archivos)")
                
                # Analizar archivos del lote
                for file_info in batch:
                    try:
                        # Actualizar descripci√≥n con archivo actual
                        file_path = file_info.get('path', 'unknown')
                        progress.update(main_task, description=f"üìÑ Analizando: {os.path.basename(file_path)}")
                        
                        file_analysis = self._analyze_single_file(project_path, file_info)
                        if file_analysis:
                            analysis_results.append(file_analysis)
                        
                        # Actualizar progreso
                        progress.update(main_task, advance=1)
                        
                    except Exception as e:
                        logger.error(f"Error al analizar archivo {file_info.get('path', '')}: {e}")
                        progress.update(main_task, advance=1)
                        continue
                
                # Actualizar progreso de lotes
                progress.update(batch_task, advance=1)
                
                # Delay entre lotes para evitar rate limiting
                if i + self.batch_size < len(valid_files):
                    delay_task = progress.add_task(f"‚è≥ Esperando {self.analysis_delay}s", total=self.analysis_delay)
                    for _ in range(self.analysis_delay):
                        time.sleep(1)
                        progress.update(delay_task, advance=1)
                    progress.remove_task(delay_task)
        
        self.cli.print_success(f"‚úÖ An√°lisis completado: {len(analysis_results)} archivos procesados")
        return analysis_results
    
    def _filter_analyzable_files(self, project_path: str, files: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        Filtrar archivos que pueden ser analizados.
        
        Args:
            project_path: Ruta al proyecto
            files: Lista de archivos
            
        Returns:
            Lista de archivos v√°lidos para an√°lisis
        """
        valid_files = []
        
        for file_info in files:
            file_path = file_info.get('path', '')
            
            if not file_path:
                continue
            
            full_path = os.path.join(project_path, file_path)
            
            # Verificar que el archivo existe
            if not os.path.exists(full_path):
                continue
            
            # Verificar que no es un directorio
            if os.path.isdir(full_path):
                continue
            
            # Verificar tama√±o del archivo
            try:
                file_size = os.path.getsize(full_path)
                if file_size > self.max_file_size:
                    logger.debug(f"Archivo {file_path} muy grande ({file_size} bytes), omitiendo")
                    continue
                
                if file_size == 0:
                    logger.debug(f"Archivo {file_path} vac√≠o, omitiendo")
                    continue
            except OSError:
                continue
            
            # Verificar que es un archivo de texto
            if self._is_text_file(full_path):
                valid_files.append(file_info)
        
        return valid_files
    
    def _is_text_file(self, file_path: str) -> bool:
        """
        Verificar si un archivo es de texto y puede ser analizado.
        
        Args:
            file_path: Ruta al archivo
            
        Returns:
            True si es un archivo de texto v√°lido
        """
        # Extensiones de archivos de c√≥digo comunes
        text_extensions = {
            '.py', '.js', '.ts', '.jsx', '.tsx', '.java', '.cpp', '.c', '.h', '.hpp',
            '.cs', '.php', '.rb', '.go', '.rs', '.swift', '.kt', '.scala', '.clj',
            '.html', '.css', '.scss', '.sass', '.less', '.xml', '.json', '.yaml',
            '.yml', '.toml', '.ini', '.cfg', '.conf', '.md', '.txt', '.sql',
            '.sh', '.bash', '.zsh', '.fish', '.ps1', '.bat', '.cmd'
        }
        
        file_ext = os.path.splitext(file_path)[1].lower()
        
        if file_ext in text_extensions:
            return True
        
        # Verificar si es archivo de texto por contenido (primera muestra)
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                sample = f.read(1024)  # Leer primeros 1KB
                # Si contiene principalmente caracteres imprimibles, considerarlo texto
                printable_chars = sum(1 for c in sample if c.isprintable() or c.isspace())
                return (printable_chars / len(sample)) > 0.7 if sample else False
        except:
            return False
    
    def _analyze_single_file(self, project_path: str, file_info: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        Analizar un archivo individual con IA.
        
        Args:
            project_path: Ruta al proyecto
            file_info: Informaci√≥n del archivo
            
        Returns:
            An√°lisis del archivo o None si falla
        """
        file_path = file_info.get('path', '')
        full_path = os.path.join(project_path, file_path)
        
        try:
            # Leer contenido del archivo
            with open(full_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
            
            if not content.strip():
                return None
            
            # Determinar lenguaje del archivo
            language = self._detect_file_language(file_path)
            
            # Crear prompt para an√°lisis
            analysis_prompt = self._create_analysis_prompt(file_path, content, language)
            
            # Debug: log para verificar que se est√° llamando a la API
            logger.info(f"Analizando archivo {file_path} con IA (tama√±o: {len(content)} chars)")
            
            # Solicitar an√°lisis a Claude usando el m√©todo explain_code con prompt personalizado
            # Combine the analysis prompt with the code content for a comprehensive analysis
            combined_prompt = f"""Analiza este archivo {language} que forma parte de un grupo funcional:

Archivo: {file_path}

Por favor proporciona un an√°lisis estructurado que incluya:

1. **Funcionalidad Principal**: ¬øQu√© hace este archivo?
2. **Responsabilidades**: Principales responsabilidades y prop√≥sito  
3. **Dependencias**: Qu√© librer√≠as, m√≥dulos o archivos importa/usa
4. **Calidad del C√≥digo**: Evaluaci√≥n de la calidad (1-10) con justificaci√≥n
5. **Complejidad**: Nivel de complejidad (Baja/Media/Alta) y por qu√©
6. **Mantenibilidad**: Qu√© tan f√°cil es mantener este c√≥digo
7. **Posibles Mejoras**: Sugerencias espec√≠ficas para mejorar

Mant√©n el an√°lisis conciso pero informativo.

C√ìDIGO A ANALIZAR:
{content}"""
            
            result = self.ai_client.explain_code(combined_prompt, language, "standard", {
                "purpose": "file_analysis",
                "file_path": file_path
            })
            
            # Debug: log de la respuesta
            logger.info(f"Respuesta IA para {file_path}: success={result.get('success', False)}")
            
            if not result.get('success', False):
                logger.error(f"Error en an√°lisis IA para {file_path}: {result.get('error', 'Unknown error')}")
                return None
            
            # Procesar y estructurar respuesta
            ai_content = result.get('explanation', result.get('content', result.get('message', '')))
            logger.info(f"Contenido AI recibido para {file_path}: {len(ai_content)} chars")
            
            analysis_data = self._parse_ai_analysis(file_path, ai_content, content)
            
            return analysis_data
            
        except Exception as e:
            logger.error(f"Error al analizar archivo {file_path}: {e}")
            return None
    
    def _detect_file_language(self, file_path: str) -> str:
        """
        Detectar el lenguaje de programaci√≥n de un archivo.
        
        Args:
            file_path: Ruta al archivo
            
        Returns:
            Lenguaje detectado
        """
        ext = os.path.splitext(file_path)[1].lower()
        
        language_map = {
            '.py': 'python',
            '.js': 'javascript', 
            '.ts': 'typescript',
            '.jsx': 'javascript',
            '.tsx': 'typescript',
            '.java': 'java',
            '.cpp': 'cpp',
            '.c': 'c',
            '.h': 'c',
            '.hpp': 'cpp',
            '.cs': 'csharp',
            '.php': 'php',
            '.rb': 'ruby',
            '.go': 'go',
            '.rs': 'rust',
            '.swift': 'swift',
            '.kt': 'kotlin',
            '.scala': 'scala',
            '.html': 'html',
            '.css': 'css',
            '.scss': 'scss',
            '.json': 'json',
            '.yaml': 'yaml',
            '.yml': 'yaml',
            '.xml': 'xml',
            '.sql': 'sql',
            '.sh': 'bash',
            '.bash': 'bash',
            '.md': 'markdown'
        }
        
        return language_map.get(ext, 'text')
    
    def _create_analysis_prompt(self, file_path: str, content: str, language: str) -> str:
        """
        Crear prompt espec√≠fico para an√°lisis de grupo funcional.
        
        Args:
            file_path: Ruta al archivo
            content: Contenido del archivo
            language: Lenguaje del archivo
            
        Returns:
            Prompt optimizado para el an√°lisis
        """
        return f"""Analiza este archivo {language} que forma parte de un grupo funcional:

Archivo: {file_path}

Por favor proporciona un an√°lisis estructurado que incluya EXACTAMENTE estos campos:

1. **Funcionalidad Espec√≠fica**: Describe en UNA l√≠nea concisa qu√© hace espec√≠ficamente este archivo (m√°ximo 60 caracteres)
2. **Dependencias Internas**: Lista SOLO los archivos internos del proyecto que este archivo importa o usa (separa con comas)
3. **Dependencias Externas**: Lista SOLO las librer√≠as externas que importa (separa con comas, m√°ximo 3)
4. **Complejidad**: Clasifica como "Baja", "Media" o "Alta" bas√°ndote en:
   - N√∫mero de funciones/clases
   - L√≥gica de negocio
   - Manejo de errores
   - Interacciones con otros sistemas
5. **Responsabilidades Principales**: Enumera las 3 responsabilidades principales
6. **Mejoras Recomendadas**: Sugiere mejoras espec√≠ficas para este archivo

Ejemplo de formato de respuesta:
**Funcionalidad Espec√≠fica**: Gestiona autenticaci√≥n de usuarios y tokens JWT
**Dependencias Internas**: auth_utils.py, models/user.py
**Dependencias Externas**: jwt, bcrypt, hashlib
**Complejidad**: Alta
**Responsabilidades Principales**: 
- Validar credenciales de usuario
- Generar y validar tokens JWT
- Gestionar sesiones de usuario
**Mejoras Recomendadas**:
- Separar l√≥gica de tokens en clase independiente
- Agregar tests unitarios para cada funci√≥n
- Mejorar manejo de errores espec√≠ficos

Mant√©n cada secci√≥n concisa y espec√≠fica."""
    
    def _parse_ai_analysis(self, file_path: str, ai_response: str, original_content: str) -> Dict[str, Any]:
        """
        Parsear y estructurar la respuesta de IA.
        
        Args:
            file_path: Ruta al archivo
            ai_response: Respuesta de Claude
            original_content: Contenido original del archivo
            
        Returns:
            An√°lisis estructurado
        """
        # Calcular m√©tricas b√°sicas del archivo
        lines_count = len(original_content.splitlines())
        char_count = len(original_content)
        
        # Extraer informaci√≥n espec√≠fica usando el nuevo formato
        functionality = self._extract_section(ai_response, "Funcionalidad Espec√≠fica")
        internal_deps = self._extract_section(ai_response, "Dependencias Internas")
        external_deps = self._extract_section(ai_response, "Dependencias Externas")
        complexity = self._extract_section(ai_response, "Complejidad")
        responsibilities = self._extract_section(ai_response, "Responsabilidades Principales")
        improvements = self._extract_section(ai_response, "Mejoras Recomendadas")
        
        # Procesar dependencias
        internal_dependencies = self._parse_dependencies_list(internal_deps)
        external_dependencies = self._parse_dependencies_list(external_deps)
        
        return {
            'file_path': file_path,
            'file_name': os.path.basename(file_path),
            'analysis': {
                'functionality': functionality,
                'internal_dependencies': internal_dependencies,
                'external_dependencies': external_dependencies,
                'complexity': complexity,
                'responsibilities': responsibilities,
                'improvements': improvements
            },
            'metrics': {
                'lines_of_code': lines_count,
                'character_count': char_count,
                'file_size_kb': round(char_count / 1024, 2)
            },
            'analysis_timestamp': datetime.now().isoformat(),
            'full_ai_response': ai_response
        }
    
    def _parse_dependencies_list(self, deps_text: str) -> List[str]:
        """
        Parsear lista de dependencias desde texto.
        
        Args:
            deps_text: Texto con dependencias separadas por comas
            
        Returns:
            Lista de dependencias limpias
        """
        if not deps_text or deps_text.strip() == "-" or "no" in deps_text.lower():
            return []
        
        # Limpiar y separar dependencias
        deps = [dep.strip() for dep in deps_text.split(',')]
        return [dep for dep in deps if dep and len(dep) > 1]
    
    def _extract_section(self, text: str, *section_names: str) -> str:
        """
        Extraer una secci√≥n espec√≠fica del an√°lisis de IA.
        
        Args:
            text: Texto completo
            section_names: Nombres posibles de la secci√≥n
            
        Returns:
            Contenido de la secci√≥n
        """
        import re
        
        for section_name in section_names:
            # Buscar patrones como "**Secci√≥n:**" o "1. **Secci√≥n**:"
            patterns = [
                rf'\*\*{re.escape(section_name)}[^*]*\*\*[:\s]*([^*\n]*(?:\n(?!\d+\.|[*#]).*)*)',
                rf'\d+\.\s*\*\*{re.escape(section_name)}[^*]*\*\*[:\s]*([^*\n]*(?:\n(?!\d+\.|[*#]).*)*)',
                rf'{re.escape(section_name)}[:\s]*([^\n]*(?:\n(?!\d+\.|[*#]).*)*)'
            ]
            
            for pattern in patterns:
                match = re.search(pattern, text, re.IGNORECASE | re.MULTILINE)
                if match:
                    content = match.group(1).strip()
                    if content:
                        return content
        
        return "No especificado"
    
    def _extract_quality_score(self, quality_text: str) -> Optional[int]:
        """
        Extraer puntuaci√≥n num√©rica de calidad del texto.
        
        Args:
            quality_text: Texto con informaci√≥n de calidad
            
        Returns:
            Puntuaci√≥n de 1-10 o None
        """
        import re
        
        # Buscar patrones como "8/10", "7 de 10", "puntuaci√≥n: 6"
        patterns = [
            r'(\d+)/10',
            r'(\d+)\s*de\s*10',
            r'puntuaci√≥n[:\s]*(\d+)',
            r'score[:\s]*(\d+)',
            r'rating[:\s]*(\d+)',
            r'calidad[:\s]*(\d+)'
        ]
        
        for pattern in patterns:
            match = re.search(pattern, quality_text, re.IGNORECASE)
            if match:
                score = int(match.group(1))
                if 1 <= score <= 10:
                    return score
        
        return None
    
    def _generate_analysis_report(self, project_path: str, group: Dict[str, Any], analysis_results: List[Dict[str, Any]]) -> str:
        """
        Generar reporte markdown del an√°lisis del grupo.
        
        Args:
            project_path: Ruta al proyecto
            group: Informaci√≥n del grupo
            analysis_results: Resultados del an√°lisis
            
        Returns:
            Ruta al archivo de reporte generado
        """
        # Crear directorio de salida
        output_dir = os.path.join(project_path, "project-output", "analyses", "functionality_groups")
        os.makedirs(output_dir, exist_ok=True)
        
        # Crear nombre de archivo seguro (sin timestamp para seguir el formato exacto requerido)
        safe_group_name = "".join(c for c in group['name'] if c.isalnum() or c in (' ', '-', '_')).strip()
        safe_group_name = safe_group_name.replace(' ', '_')
        
        report_filename = f"{safe_group_name}.md"
        report_path = os.path.join(output_dir, report_filename)
        
        # Generar contenido del reporte con formato espec√≠fico requerido
        content = self._create_structured_report_content(group, analysis_results, project_path)
        
        # Escribir reporte
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        self.cli.print_success(f"üìÑ Reporte generado: {report_path}")
        return report_path
    
    def _create_report_content(self, group: Dict[str, Any], analysis_results: List[Dict[str, Any]], project_path: str) -> str:
        """
        Crear el contenido markdown del reporte.
        
        Args:
            group: Informaci√≥n del grupo
            analysis_results: Resultados del an√°lisis
            project_path: Ruta al proyecto
            
        Returns:
            Contenido markdown del reporte
        """
        project_name = os.path.basename(project_path)
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        content = [
            f"# ü§ñ An√°lisis IA de Grupo Funcional: {group['name']}",
            "",
            f"**Proyecto:** {project_name}  ",
            f"**Fecha de An√°lisis:** {timestamp}  ",
            f"**Tipo de Grupo:** {group.get('type', 'Unknown')}  ",
            f"**Archivos Analizados:** {len(analysis_results)}  ",
            "",
            "---",
            "",
            "## üìä Resumen del Grupo",
            "",
            f"- **Nombre del Grupo:** {group['name']}",
            f"- **Tipo:** {group.get('type', 'Unknown')}",
            f"- **Total de Archivos:** {group.get('size', 0)}",
            f"- **Archivos Procesados:** {len(analysis_results)}",
            f"- **Importancia Total:** {group.get('total_importance', 0):.1f}",
            "",
        ]
        
        # Agregar tabla resumen simplificada
        if analysis_results:
            content.extend([
                "## üìã Resumen de An√°lisis",
                "",
                "| Archivo | Funcionalidad | Mejoras Sugeridas |",
                "|---------|---------------|-------------------|"
            ])
            
            for result in analysis_results:
                file_name = result['file_name']
                functionality = self._truncate_text(result['analysis']['functionality'], 60)
                improvements = self._truncate_text(result['analysis']['suggested_improvements'], 60)
                
                content.append(
                    f"| `{file_name}` | {functionality} | {improvements} |"
                )
            
            content.extend(["", "---", ""])
        
        # An√°lisis detallado por archivo - Solo informaci√≥n √∫til
        content.extend([
            "## üîç An√°lisis Detallado por Archivo",
            ""
        ])
        
        for i, result in enumerate(analysis_results, 1):
            analysis = result['analysis']
            
            content.extend([
                f"### {i}. üìÑ `{result['file_path']}`",
                "",
                f"**üéØ Funcionalidad Principal:**",
                f"{analysis['functionality']}",
                "",
                f"**üîó Dependencias:**",
                f"{analysis['dependencies']}",
                "",
                f"**üí° Sugerencias de Mejora:**",
                f"{analysis['suggested_improvements']}",
                "",
                "---",
                ""
            ])
        
        # Footer
        content.extend([
            "",
            f"*Reporte generado por Project Prompt - An√°lisis IA con Anthropic Claude*",
            f"*Timestamp: {timestamp}*"
        ])
        
        return "\n".join(content)
    
    def _create_structured_report_content(self, group: Dict[str, Any], analysis_results: List[Dict[str, Any]], project_path: str) -> str:
        """
        Crear el contenido markdown del reporte con formato estructurado espec√≠fico.
        
        Args:
            group: Informaci√≥n del grupo
            analysis_results: Resultados del an√°lisis
            project_path: Ruta al proyecto
            
        Returns:
            Contenido markdown del reporte con formato espec√≠fico
        """
        from datetime import datetime
        import os
        
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        content = [
            f"# An√°lisis del Grupo: {group['name']}",
            f"Fecha: {timestamp}",
            f"Archivos analizados: {len(analysis_results)}",
            "",
            "## Resumen del Grupo",
            "",
            self._generate_group_summary(group, analysis_results),
            "",
            "## An√°lisis Detallado por Archivo",
            "",
            "| Archivo | Funcionalidad Espec√≠fica | Dependencias Internas | Dependencias Externas | Complejidad |",
            "|---------|--------------------------|----------------------|----------------------|-------------|"
        ]
        
        # Generar tabla con formato espec√≠fico requerido
        for result in analysis_results:
            file_name = result['file_name']
            functionality = self._extract_specific_functionality(result['analysis'])
            internal_deps = self._extract_internal_dependencies(result['analysis'])
            external_deps = self._extract_external_dependencies(result['analysis'])
            complexity = self._extract_complexity_level(result['analysis'])
            
            content.append(
                f"| {file_name} | {functionality} | {internal_deps} | {external_deps} | {complexity} |"
            )
        
        content.extend([
            "",
            "## Conexiones y Dependencias",
            "",
            self._generate_dependency_diagram(analysis_results),
            "",
            "## Recomendaciones",
            "",
            self._generate_group_recommendations(analysis_results)
        ])
        
        return "\n".join(content)
    
    def _generate_group_summary(self, group: Dict[str, Any], analysis_results: List[Dict[str, Any]]) -> str:
        """Generar resumen general del grupo."""
        functionalities = []
        for result in analysis_results:
            functionality = self._extract_specific_functionality(result['analysis'])
            if functionality and functionality != "Sin especificar":
                functionalities.append(functionality)
        
        if functionalities:
            main_purpose = f"Este grupo se encarga principalmente de: {', '.join(functionalities[:3])}."
        else:
            main_purpose = f"Grupo funcional '{group['name']}' que contiene {len(analysis_results)} archivos."
        
        return main_purpose
    
    def _extract_specific_functionality(self, analysis: Dict[str, Any]) -> str:
        """Extraer funcionalidad espec√≠fica del an√°lisis."""
        if isinstance(analysis, dict):
            functionality = analysis.get('functionality', '')
            if isinstance(functionality, str) and len(functionality) > 50:
                # Truncar funcionalidad si es muy larga
                return functionality[:47] + "..."
            return functionality or "Sin especificar"
        return "Sin especificar"
    
    def _extract_internal_dependencies(self, analysis: Dict[str, Any]) -> str:
        """Extraer dependencias internas del an√°lisis."""
        if isinstance(analysis, dict):
            deps = analysis.get('internal_dependencies', [])
            if isinstance(deps, list) and deps:
                return ", ".join(deps[:3])  # M√°ximo 3 dependencias
            elif isinstance(deps, str):
                return deps
        return "-"
    
    def _extract_external_dependencies(self, analysis: Dict[str, Any]) -> str:
        """Extraer dependencias externas del an√°lisis."""
        if isinstance(analysis, dict):
            deps = analysis.get('external_dependencies', [])
            if isinstance(deps, list) and deps:
                return ", ".join(deps[:3])  # M√°ximo 3 dependencias
            elif isinstance(deps, str):
                return deps
        return "-"
    
    def _extract_complexity_level(self, analysis: Dict[str, Any]) -> str:
        """Extraer nivel de complejidad del an√°lisis."""
        if isinstance(analysis, dict):
            complexity = analysis.get('complexity', '')
            if complexity:
                return complexity
            # Intentar inferir complejidad por palabras clave
            text = str(analysis)
            if 'alta' in text.lower() or 'complex' in text.lower():
                return "Alta"
            elif 'media' in text.lower() or 'medium' in text.lower():
                return "Media"
            elif 'baja' in text.lower() or 'low' in text.lower():
                return "Baja"
        return "Media"
    
    def _generate_dependency_diagram(self, analysis_results: List[Dict[str, Any]]) -> str:
        """Generar diagrama textual de dependencias."""
        lines = []
        for result in analysis_results:
            file_name = result['file_name']
            internal_deps = self._extract_internal_dependencies(result['analysis'])
            if internal_deps and internal_deps != "-":
                lines.append(f"- `{file_name}` ‚Üí {internal_deps}")
        
        if lines:
            return "\n".join(lines)
        else:
            return "No se detectaron dependencias internas complejas entre los archivos del grupo."
    
    def _generate_group_recommendations(self, analysis_results: List[Dict[str, Any]]) -> str:
        """Generar recomendaciones basadas en el an√°lisis."""
        recommendations = []
        
        # Analizar patrones comunes
        high_complexity_files = []
        files_with_many_deps = []
        
        for result in analysis_results:
            complexity = self._extract_complexity_level(result['analysis'])
            if complexity == "Alta":
                high_complexity_files.append(result['file_name'])
                
            internal_deps = self._extract_internal_dependencies(result['analysis'])
            if internal_deps and len(internal_deps.split(',')) > 2:
                files_with_many_deps.append(result['file_name'])
        
        if high_complexity_files:
            recommendations.append(f"- **Refactorizaci√≥n de complejidad**: Los archivos {', '.join(high_complexity_files)} presentan alta complejidad y podr√≠an beneficiarse de modularizaci√≥n.")
        
        if files_with_many_deps:
            recommendations.append(f"- **Reducci√≥n de dependencias**: Considerar simplificar las dependencias en {', '.join(files_with_many_deps)} para mejorar la mantenibilidad.")
        
        if len(analysis_results) > 5:
            recommendations.append("- **Organizaci√≥n**: El grupo contiene muchos archivos. Considerar subdividir en grupos m√°s peque√±os para mejor organizaci√≥n.")
        
        recommendations.append("- **Documentaci√≥n**: Agregar documentaci√≥n espec√≠fica sobre las responsabilidades y interfaces de cada archivo.")
        recommendations.append("- **Testing**: Implementar tests unitarios espec√≠ficos para cada funcionalidad identificada.")
        
        return "\n".join(recommendations)
    
    def _create_detailed_report_content(self, group: Dict[str, Any], analysis_results: List[Dict[str, Any]], project_path: str) -> str:
        """
        Crear un reporte detallado con an√°lisis avanzado.
        
        Args:
            group: Informaci√≥n del grupo
            analysis_results: Resultados del an√°lisis
            project_path: Ruta al proyecto
            
        Returns:
            Contenido del reporte detallado
        """
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        content = []
        
        # Para cada archivo
        for result in analysis_results:
            analysis = result['analysis']
            
            # Extraer dependencias
            deps = self._parse_dependencies_from_analysis(analysis)
            if deps:
                for dep in deps:
                    content.append(f"- {dep}")
            else:
                content.append("- Ninguna dependencia cr√≠tica identificada")
            
            content.extend([
                "",
                f"**Puntos de Mejora:**",
            ])
            
            # Extraer mejoras sugeridas
            improvements = self._parse_improvements_from_analysis(analysis)
            if improvements:
                for improvement in improvements:
                    content.append(f"- {improvement}")
            else:
                content.append("- No se identificaron mejoras espec√≠ficas")
            
            content.extend([
                "",
                f"**Nivel de Complejidad:** {self._assess_complexity(analysis)}",
                f"**Prioridad de Refactoring:** {self._assess_refactoring_priority(analysis)}",
                "",
                "---",
                ""
            ])
        
        # Secci√≥n de dependencias del grupo
        content.extend([
            "## Dependencias del Grupo",
            "",
            "### Dependencias Internas",
        ])
        
        internal_deps = self._identify_internal_dependencies(analysis_results)
        if internal_deps:
            for dep in internal_deps:
                content.append(f"- {dep}")
        else:
            content.append("- No se identificaron dependencias internas cr√≠ticas")
        
        content.extend([
            "",
            "### Dependencias Externas",
        ])
        
        external_deps = self._identify_external_dependencies(analysis_results)
        if external_deps:
            for dep in external_deps:
                content.append(f"- {dep}")
        else:
            content.append("- No se identificaron dependencias externas cr√≠ticas")
        
        # Recomendaciones finales
        content.extend([
            "",
            "## Recomendaciones Generales",
            "",
            "### Mejoras de Arquitectura",
        ])
        
        arch_recommendations = self._generate_architecture_recommendations(group, analysis_results)
        for rec in arch_recommendations:
            content.append(f"- {rec}")
        
        content.extend([
            "",
            "### Mejoras de C√≥digo",
        ])
        
        code_recommendations = self._generate_code_recommendations(analysis_results)
        for rec in code_recommendations:
            content.append(f"- {rec}")
        
        content.extend([
            "",
            "### Pr√≥ximos Pasos Sugeridos",
            "",
            "1. **Fase 1:** Implementar mejoras de calidad de c√≥digo identificadas",
            "2. **Fase 2:** Refactorizar componentes con alta complejidad",
            "3. **Fase 3:** Optimizar dependencias y arquitectura",
            "4. **Fase 4:** Implementar patrones de dise√±o recomendados",
            "",
            "---",
            "",
            f"*Reporte generado el {timestamp} por ProjectPrompt AI Analyzer*"
        ])
        
        return "\n".join(content)
    
    def _extract_main_functionality(self, analysis: dict) -> str:
        """Extraer la funcionalidad principal de un an√°lisis."""
        functionality = analysis.get('functionality', '')
        if len(functionality) > 60:
            return functionality[:57] + "..."
        return functionality or "No especificada"
    
    def _extract_dependencies(self, analysis: dict) -> str:
        """Extraer dependencias clave del an√°lisis."""
        # Buscar menciones de imports, requires, etc.
        text = str(analysis.get('technical_details', '')) + str(analysis.get('functionality', ''))
        deps = []
        
        # Patrones comunes de dependencias
        import_patterns = ['import ', 'from ', 'require(', 'include ', '#include']
        for pattern in import_patterns:
            if pattern in text.lower():
                deps.append("M√∫ltiples")
                break
        
        if not deps:
            deps.append("M√≠nimas")
            
        return ", ".join(deps[:3])  # M√°ximo 3 dependencias mostradas
    
    def _extract_quality_score(self, analysis: dict) -> str:
        """Extraer puntuaci√≥n de calidad del an√°lisis."""
        # Buscar puntuaciones num√©ricas en el an√°lisis
        text = str(analysis)
        scores = []
        
        # Buscar patrones de puntuaci√≥n
        import re
        score_patterns = [
            r'(\d+)/10',
            r'score[:\s]*(\d+)',
            r'quality[:\s]*(\d+)',
            r'rating[:\s]*(\d+)'
        ]
        
        for pattern in score_patterns:
            matches = re.findall(pattern, text.lower())
            if matches:
                scores.extend([int(m) for m in matches if m.isdigit()])
        
        if scores:
            avg_score = sum(scores) / len(scores)
            if avg_score >= 8:
                return f"Alta ({avg_score:.1f}/10)"
            elif avg_score >= 6:
                return f"Media ({avg_score:.1f}/10)"
            else:
                return f"Baja ({avg_score:.1f}/10)"
        
        # An√°lisis heur√≠stico basado en palabras clave
        text_lower = text.lower()
        if any(word in text_lower for word in ['excellent', 'good', 'well', 'clean']):
            return "Alta"
        elif any(word in text_lower for word in ['improve', 'refactor', 'fix', 'issue']):
            return "Media"
        else:
            return "Por evaluar"
    
    def _extract_key_recommendations(self, analysis: dict) -> str:
        """Extraer recomendaciones clave del an√°lisis."""
        improvements = analysis.get('suggested_improvements', '')
        if len(improvements) > 50:
            return improvements[:47] + "..."
        return improvements or "Ninguna"
    
    def _parse_dependencies_from_analysis(self, analysis: dict) -> List[str]:
        """Extraer lista de dependencias del an√°lisis."""
        deps = []
        text = str(analysis.get('technical_details', '')) + str(analysis.get('functionality', ''))
        
        # Buscar menciones espec√≠ficas de librer√≠as/m√≥dulos
        common_deps = [
            'os', 'sys', 'json', 'datetime', 'pathlib', 'typing',
            'requests', 'numpy', 'pandas', 'flask', 'django',
            'fastapi', 'sqlalchemy', 'pytest', 'logging'
        ]
        
        for dep in common_deps:
            if dep in text.lower():
                deps.append(f"M√≥dulo {dep}")
        
        # Si no se encontraron dependencias espec√≠ficas, agregar gen√©ricas
        if not deps:
            if 'import' in text.lower():
                deps.append("Dependencias est√°ndar de Python")
            else:
                deps.append("Sin dependencias externas identificadas")
        
        return deps[:5]  # M√°ximo 5 dependencias
    
    def _parse_improvements_from_analysis(self, analysis: dict) -> List[str]:
        """Extraer lista de mejoras del an√°lisis."""
        improvements_text = analysis.get('suggested_improvements', '')
        if not improvements_text:
            return []
        
        # Dividir por puntos o l√≠neas
        improvements = []
        
        # Intentar dividir por n√∫meros o bullets
        import re
        lines = re.split(r'[.\n]|\d+\.', improvements_text)
        
        for line in lines:
            line = line.strip()
            if len(line) > 10:  # Filtrar l√≠neas muy cortas
                improvements.append(line[:80] + ("..." if len(line) > 80 else ""))
        
        return improvements[:4]  # M√°ximo 4 mejoras
    
    def _assess_complexity(self, analysis: dict) -> str:
        """Evaluar el nivel de complejidad basado en el an√°lisis."""
        text = str(analysis).lower()
        
        # Indicadores de alta complejidad
        high_complexity_indicators = [
            'complex', 'complicated', 'intricate', 'nested',
            'multiple inheritance', 'deep hierarchy', 'coupling'
        ]
        
        # Indicadores de baja complejidad
        low_complexity_indicators = [
            'simple', 'straightforward', 'basic', 'minimal',
            'clean', 'clear', 'direct'
        ]
        
        high_score = sum(1 for indicator in high_complexity_indicators if indicator in text)
        low_score = sum(1 for indicator in low_complexity_indicators if indicator in text)
        
        if high_score > low_score:
            return "Alta"
        elif low_score > high_score:
            return "Baja"
        else:
            return "Media"
    
    def _assess_refactoring_priority(self, analysis: dict) -> str:
        """Evaluar la prioridad de refactoring."""
        improvements = analysis.get('suggested_improvements', '').lower()
        
        # Indicadores de alta prioridad
        high_priority_words = [
            'critical', 'urgent', 'important', 'must', 'should',
            'refactor', 'rewrite', 'fix', 'issue', 'problem'
        ]
        
        priority_score = sum(1 for word in high_priority_words if word in improvements)
        
        if priority_score >= 3:
            return "Alta"
        elif priority_score >= 1:
            return "Media"
        else:
            return "Baja"
    
    def _identify_internal_dependencies(self, analysis_results: List[Dict[str, Any]]) -> List[str]:
        """Identificar dependencias internas entre archivos del grupo."""
        deps = []
        file_names = [result['file_name'] for result in analysis_results]
        
        for result in analysis_results:
            text = str(result['analysis'])
            for other_file in file_names:
                if other_file != result['file_name'] and other_file.replace('.py', '') in text:
                    deps.append(f"{result['file_name']} ‚Üí {other_file}")
        
        return list(set(deps))[:8]  # Eliminar duplicados y limitar
    
    def _identify_external_dependencies(self, analysis_results: List[Dict[str, Any]]) -> List[str]:
        """Identificar dependencias externas del grupo."""
        deps = set()
        
        for result in analysis_results:
            text = str(result['analysis']).lower()
            
            # Librer√≠as comunes
            external_libs = [
                'requests', 'numpy', 'pandas', 'flask', 'django',
                'fastapi', 'sqlalchemy', 'pytest', 'click', 'typer',
                'rich', 'anthropic', 'openai'
            ]
            
            for lib in external_libs:
                if lib in text:
                    deps.add(f"Librer√≠a {lib}")
        
        return list(deps)[:10]
    
    def _generate_architecture_recommendations(self, group: Dict[str, Any], analysis_results: List[Dict[str, Any]]) -> List[str]:
        """Generar recomendaciones de arquitectura."""
        recommendations = []
        
        # Basado en el n√∫mero de archivos
        if len(analysis_results) > 10:
            recommendations.append("Considerar dividir el grupo en subgrupos m√°s peque√±os")
        
        # Basado en dependencias
        internal_deps = self._identify_internal_dependencies(analysis_results)
        if len(internal_deps) > 5:
            recommendations.append("Reducir el acoplamiento entre m√≥dulos")
        
        # Recomendaciones generales
        recommendations.extend([
            "Implementar patrones de dise√±o apropiados para el dominio",
            "Evaluar la separaci√≥n de responsabilidades",
            "Considerar la aplicaci√≥n de principios SOLID"
        ])
        
        return recommendations[:5]
    
    def _generate_code_recommendations(self, analysis_results: List[Dict[str, Any]]) -> List[str]:
        """Generar recomendaciones de c√≥digo."""
        recommendations = []
        
        # Analizar patrones comunes en las mejoras sugeridas
        all_improvements = []
        for result in analysis_results:
            improvements = result['analysis'].get('suggested_improvements', '')
            all_improvements.append(improvements.lower())
        
        combined_text = ' '.join(all_improvements)
        
        # Recomendaciones basadas en patrones
        if 'documentation' in combined_text or 'comment' in combined_text:
            recommendations.append("Mejorar documentaci√≥n y comentarios")
        
        if 'test' in combined_text:
            recommendations.append("Incrementar cobertura de pruebas")
        
        if 'error' in combined_text or 'exception' in combined_text:
            recommendations.append("Mejorar manejo de errores")
        
        if 'performance' in combined_text or 'optimization' in combined_text:
            recommendations.append("Optimizar rendimiento")
        
        # Recomendaciones generales
        recommendations.extend([
            "Aplicar est√°ndares de codificaci√≥n consistentes",
            "Implementar logging adecuado",
            "Validar entradas y salidas"
        ])
        
        return recommendations[:6]

    def _analyze_group_fallback(self, project_path: str, group_name: str) -> Dict[str, Any]:
        """
        An√°lisis b√°sico sin IA cuando no hay acceso premium.
        
        Args:
            project_path: Ruta al proyecto
            group_name: Nombre del grupo a analizar
            
        Returns:
            An√°lisis b√°sico del grupo
        """
        try:
            # Obtener grupos funcionales usando m√©todo b√°sico
            groups = self._get_functional_groups_basic(project_path)
            
            if not groups:
                return {
                    "success": False,
                    "error": "No se encontraron grupos funcionales en el proyecto",
                    "group_name": group_name
                }
            
            # Buscar el grupo espec√≠fico
            target_group = None
            for group in groups:
                if group.get('name', '').lower() == group_name.lower():
                    target_group = group
                    break
                # Tambi√©n buscar por coincidencia parcial
                if group_name.lower() in group.get('name', '').lower():
                    target_group = group
                    break
            
            if not target_group:
                available_groups = [g.get('name', 'Sin nombre') for g in groups]
                return {
                    "success": False,
                    "error": f"Grupo '{group_name}' no encontrado. Grupos disponibles: {', '.join(available_groups)}",
                    "group_name": group_name,
                    "available_groups": available_groups
                }
            
            # Mostrar informaci√≥n del grupo
            self.cli.print_info(f"\nüìä Analizando grupo (modo b√°sico): {target_group['name']}")
            self.cli.print_info(f"üìÅ Archivos en el grupo: {target_group['size']}")
            
            # An√°lisis b√°sico de archivos del grupo
            analysis_results = self._analyze_group_files_basic(project_path, target_group)
            
            # Generar reporte de an√°lisis b√°sico
            report_path = self._generate_basic_analysis_report(project_path, target_group, analysis_results)
            
            return {
                "success": True,
                "group_name": target_group['name'],
                "files_analyzed": len(analysis_results),
                "report_path": report_path,
                "analysis_results": analysis_results,
                "analysis_type": "basic"
            }
            
        except Exception as e:
            logger.error(f"Error en an√°lisis b√°sico del grupo '{group_name}': {e}")
            return {
                "success": False,
                "error": f"Error en an√°lisis b√°sico: {str(e)}",
                "group_name": group_name
            }

    def _get_functional_groups_basic(self, project_path: str) -> List[Dict[str, Any]]:
        """
        Obtener grupos funcionales usando an√°lisis b√°sico de directorios.
        
        Args:
            project_path: Ruta al proyecto
            
        Returns:
            Lista de grupos funcionales b√°sicos
        """
        return self._create_directory_based_groups(project_path)

    def _analyze_group_files_basic(self, project_path: str, group: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        An√°lisis b√°sico de archivos sin IA.
        
        Args:
            project_path: Ruta al proyecto
            group: Grupo a analizar
            
        Returns:
            Lista con an√°lisis b√°sico de cada archivo
        """
        from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TaskProgressColumn, TimeElapsedColumn
        from rich.console import Console
        
        files = group.get('files', [])
        analysis_results = []
        
        # Filtrar archivos v√°lidos para an√°lisis
        valid_files = self._filter_analyzable_files(project_path, files)
        
        if not valid_files:
            logger.warning("No hay archivos v√°lidos para analizar en el grupo")
            return []
        
        total_files = len(valid_files)
        console = Console()
        
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            BarColumn(),
            TaskProgressColumn(),
            TimeElapsedColumn(),
            console=console
        ) as progress:
            
            main_task = progress.add_task(f"üìä An√°lisis b√°sico de {total_files} archivos", total=total_files)
            
            for file_info in valid_files:
                try:
                    file_path = file_info.get('path', 'unknown')
                    progress.update(main_task, description=f"üìÑ Analizando: {os.path.basename(file_path)}")
                    
                    file_analysis = self._analyze_single_file_basic(project_path, file_info)
                    if file_analysis:
                        analysis_results.append(file_analysis)
                    
                    progress.update(main_task, advance=1)
                    
                except Exception as e:
                    logger.error(f"Error en an√°lisis b√°sico del archivo {file_info.get('path', '')}: {e}")
                    progress.update(main_task, advance=1)
                    continue
        
        self.cli.print_success(f"‚úÖ An√°lisis b√°sico completado: {len(analysis_results)} archivos procesados")
        return analysis_results

    def _analyze_single_file_basic(self, project_path: str, file_info: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        An√°lisis b√°sico de un archivo individual sin IA.
        
        Args:
            project_path: Ruta al proyecto
            file_info: Informaci√≥n del archivo
            
        Returns:
            An√°lisis b√°sico del archivo o None si falla
        """
        file_path = file_info.get('path', '')
        full_path = os.path.join(project_path, file_path)
        
        try:
            # Leer contenido del archivo
            with open(full_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
            
            if not content.strip():
                return None
            
            # An√°lisis b√°sico est√°tico
            lines = content.split('\n')
            lines_count = len(lines)
            char_count = len(content)
            
            # Detectar lenguaje
            language = self._detect_file_language(file_path)
            
            # An√°lisis b√°sico de funcionalidad
            functionality = self._detect_basic_functionality(file_path, content, language)
            
            # An√°lisis b√°sico de dependencias
            dependencies = self._detect_basic_dependencies(content, language)
            
            # Evaluaci√≥n b√°sica de complejidad
            complexity = self._evaluate_basic_complexity(content, lines_count)
            
            # Generar an√°lisis estructurado
            analysis_data = {
                'file_path': file_path,
                'file_name': os.path.basename(file_path),
                'analysis': {
                    'functionality': functionality,
                    'internal_dependencies': dependencies.get('internal', []),
                    'external_dependencies': dependencies.get('external', []),
                    'complexity': complexity,
                    'responsibilities': self._detect_basic_responsibilities(file_path, content, language),
                    'improvements': self._suggest_basic_improvements(content, language)
                },
                'metrics': {
                    'lines_of_code': lines_count,
                    'character_count': char_count,
                    'file_size_kb': round(char_count / 1024, 2)
                },
                'analysis_timestamp': datetime.now().isoformat(),
                'analysis_type': 'basic'
            }
            
            return analysis_data
            
        except Exception as e:
            logger.error(f"Error en an√°lisis b√°sico del archivo {file_path}: {e}")
            return None

    def _detect_basic_functionality(self, file_path: str, content: str, language: str) -> str:
        """Detectar funcionalidad b√°sica del archivo basada en patrones."""
        if 'test' in file_path.lower():
            return "Archivo de pruebas"
        elif 'config' in file_path.lower():
            return "Archivo de configuraci√≥n"
        elif language == 'python':
            if 'class ' in content:
                return "Definici√≥n de clases Python"
            elif 'def ' in content:
                return "Funciones Python"
            elif 'import ' in content:
                return "M√≥dulo Python"
        elif language == 'javascript':
            if 'function ' in content or '=>' in content:
                return "Funciones JavaScript"
            elif 'class ' in content:
                return "Clases JavaScript"
        
        return f"Archivo de c√≥digo {language}"

    def _detect_basic_dependencies(self, content: str, language: str) -> Dict[str, List[str]]:
        """Detectar dependencias b√°sicas del archivo."""
        import re
        
        dependencies = {'internal': [], 'external': []}
        
        if language == 'python':
            # Buscar imports
            import_patterns = [
                r'import\s+([a-zA-Z_][a-zA-Z0-9_]*)',
                r'from\s+([a-zA-Z_][a-zA-Z0-9_]*)\s+import'
            ]
            for pattern in import_patterns:
                matches = re.findall(pattern, content)
                dependencies['external'].extend(matches)
        
        elif language == 'javascript':
            # Buscar requires e imports
            import_patterns = [
                r'require\([\'"]([^\'"]+)[\'"]\)',
                r'import.*from\s+[\'"]([^\'"]+)[\'"]'
            ]
            for pattern in import_patterns:
                matches = re.findall(pattern, content)
                dependencies['external'].extend(matches)
        
        # Limpiar duplicados
        dependencies['external'] = list(set(dependencies['external']))
        
        return dependencies

    def _evaluate_basic_complexity(self, content: str, lines_count: int) -> str:
        """Evaluar complejidad b√°sica del archivo."""
        if lines_count < 50:
            return "Baja"
        elif lines_count < 200:
            return "Media"
        else:
            return "Alta"

    def _detect_basic_responsibilities(self, file_path: str, content: str, language: str) -> str:
        """Detectar responsabilidades b√°sicas del archivo."""
        filename = os.path.basename(file_path).lower()
        
        if 'main' in filename:
            return "Punto de entrada principal del sistema"
        elif 'test' in filename:
            return "Pruebas unitarias y validaci√≥n de funcionalidad"
        elif 'config' in filename:
            return "Gesti√≥n de configuraci√≥n del sistema"
        elif 'util' in filename:
            return "Funciones de utilidad y helpers"
        elif language == 'python' and 'class ' in content:
            return "Implementaci√≥n de clases y l√≥gica de negocio"
        
        return "L√≥gica de aplicaci√≥n general"

    def _suggest_basic_improvements(self, content: str, language: str) -> str:
        """Sugerir mejoras b√°sicas del archivo."""
        suggestions = []
        
        lines = content.split('\n')
        
        # Verificar documentaci√≥n
        if language == 'python':
            if '"""' not in content and "'''" not in content:
                suggestions.append("Agregar docstrings para documentar funciones y clases")
        
        # Verificar longitud de l√≠neas
        long_lines = [i for i, line in enumerate(lines) if len(line) > 100]
        if long_lines:
            suggestions.append("Reducir longitud de l√≠neas muy largas para mejorar legibilidad")
        
        # Verificar funciones muy largas
        if language == 'python':
            function_lines = [i for i, line in enumerate(lines) if line.strip().startswith('def ')]
            for func_start in function_lines:
                func_end = func_start + 1
                while func_end < len(lines) and (lines[func_end].startswith('    ') or lines[func_end].strip() == ''):
                    func_end += 1
                if func_end - func_start > 30:
                    suggestions.append("Dividir funciones muy largas en funciones m√°s peque√±as")
                    break
        
        if not suggestions:
            suggestions.append("Mantener buenas pr√°cticas de codificaci√≥n")
        
        return '; '.join(suggestions[:3])

    def _generate_basic_analysis_report(self, project_path: str, group: Dict[str, Any], analysis_results: List[Dict[str, Any]]) -> str:
        """
        Generar reporte de an√°lisis b√°sico.
        
        Args:
            project_path: Ruta al proyecto
            group: Grupo analizado
            analysis_results: Resultados del an√°lisis
            
        Returns:
            Ruta al archivo de reporte generado
        """
        # Usar el mismo directorio que el an√°lisis con IA
        project_name = os.path.basename(project_path)
        safe_group_name = "".join(c for c in group['name'] if c.isalnum() or c in (' ', '-', '_')).strip()
        safe_group_name = safe_group_name.replace(' ', '_')
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{safe_group_name}_basic_analysis_{timestamp}.md"
        
        # Crear directorio de salida
        output_dir = os.path.join(project_path, "project-output", "analyses", "functionality_groups")
        os.makedirs(output_dir, exist_ok=True)
        report_path = os.path.join(output_dir, filename)
        
        # Generar contenido del reporte
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(f"# An√°lisis B√°sico del Grupo Funcional: {group['name']}\n\n")
            f.write(f"**Fecha de an√°lisis:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"**Proyecto:** {project_name}\n")
            f.write(f"**Tipo de an√°lisis:** B√°sico (sin IA)\n")
            f.write(f"**Archivos analizados:** {len(analysis_results)}\n\n")
            
            f.write("## Resumen del Grupo\n\n")
            f.write(f"- **Nombre:** {group['name']}\n")
            f.write(f"- **Tipo:** {group.get('type', 'Desconocido')}\n")
            f.write(f"- **Total de archivos:** {group.get('size', 0)}\n")
            f.write(f"- **Archivos procesados:** {len(analysis_results)}\n\n")
            
            if analysis_results:
                f.write("## An√°lisis por Archivo\n\n")
                
                for i, result in enumerate(analysis_results, 1):
                    f.write(f"### {i}. {result['file_name']}\n\n")
                    f.write(f"**Ruta:** `{result['file_path']}`\n\n")
                    
                    analysis = result['analysis']
                    metrics = result['metrics']
                    
                    f.write(f"- **Funcionalidad:** {analysis['functionality']}\n")
                    f.write(f"- **Responsabilidades:** {analysis['responsibilities']}\n")
                    f.write(f"- **Complejidad:** {analysis['complexity']}\n")
                    f.write(f"- **L√≠neas de c√≥digo:** {metrics['lines_of_code']}\n")
                    f.write(f"- **Tama√±o:** {metrics['file_size_kb']} KB\n\n")
                    
                    if analysis['external_dependencies']:
                        f.write(f"**Dependencias externas:** {', '.join(analysis['external_dependencies'][:5])}\n")
                        if len(analysis['external_dependencies']) > 5:
                            f.write(f" (+{len(analysis['external_dependencies']) - 5} m√°s)\n")
                        f.write("\n")
                    
                    f.write(f"**Mejoras sugeridas:** {analysis['improvements']}\n\n")
                    f.write("---\n\n")
                
                # Agregar resumen y recomendaciones
                f.write("## Resumen y Recomendaciones\n\n")
                f.write("### Estad√≠sticas Generales\n\n")
                
                total_lines = sum(r['metrics']['lines_of_code'] for r in analysis_results)
                total_size = sum(r['metrics']['file_size_kb'] for r in analysis_results)
                
                f.write(f"- **Total de l√≠neas:** {total_lines:,}\n")
                f.write(f"- **Tama√±o total:** {total_size:.2f} KB\n")
                f.write(f"- **Promedio de l√≠neas por archivo:** {total_lines // len(analysis_results) if analysis_results else 0}\n\n")
                
                # An√°lisis de complejidad
                complexity_counts = {}
                for result in analysis_results:
                    complexity = result['analysis']['complexity']
                    complexity_counts[complexity] = complexity_counts.get(complexity, 0) + 1
                
                f.write("### Distribuci√≥n de Complejidad\n\n")
                for complexity, count in complexity_counts.items():
                    f.write(f"- **{complexity}:** {count} archivos\n")
                f.write("\n")
                
                f.write("### Recomendaciones Generales\n\n")
                f.write("- Revisar archivos de alta complejidad para posibles refactorizaciones\n")
                f.write("- Mejorar documentaci√≥n en archivos con pocas l√≠neas de comentarios\n")
                f.write("- Considerar dividir archivos muy grandes en m√≥dulos m√°s peque√±os\n")
                f.write("- Implementar pruebas unitarias si no las hay\n")
                f.write("- Validar y optimizar dependencias externas\n\n")
            else:
                f.write("## Sin Resultados\n\n")
                f.write("No se pudieron procesar archivos en este grupo.\n\n")
            
            f.write("---\n")
            f.write("*Reporte generado por ProjectPrompt (An√°lisis B√°sico)*\n")
        
        return report_path

def get_ai_group_analyzer(config: Optional[ConfigManager] = None) -> AIGroupAnalyzer:
    """
    Obtener instancia singleton del analizador de grupos con IA.
    
    Args:
        config: Configuraci√≥n opcional
        
    Returns:
        Instancia del analizador
    """
    if not hasattr(get_ai_group_analyzer, '_instance'):
        get_ai_group_analyzer._instance = AIGroupAnalyzer(config)
    return get_ai_group_analyzer._instance
